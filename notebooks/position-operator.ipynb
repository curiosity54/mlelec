{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/twocenter_utils.py:110: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Returns the m \\in {-l,...,l} indices\"\"\"\n",
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/twocenter_utils.py:116: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Returns the 2D outerproduct of m_i \\in {-l_i,... , l_i} and m_j \\in {-l_j,... , l_j} to index the (l_i, l_j) block of the hamiltonian\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/twocenter_utils.py:110: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Returns the m \\in {-l,...,l} indices\"\"\"\n",
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/twocenter_utils.py:116: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Returns the 2D outerproduct of m_i \\in {-l_i,... , l_i} and m_j \\in {-l_j,... , l_j} to index the (l_i, l_j) block of the hamiltonian\n",
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/pbc_utils.py:1688: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  assert np.isclose(torch.norm(matrixT - matrixmT.T).item(), 0.0), f\"Failed to check H({T}) = H({mT})^\\dagger\"\n",
      "/Users/jigyasa/miniconda3/lib/python3.12/site-packages/pyscf/dft/libxc.py:771: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, corresponding to the original definition by Stephens et al. (issue 1480) and the same as the B3LYP functional in Gaussian. To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import metatensor.torch as mts\n",
    "from metatensor.torch import TensorMap, Labels, TensorBlock\n",
    "import ase \n",
    "from mlelec.data.dataset import QMDataset\n",
    "from mlelec.utils.target_utils import get_targets\n",
    "from mlelec.utils.twocenter_utils import _to_coupled_basis\n",
    "\n",
    "# print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/scratch/mlelec/src/mlelec/data/dataset.py:210: UserWarning: Overlap matrices not provided\n",
      "  warnings.warn(\"Overlap matrices not provided\")\n"
     ]
    }
   ],
   "source": [
    "frames = [ase.Atoms('H2O', positions=[[0, 0, 0], [0, 0, 1], [0, 1, 0]], pbc = False)]\n",
    "qmdata = QMDataset(frames = frames, \n",
    "                   fock_realspace= torch.randn(1,7,7),\n",
    "                   dimension = 0, \n",
    "                   orbs = {8:[[1,0,0],[2,0,0],[2,1,0], [2,1,1], [2,1,-1]], 1:[[1,0,0]]},\n",
    "                   orbs_name = 'sto-3g',    \n",
    "                   device = 'cpu'\n",
    ")   \n",
    "blocks, coupled_blocks  = get_targets(qmdata, cutoff = 4, device = 'cpu', all_pairs = False, sort_orbs =True, return_uncoupled=True)\n",
    "# just needed them for keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[0].values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a 3D tensor, we should have the same bloch structure, except, we have an additional components dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_3D = []\n",
    "position_components = Labels(['m_3'], values = torch.tensor([-1,0,1]).reshape(3,-1))\n",
    "for block in blocks:\n",
    "    nsample, nmi, nmj, nprop = block.values.shape\n",
    "    blocks_3D.append(\n",
    "        TensorBlock( values = torch.randn(nsample, nmi, nmj,3, nprop), \n",
    "                    components = [block.components[0],  block.components[1], position_components],\n",
    "                    properties = block.properties,\n",
    "                    samples = block.samples,\n",
    "        )\n",
    "    )\n",
    "key_names = blocks.keys.names + [\"l_3\"]\n",
    "key_value = torch.nn.functional.pad(blocks.keys.values, (0,1), mode='constant', value=1) \n",
    "\n",
    "uncoupled_blocks_3D = TensorMap( Labels(key_names, key_value) , blocks_3D)\n",
    "\n",
    "uncoupled_blocks_3D = mts.remove_dimension(uncoupled_blocks_3D, 'samples', 'cell_shift_a') \n",
    "uncoupled_blocks_3D = mts.remove_dimension(uncoupled_blocks_3D, 'samples', 'cell_shift_b') \n",
    "uncoupled_blocks_3D = mts.remove_dimension(uncoupled_blocks_3D, 'samples', 'cell_shift_c') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMap with 12 blocks\n",
       "keys: block_type  species_i  n_i  l_i  species_j  n_j  l_j  l_3\n",
       "          -1          1       1    0       1       1    0    1\n",
       "          0           1       1    0       1       1    0    1\n",
       "          0           8       1    0       8       1    0    1\n",
       "          0           8       1    0       8       2    0    1\n",
       "          0           8       1    0       8       2    1    1\n",
       "          0           8       2    0       8       2    0    1\n",
       "          0           8       2    0       8       2    1    1\n",
       "          0           8       2    1       8       2    1    1\n",
       "          1           1       1    0       1       1    0    1\n",
       "          2           1       1    0       8       1    0    1\n",
       "          2           1       1    0       8       2    0    1\n",
       "          2           1       1    0       8       2    1    1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoupled_blocks_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_2Dx = []; blocks_2Dy = []; blocks_2Dz = []\n",
    "for block in uncoupled_blocks_3D:\n",
    "    nsample, nmi, nmj, _, nprop = block.values.shape\n",
    "    blocks_2Dy.append(\n",
    "        TensorBlock( values = block.values[...,0,:], \n",
    "                    components = [block.components[0],  block.components[1]],\n",
    "                    properties = block.properties,\n",
    "                      samples = block.samples,\n",
    "        ))\n",
    "    blocks_2Dz.append(\n",
    "        TensorBlock( values = block.values[...,1,:], \n",
    "                    components = [block.components[0],  block.components[1]],\n",
    "                    properties = block.properties,\n",
    "                    samples = block.samples,\n",
    "        ))\n",
    "    blocks_2Dx.append(\n",
    "        TensorBlock( values = block.values[...,2,:], \n",
    "                    components = [block.components[0],  block.components[1]],\n",
    "                    properties = block.properties,\n",
    "                    samples = block.samples,\n",
    "        ))\n",
    "uncoupled_blocks_2Dx = TensorMap( blocks.keys , blocks_2Dx)\n",
    "uncoupled_blocks_2Dy = TensorMap( blocks.keys , blocks_2Dy)\n",
    "uncoupled_blocks_2Dz = TensorMap( blocks.keys , blocks_2Dz)\n",
    "\n",
    "# uncoupled_blocks_2Dx = mts.remove_dimension(uncoupled_blocks_2Dx, 'samples', 'cell_shift_a') \n",
    "# uncoupled_blocks_2Dx = mts.remove_dimension(uncoupled_blocks_2Dx, 'samples', 'cell_shift_b') \n",
    "# uncoupled_blocks_2Dx = mts.remove_dimension(uncoupled_blocks_2Dx, 'samples', 'cell_shift_c') \n",
    "\n",
    "# uncoupled_blocks_2Dy = mts.remove_dimension(uncoupled_blocks_2Dy, 'samples', 'cell_shift_a') \n",
    "# uncoupled_blocks_2Dy = mts.remove_dimension(uncoupled_blocks_2Dy, 'samples', 'cell_shift_b') \n",
    "# uncoupled_blocks_2Dy = mts.remove_dimension(uncoupled_blocks_2Dy, 'samples', 'cell_shift_c') \n",
    "\n",
    "# uncoupled_blocks_2Dz = mts.remove_dimension(uncoupled_blocks_2Dz, 'samples', 'cell_shift_a') \n",
    "# uncoupled_blocks_2Dz = mts.remove_dimension(uncoupled_blocks_2Dz, 'samples', 'cell_shift_b') \n",
    "# uncoupled_blocks_2Dz = mts.remove_dimension(uncoupled_blocks_2Dz, 'samples', 'cell_shift_c') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupled_blocks_2Dx = _to_coupled_basis(uncoupled_blocks_2Dx, skip_symmetry = False, device = 'cpu', translations = None)\n",
    "coupled_blocks_2Dy = _to_coupled_basis(uncoupled_blocks_2Dy, skip_symmetry = False, device = 'cpu', translations = None)\n",
    "coupled_blocks_2Dz = _to_coupled_basis(uncoupled_blocks_2Dz, skip_symmetry = False, device = 'cpu', translations = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a tensor map from these three individually coupled tmaps, concatenating them along the components dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupled_blocks_2Dx = coupled_blocks_2Dx.keys_to_properties(['species_i', 'n_i', 'l_i','species_j', 'n_j', 'l_j'])\n",
    "coupled_blocks_2Dy = coupled_blocks_2Dy.keys_to_properties(['species_i', 'n_i', 'l_i','species_j', 'n_j', 'l_j'])\n",
    "coupled_blocks_2Dz = coupled_blocks_2Dz.keys_to_properties(['species_i', 'n_i', 'l_i','species_j', 'n_j', 'l_j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncoupled_2 = []\n",
    "for (bx,by,bz) in zip(coupled_blocks_2Dy.blocks(), coupled_blocks_2Dz.blocks(),coupled_blocks_2Dx.blocks()):\n",
    "    ## Assert that the blocks correspond to the same keys\n",
    "    assert bx.values.shape == by.values.shape == bz.values.shape\n",
    "    uncoupled_2.append( TensorBlock( values = torch.stack([bx.values, by.values,bz.values], dim=2), \n",
    "                                    components = [bx.components[0],position_components], \n",
    "                                    samples = bx.samples, \n",
    "                                    properties = bx.properties\n",
    "    ) )\n",
    "newkeys = Labels(coupled_blocks_2Dz.keys.names+['L2'], values = torch.nn.functional.pad(coupled_blocks_2Dz.keys.values, (0,1), mode='constant', value=1))\n",
    "uncoupled_2 = TensorMap(newkeys, uncoupled_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMap with 6 blocks\n",
       "keys: block_type  L  L2\n",
       "          0       0  1\n",
       "          0       1  1\n",
       "          0       2  1\n",
       "          1       0  1\n",
       "          2       0  1\n",
       "          2       1  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoupled_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/twocenter_utils.py:110: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Returns the m \\in {-l,...,l} indices\"\"\"\n",
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/twocenter_utils.py:116: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Returns the 2D outerproduct of m_i \\in {-l_i,... , l_i} and m_j \\in {-l_j,... , l_j} to index the (l_i, l_j) block of the hamiltonian\n"
     ]
    }
   ],
   "source": [
    "coupled_blocks = _to_coupled_basis(uncoupled_blocks_3D, skip_symmetry = False, device = 'cpu', translations = None, high_rank = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8360],\n",
       "         [ 1.1375],\n",
       "         [ 0.0626]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupled_blocks[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoupled_blocks_3D[0].samples.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1, 0, 1): {1: tensor([[[-0.8360,  1.1375,  0.0626]]])}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupled_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.symmetry import ClebschGordanReal\n",
    "CG = ClebschGordanReal(10, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def couple(decoupled, iterate = 0, cg=None, selfdevice= 'cpu', lmax=10):\n",
    "       \n",
    "        coupled = {}\n",
    "\n",
    "        # when called on a matrix, turns it into a dict form to which we can\n",
    "        # apply the generic algorithm\n",
    "        if not isinstance(decoupled, dict):\n",
    "            l2 = (decoupled.shape[-1] - 1) // 2\n",
    "            decoupled = {(): {l2: decoupled}}\n",
    "\n",
    "        # runs over the tuple of (partly) decoupled terms\n",
    "        for ltuple, lcomponents in decoupled.items():\n",
    "            # each is a list of L terms\n",
    "            for lc in lcomponents.keys():\n",
    "                # this is the actual matrix-valued coupled term,\n",
    "                # of shape (..., 2l1+1, 2l2+1), transforming as Y^m1_l1 Y^m2_l2\n",
    "                dec_term = lcomponents[lc]\n",
    "                l1 = (dec_term.shape[-2] - 1) // 2\n",
    "                l2 = (dec_term.shape[-1] - 1) // 2\n",
    "\n",
    "                # there is a certain redundance: the L value is also the last entry\n",
    "                # in ltuple\n",
    "                if lc != l2:\n",
    "                    raise ValueError(\n",
    "                        \"Inconsistent shape for coupled angular momentum block.\"\n",
    "                    )\n",
    "\n",
    "                # in the new coupled term, prepend (l1,l2) to the existing label\n",
    "                device = dec_term.device\n",
    "                if device != selfdevice:\n",
    "                    dec_term = dec_term.to(selfdevice)\n",
    "                \n",
    "                coupled[(l1, l2) + ltuple] = {}\n",
    "                for L in range(\n",
    "                    max(l1, l2) - min(l1, l2), min(lmax, (l1 + l2)) + 1\n",
    "                ):\n",
    "                    # Lterm = torch.einsum('spmn,mnM->spM', dec_term, self._cg[(l1, l2, L)])\n",
    "                    coupled[(l1, l2) + ltuple][L] = torch.tensordot(dec_term, cg._cg[(l1, l2, L)].to(dec_term), dims=2)\n",
    "\n",
    "        # repeat if required\n",
    "        if iterate > 0:\n",
    "            coupled = couple(coupled, iterate - 1, cg= cg, selfdevice=selfdevice,lmax=lmax)\n",
    "        return coupled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/twocenter_utils.py:110: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Returns the m \\in {-l,...,l} indices\"\"\"\n",
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/twocenter_utils.py:116: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Returns the 2D outerproduct of m_i \\in {-l_i,... , l_i} and m_j \\in {-l_j,... , l_j} to index the (l_i, l_j) block of the hamiltonian\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,5,7,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 5, 7])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.moveaxis(a, -1,-3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = couple(a, 1,cg = CG,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3, 1)\n",
      "(2, 2, 3, 1) 0\n",
      "torch.Size([2, 3]) torch.Size([1, 1]) torch.Size([1, 1])\n",
      "(2, 2, 3, 1) 1\n",
      "torch.Size([2, 3]) torch.Size([1, 3]) torch.Size([3, 1])\n",
      "(2, 2, 3, 1) 2\n",
      "torch.Size([2, 3]) torch.Size([1, 5]) torch.Size([5, 1])\n",
      "(2, 2, 3, 1) 3\n",
      "torch.Size([2, 3]) torch.Size([1, 7]) torch.Size([7, 1])\n",
      "(2, 2, 3, 1) 4\n",
      "torch.Size([2, 3]) torch.Size([1, 9]) torch.Size([9, 1])\n",
      "(2, 3, 3, 1)\n",
      "(2, 3, 3, 1) 1\n",
      "torch.Size([2, 3]) torch.Size([1, 3]) torch.Size([3, 1])\n",
      "(2, 3, 3, 1) 2\n",
      "torch.Size([2, 3]) torch.Size([1, 5]) torch.Size([5, 1])\n",
      "(2, 3, 3, 1) 3\n",
      "torch.Size([2, 3]) torch.Size([1, 7]) torch.Size([7, 1])\n",
      "(2, 3, 3, 1) 4\n",
      "torch.Size([2, 3]) torch.Size([1, 9]) torch.Size([9, 1])\n",
      "(2, 3, 3, 1) 5\n",
      "torch.Size([2, 3]) torch.Size([1, 11]) torch.Size([11, 1])\n",
      "(2, 4, 3, 1)\n",
      "(2, 4, 3, 1) 2\n",
      "torch.Size([2, 3]) torch.Size([1, 5]) torch.Size([5, 1])\n",
      "(2, 4, 3, 1) 3\n",
      "torch.Size([2, 3]) torch.Size([1, 7]) torch.Size([7, 1])\n",
      "(2, 4, 3, 1) 4\n",
      "torch.Size([2, 3]) torch.Size([1, 9]) torch.Size([9, 1])\n",
      "(2, 4, 3, 1) 5\n",
      "torch.Size([2, 3]) torch.Size([1, 11]) torch.Size([11, 1])\n",
      "(2, 4, 3, 1) 6\n",
      "torch.Size([2, 3]) torch.Size([1, 13]) torch.Size([13, 1])\n"
     ]
    }
   ],
   "source": [
    "coupled = a\n",
    "for coupledkey in coupled:\n",
    "    k = coupledkey[1]\n",
    "    print(coupledkey)\n",
    "    for L in coupled[coupledkey]:\n",
    "        print(coupledkey, L)\n",
    "                    # block_idx = tuple(idx) + (k, L)\n",
    "                    # skip blocks that are zero because of symmetry - TBD \n",
    "                    # if ai == aj and ni == nj and li == lj:\n",
    "                    #     parity = (-1) ** (li + lj + L)\n",
    "                    #     if ((parity == -1 and block_type in (0, 1)) or (parity == 1 and block_type == -1)) and not skip_symmetry:\n",
    "                    #         continue\n",
    "                    \n",
    "        print(block.samples.values.shape, coupled[coupledkey][L].shape, torch.moveaxis(coupled[coupledkey][L], -1, -2).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
