{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/miniconda3/lib/python3.12/site-packages/pyscf/dft/libxc.py:771: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, corresponding to the original definition by Stephens et al. (issue 1480) and the same as the B3LYP functional in Gaussian. To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import metatensor.torch as mts\n",
    "from metatensor.torch import TensorMap, Labels, TensorBlock\n",
    "import ase \n",
    "from mlelec.data.dataset import QMDataset\n",
    "from mlelec.utils.target_utils import get_targets\n",
    "from mlelec.utils.twocenter_utils import _to_coupled_basis,_to_uncoupled_basis_old\n",
    "torch.set_default_dtype(torch.float64)\n",
    "# print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlelec.data.pyscf_calculator import _instantiate_pyscf_mol\n",
    "import pyscf.pbc.tools.pyscf_ase as pyscf_ase\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import pyscf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_xhat(frame, basis='sto-3g', fix_xyz=False, device='cpu'):\n",
    "    mol = pyscf.gto.Mole()\n",
    "    mol.atom = pyscf_ase.ase_atoms_to_pyscf(frame)\n",
    "    mol.basis = basis\n",
    "    mol.symmetry = False    \n",
    "    mol.verbose = 2\n",
    "    mol.build() \n",
    "    with mol.with_common_orig((0,0,0)):\n",
    "       x= torch.from_numpy(mol.intor('int1e_r', comp=3)).to(device = device)\n",
    "    if fix_xyz:\n",
    "        x = torch.roll(x, shifts=-1, dims=0)\n",
    "\n",
    "    return x.moveaxis(0,-1)\n",
    "\n",
    "# other integrals to try mol.intor('cint1e_kin_sph') #+ mol.intor('cint1e_nuc_sph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/scratch/mlelec/src/mlelec/data/dataset.py:210: UserWarning: Overlap matrices not provided\n",
      "  warnings.warn(\"Overlap matrices not provided\")\n"
     ]
    }
   ],
   "source": [
    "frames = [ase.Atoms('H2O', positions=[[0, 0, 0], [0, 0, 1], [0, 1, 0]], pbc = False)]\n",
    "H = torch.randn(1,7,7) \n",
    "H = H + H.transpose(-1,-2)   \n",
    "qmdata = QMDataset(frames = frames, \n",
    "                   fock_realspace= H,\n",
    "                   dimension = 0, \n",
    "                   orbs = {8:[[1,0,0],[2,0,0],[2,1,0], [2,1,1], [2,1,-1]], 1:[[1,0,0]]},\n",
    "                   orbs_name = 'sto-3g',    \n",
    "                   device = 'cpu'\n",
    ")   \n",
    "blocks, coupled_blocks  = get_targets(qmdata, cutoff = 4, device = 'cpu', all_pairs = False, sort_orbs =True, return_uncoupled=True)\n",
    "# just needed them for keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_sto3g = []\n",
    "xhat_def2 = []\n",
    "for f in frames:\n",
    "    # _instantiate_pyscf_mol(frames[0], basis=\"sto-3g\"\n",
    "    xhat_sto3g.append(compute_xhat(f, basis='sto-3g'))\n",
    "    xhat_def2.append(compute_xhat(f, basis='def2-svp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1102e-16,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1102e-16,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat_sto3g[0][...,0] - xhat_sto3g[0][...,0].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor - to -blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go from matrix to blocks of the shape(nsample, nmi, nmj,3, nprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [4.4409e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlelec.utils.pbc_utils import blocks_to_matrix, matrix_to_blocks\n",
    "\n",
    "blocks_to_matrix(matrix_to_blocks(qmdata, cutoff = 10), qmdata)[0][0,0,0] - qmdata.fock_realspace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigyasa/scratch/mlelec/src/mlelec/utils/pbc_utils.py:147: UserWarning: high_rank must be True if matrix is a 3D tensor, setting to True\n",
      "  warnings.warn(\"high_rank must be True if matrix is a 3D tensor, setting to True\")\n"
     ]
    }
   ],
   "source": [
    "xhat_blocks= matrix_to_blocks(qmdata, matrix= xhat_sto3g, cutoff = 10, high_rank = True, )\n",
    "# xhat_blocks = mts.remove_dimension(xhat_blocks, 'samples', 'cell_shift_a') \n",
    "# xhat_blocks = mts.remove_dimension(xhat_blocks, 'samples', 'cell_shift_b') \n",
    "# xhat_blocks= mts.remove_dimension(xhat_blocks, 'samples', 'cell_shift_c') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# couple blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a 3D tensor, we should have the same block structure, except, we have an additional components dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMap with 12 blocks\n",
       "keys: block_type  species_i  n_i  l_i  species_j  n_j  l_j  l_3\n",
       "          -1          1       1    0       1       1    0    1\n",
       "          0           1       1    0       1       1    0    1\n",
       "          0           8       1    0       8       1    0    1\n",
       "          0           8       1    0       8       2    0    1\n",
       "          0           8       1    0       8       2    1    1\n",
       "          0           8       2    0       8       2    0    1\n",
       "          0           8       2    0       8       2    1    1\n",
       "          0           8       2    1       8       2    1    1\n",
       "          1           1       1    0       1       1    0    1\n",
       "          2           1       1    0       8       1    0    1\n",
       "          2           1       1    0       8       2    0    1\n",
       "          2           1       1    0       8       2    1    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_3D = []\n",
    "position_components = Labels(['m_3'], values = torch.tensor([-1,0,1]).reshape(3,-1))\n",
    "for block in blocks:\n",
    "    nsample, nmi, nmj, nprop = block.values.shape\n",
    "    blocks_3D.append(\n",
    "        TensorBlock( values = torch.randn(nsample, nmi, nmj,3, nprop), \n",
    "                    components = [block.components[0],  block.components[1], position_components],\n",
    "                    properties = block.properties,\n",
    "                    samples = block.samples,\n",
    "        )\n",
    "    )\n",
    "key_names = blocks.keys.names + [\"l_3\"]\n",
    "key_value = torch.nn.functional.pad(blocks.keys.values, (0,1), mode='constant', value=1) \n",
    "\n",
    "uncoupled_blocks_3D = TensorMap( Labels(key_names, key_value) , blocks_3D)\n",
    "\n",
    "uncoupled_blocks_3D = mts.remove_dimension(uncoupled_blocks_3D, 'samples', 'cell_shift_a') \n",
    "uncoupled_blocks_3D = mts.remove_dimension(uncoupled_blocks_3D, 'samples', 'cell_shift_b') \n",
    "uncoupled_blocks_3D = mts.remove_dimension(uncoupled_blocks_3D, 'samples', 'cell_shift_c') \n",
    "uncoupled_blocks_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupled_blocks = _to_coupled_basis(xhat_blocks, skip_symmetry = False, device = 'cpu', translations = True, high_rank = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decouple blocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc = _to_uncoupled_basis_old(coupled_blocks,device = 'cpu', translations = None, high_rank = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 0, 1, 1, 0, 1], dtype=torch.int32) tensor(1.3323e-15)\n",
      "tensor([1, 1, 1, 0, 1, 1, 0, 1], dtype=torch.int32) tensor(4.4409e-16)\n",
      "tensor([-1,  1,  1,  0,  1,  1,  0,  1], dtype=torch.int32) tensor(0.)\n",
      "tensor([2, 1, 1, 0, 8, 1, 0, 1], dtype=torch.int32) tensor(3.1038e-17)\n",
      "tensor([2, 1, 1, 0, 8, 2, 0, 1], dtype=torch.int32) tensor(1.9230e-16)\n",
      "tensor([2, 1, 1, 0, 8, 2, 1, 1], dtype=torch.int32) tensor(6.1448e-16)\n",
      "tensor([0, 8, 1, 0, 8, 1, 0, 1], dtype=torch.int32) tensor(4.4409e-16)\n",
      "tensor([0, 8, 1, 0, 8, 2, 0, 1], dtype=torch.int32) tensor(1.1102e-16)\n",
      "tensor([0, 8, 1, 0, 8, 2, 1, 1], dtype=torch.int32) tensor(8.1218e-17)\n",
      "tensor([0, 8, 2, 0, 8, 2, 0, 1], dtype=torch.int32) tensor(4.4409e-16)\n",
      "tensor([0, 8, 2, 0, 8, 2, 1, 1], dtype=torch.int32) tensor(9.9920e-16)\n",
      "tensor([0, 8, 2, 1, 8, 2, 1, 1], dtype=torch.int32) tensor(2.1896e-15)\n"
     ]
    }
   ],
   "source": [
    "import metatensor.torch as mts\n",
    "\n",
    "for k,b in unc.items():\n",
    "    b1 = xhat_blocks.block(k)\n",
    "    print(k.values, torch.norm(b.values - b1.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1, 3, 1])\n",
      "torch.Size([1, 1, 1, 3, 1])\n",
      "torch.Size([1, 1, 1, 3, 1])\n",
      "torch.Size([2, 1, 1, 3, 1])\n",
      "torch.Size([2, 1, 1, 3, 1])\n",
      "torch.Size([2, 1, 3, 3, 1])\n",
      "torch.Size([1, 1, 1, 3, 1])\n",
      "torch.Size([1, 1, 1, 3, 1])\n",
      "torch.Size([1, 1, 3, 3, 1])\n",
      "torch.Size([1, 1, 1, 3, 1])\n",
      "torch.Size([1, 1, 3, 3, 1])\n",
      "torch.Size([1, 3, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "for k,b in unc.items():\n",
    "\n",
    "    print(b.values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blocks to tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.pbc_utils import inverse_bloch_sum, _orbs_offsets, _components_idx, ISQRT_2, _atom_blocks_idx\n",
    "from ase.units import Bohr\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "torch.Size([1, 1, 1])\n",
      "0 0\n",
      "torch.Size([1, 1, 1])\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 1\n",
      "0 0\n",
      "torch.Size([1, 1, 1])\n",
      "0 0\n",
      "torch.Size([1, 1, 1])\n",
      "0 1\n",
      "torch.Size([1, 3, 1])\n",
      "0 0\n",
      "torch.Size([1, 1, 1])\n",
      "0 1\n",
      "torch.Size([1, 3, 1])\n",
      "1 1\n",
      "torch.Size([3, 3, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/q06q1_g56p78b5klqcvmw1mw0000gn/T/ipykernel_24453/2332225319.py:52: UserWarning: l_3 detected, setting high_rank to True\n",
      "  warnings.warn(\"l_3 detected, setting high_rank to True\")\n"
     ]
    }
   ],
   "source": [
    "recon = blocks_to_matrix(xhat_blocks, qmdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -4.6911e-01],\n",
       "         [ 0.0000e+00, -8.8543e-02,  0.0000e+00],\n",
       "         [ 0.0000e+00, -4.8729e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00,  2.8755e-01,  2.8755e-01],\n",
       "         [ 0.0000e+00,  1.1610e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -2.8755e-01]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00, -4.6911e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00, -1.8897e+00],\n",
       "         [ 0.0000e+00, -3.4216e-02, -9.1265e-04],\n",
       "         [ 0.0000e+00, -2.6750e-01, -1.6970e-01],\n",
       "         [ 0.0000e+00,  1.5190e-01,  1.5190e-01],\n",
       "         [ 0.0000e+00,  2.6498e-02,  1.2224e-01],\n",
       "         [ 0.0000e+00, -1.7839e-01, -2.7414e-01]],\n",
       "\n",
       "        [[ 0.0000e+00, -8.8543e-02,  0.0000e+00],\n",
       "         [ 0.0000e+00, -3.4216e-02, -9.1265e-04],\n",
       "         [ 0.0000e+00, -1.8897e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -4.4731e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00,  5.0792e-02,  5.0792e-02],\n",
       "         [ 0.0000e+00, -5.0792e-02,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -5.0792e-02]],\n",
       "\n",
       "        [[ 0.0000e+00, -4.8729e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00, -2.6750e-01, -1.6970e-01],\n",
       "         [ 0.0000e+00, -4.4731e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.8897e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  6.4117e-01,  6.4117e-01],\n",
       "         [ 0.0000e+00, -6.4117e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -6.4117e-01]],\n",
       "\n",
       "        [[ 0.0000e+00,  2.8755e-01,  2.8755e-01],\n",
       "         [ 0.0000e+00,  1.5190e-01,  1.5190e-01],\n",
       "         [ 0.0000e+00,  5.0792e-02,  5.0792e-02],\n",
       "         [-1.1102e-16,  6.4117e-01,  6.4117e-01],\n",
       "         [ 0.0000e+00, -1.8897e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  1.1610e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00,  2.6498e-02,  1.2224e-01],\n",
       "         [ 0.0000e+00, -5.0792e-02,  0.0000e+00],\n",
       "         [ 0.0000e+00, -6.4117e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.8897e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00, -2.8755e-01],\n",
       "         [ 0.0000e+00, -1.7839e-01, -2.7414e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00, -5.0792e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00, -6.4117e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.8897e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon[0][0,0,0]  - xhat_sto3g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_2Dx = []; blocks_2Dy = []; blocks_2Dz = []\n",
    "for block in uncoupled_blocks_3D:\n",
    "    nsample, nmi, nmj, _, nprop = block.values.shape\n",
    "    blocks_2Dy.append(\n",
    "        TensorBlock( values = block.values[...,0,:], \n",
    "                    components = [block.components[0],  block.components[1]],\n",
    "                    properties = block.properties,\n",
    "                      samples = block.samples,\n",
    "        ))\n",
    "    blocks_2Dz.append(\n",
    "        TensorBlock( values = block.values[...,1,:], \n",
    "                    components = [block.components[0],  block.components[1]],\n",
    "                    properties = block.properties,\n",
    "                    samples = block.samples,\n",
    "        ))\n",
    "    blocks_2Dx.append(\n",
    "        TensorBlock( values = block.values[...,2,:], \n",
    "                    components = [block.components[0],  block.components[1]],\n",
    "                    properties = block.properties,\n",
    "                    samples = block.samples,\n",
    "        ))\n",
    "uncoupled_blocks_2Dx = TensorMap( blocks.keys , blocks_2Dx)\n",
    "uncoupled_blocks_2Dy = TensorMap( blocks.keys , blocks_2Dy)\n",
    "uncoupled_blocks_2Dz = TensorMap( blocks.keys , blocks_2Dz)\n",
    "\n",
    "# uncoupled_blocks_2Dx = mts.remove_dimension(uncoupled_blocks_2Dx, 'samples', 'cell_shift_a') \n",
    "# uncoupled_blocks_2Dx = mts.remove_dimension(uncoupled_blocks_2Dx, 'samples', 'cell_shift_b') \n",
    "# uncoupled_blocks_2Dx = mts.remove_dimension(uncoupled_blocks_2Dx, 'samples', 'cell_shift_c') \n",
    "\n",
    "# uncoupled_blocks_2Dy = mts.remove_dimension(uncoupled_blocks_2Dy, 'samples', 'cell_shift_a') \n",
    "# uncoupled_blocks_2Dy = mts.remove_dimension(uncoupled_blocks_2Dy, 'samples', 'cell_shift_b') \n",
    "# uncoupled_blocks_2Dy = mts.remove_dimension(uncoupled_blocks_2Dy, 'samples', 'cell_shift_c') \n",
    "\n",
    "# uncoupled_blocks_2Dz = mts.remove_dimension(uncoupled_blocks_2Dz, 'samples', 'cell_shift_a') \n",
    "# uncoupled_blocks_2Dz = mts.remove_dimension(uncoupled_blocks_2Dz, 'samples', 'cell_shift_b') \n",
    "# uncoupled_blocks_2Dz = mts.remove_dimension(uncoupled_blocks_2Dz, 'samples', 'cell_shift_c') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupled_blocks_2Dx = _to_coupled_basis(uncoupled_blocks_2Dx, skip_symmetry = False, device = 'cpu', translations = None)\n",
    "coupled_blocks_2Dy = _to_coupled_basis(uncoupled_blocks_2Dy, skip_symmetry = False, device = 'cpu', translations = None)\n",
    "coupled_blocks_2Dz = _to_coupled_basis(uncoupled_blocks_2Dz, skip_symmetry = False, device = 'cpu', translations = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a tensor map from these three individually coupled tmaps, concatenating them along the components dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupled_blocks_2Dx = coupled_blocks_2Dx.keys_to_properties(['species_i', 'n_i', 'l_i','species_j', 'n_j', 'l_j'])\n",
    "coupled_blocks_2Dy = coupled_blocks_2Dy.keys_to_properties(['species_i', 'n_i', 'l_i','species_j', 'n_j', 'l_j'])\n",
    "coupled_blocks_2Dz = coupled_blocks_2Dz.keys_to_properties(['species_i', 'n_i', 'l_i','species_j', 'n_j', 'l_j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncoupled_2 = []\n",
    "for (bx,by,bz) in zip(coupled_blocks_2Dy.blocks(), coupled_blocks_2Dz.blocks(),coupled_blocks_2Dx.blocks()):\n",
    "    ## Assert that the blocks correspond to the same keys\n",
    "    assert bx.values.shape == by.values.shape == bz.values.shape\n",
    "    uncoupled_2.append( TensorBlock( values = torch.stack([bx.values, by.values,bz.values], dim=2), \n",
    "                                    components = [bx.components[0],position_components], \n",
    "                                    samples = bx.samples, \n",
    "                                    properties = bx.properties\n",
    "    ) )\n",
    "newkeys = Labels(coupled_blocks_2Dz.keys.names+['L2'], values = torch.nn.functional.pad(coupled_blocks_2Dz.keys.values, (0,1), mode='constant', value=1))\n",
    "uncoupled_2 = TensorMap(newkeys, uncoupled_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMap with 6 blocks\n",
       "keys: block_type  L  L2\n",
       "          0       0  1\n",
       "          0       1  1\n",
       "          0       2  1\n",
       "          1       0  1\n",
       "          2       0  1\n",
       "          2       1  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoupled_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _to_coupled_basis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8360],\n",
       "         [ 1.1375],\n",
       "         [ 0.0626]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupled_blocks[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1, 0, 1): {1: tensor([[[-0.8360,  1.1375,  0.0626]]])}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupled_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.symmetry import ClebschGordanReal\n",
    "CG = ClebschGordanReal(10, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def couple(decoupled, iterate = 0, cg=None, selfdevice= 'cpu', lmax=10):\n",
    "       \n",
    "        coupled = {}\n",
    "\n",
    "        # when called on a matrix, turns it into a dict form to which we can\n",
    "        # apply the generic algorithm\n",
    "        if not isinstance(decoupled, dict):\n",
    "            l2 = (decoupled.shape[-1] - 1) // 2\n",
    "            decoupled = {(): {l2: decoupled}}\n",
    "\n",
    "        # runs over the tuple of (partly) decoupled terms\n",
    "        for ltuple, lcomponents in decoupled.items():\n",
    "            # each is a list of L terms\n",
    "            for lc in lcomponents.keys():\n",
    "                # this is the actual matrix-valued coupled term,\n",
    "                # of shape (..., 2l1+1, 2l2+1), transforming as Y^m1_l1 Y^m2_l2\n",
    "                dec_term = lcomponents[lc]\n",
    "                l1 = (dec_term.shape[-2] - 1) // 2\n",
    "                l2 = (dec_term.shape[-1] - 1) // 2\n",
    "\n",
    "                # there is a certain redundance: the L value is also the last entry\n",
    "                # in ltuple\n",
    "                if lc != l2:\n",
    "                    raise ValueError(\n",
    "                        \"Inconsistent shape for coupled angular momentum block.\"\n",
    "                    )\n",
    "\n",
    "                # in the new coupled term, prepend (l1,l2) to the existing label\n",
    "                device = dec_term.device\n",
    "                if device != selfdevice:\n",
    "                    dec_term = dec_term.to(selfdevice)\n",
    "                \n",
    "                coupled[(l1, l2) + ltuple] = {}\n",
    "                for L in range(\n",
    "                    max(l1, l2) - min(l1, l2), min(lmax, (l1 + l2)) + 1\n",
    "                ):\n",
    "                    # Lterm = torch.einsum('spmn,mnM->spM', dec_term, self._cg[(l1, l2, L)])\n",
    "                    coupled[(l1, l2) + ltuple][L] = torch.tensordot(dec_term, cg._cg[(l1, l2, L)].to(dec_term), dims=2)\n",
    "\n",
    "        # repeat if required\n",
    "        if iterate > 0:\n",
    "            coupled = couple(coupled, iterate - 1, cg= cg, selfdevice=selfdevice,lmax=lmax)\n",
    "        return coupled\n",
    "\n",
    "def decouple(coupled, iterate: int = 0, cg=None, selfdevice= 'cpu', lmax=10 ):\n",
    "        decoupled = {}\n",
    "        # applies the decoupling to each entry in the dictionary\n",
    "        for ltuple, lcomponents in coupled.items():\n",
    "            # the initial pair in the key indicates the decoupled terms that generated\n",
    "            # the L entries\n",
    "            l1, l2 = ltuple[:2]\n",
    "            # shape of the coupled matrix (last entry is the 2L+1 M terms)\n",
    "            # if lcomponents == {}:\n",
    "            #     print(f'here,{ltuple}')\n",
    "            #     continue\n",
    "            shape = next(iter(lcomponents.values())).shape[:-1]\n",
    "            dtype_ = next(iter(lcomponents.values())).dtype\n",
    "\n",
    "            dec_term = torch.zeros(shape+ ( 2 * l1 + 1, 2 * l2 + 1),device=selfdevice, dtype = dtype_)\n",
    "            for L in range(max(l1, l2) - min(l1, l2), min(lmax, (l1 + l2)) + 1):\n",
    "                # supports missing L components, e.g. if they are zero because of symmetry\n",
    "                if L not in lcomponents:\n",
    "                    continue\n",
    "                # decouples the L term into m1, m2 components\n",
    "                # a = torch.einsum('spM,mnM->spmn', lcomponents[L], self._cg[(l1, l2, L)])\n",
    "                # dec_term+=torch.tensordot(lcomponents[L], self._cg[(l1, l2, L)].to(dtype_), dims=([2],[2]))\n",
    "                dec_term+=torch.tensordot(lcomponents[L], cg._cg[(l1, l2, L)].to(dtype_), dims=([-1],[-1])) #CHECK<<<<<< \n",
    "            if not ltuple[2:] in decoupled:\n",
    "                decoupled[ltuple[2:]] = {}\n",
    "            decoupled[ltuple[2:]][l2] = dec_term\n",
    "\n",
    "        # rinse, repeat\n",
    "        if iterate > 0:\n",
    "            decoupled = decouple(decoupled, iterate - 1,cg= cg, selfdevice=selfdevice,lmax=lmax)\n",
    "        # if we got a fully decoupled state, just return an array\n",
    "        if ltuple[2:] == ():\n",
    "            decoupled = next(iter(decoupled[()].values()))\n",
    "        return decoupled\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,5,7,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = couple(a, 1,cg = CG,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = decouple(b, 1, cg = CG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 7, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1898e-06)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(c - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = b.copy()\n",
    "bb[(2, 2, 3, 1)] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = decouple(bb, 1, cg = CG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3, 1)\n",
      "(2, 2, 3, 1) 0\n",
      "torch.Size([2, 6]) torch.Size([1, 1]) torch.Size([1, 1])\n",
      "(2, 2, 3, 1) 1\n",
      "torch.Size([2, 6]) torch.Size([1, 3]) torch.Size([3, 1])\n",
      "(2, 2, 3, 1) 2\n",
      "torch.Size([2, 6]) torch.Size([1, 5]) torch.Size([5, 1])\n",
      "(2, 2, 3, 1) 3\n",
      "torch.Size([2, 6]) torch.Size([1, 7]) torch.Size([7, 1])\n",
      "(2, 2, 3, 1) 4\n",
      "torch.Size([2, 6]) torch.Size([1, 9]) torch.Size([9, 1])\n",
      "(2, 3, 3, 1)\n",
      "(2, 3, 3, 1) 1\n",
      "torch.Size([2, 6]) torch.Size([1, 3]) torch.Size([3, 1])\n",
      "(2, 3, 3, 1) 2\n",
      "torch.Size([2, 6]) torch.Size([1, 5]) torch.Size([5, 1])\n",
      "(2, 3, 3, 1) 3\n",
      "torch.Size([2, 6]) torch.Size([1, 7]) torch.Size([7, 1])\n",
      "(2, 3, 3, 1) 4\n",
      "torch.Size([2, 6]) torch.Size([1, 9]) torch.Size([9, 1])\n",
      "(2, 3, 3, 1) 5\n",
      "torch.Size([2, 6]) torch.Size([1, 11]) torch.Size([11, 1])\n",
      "(2, 4, 3, 1)\n",
      "(2, 4, 3, 1) 2\n",
      "torch.Size([2, 6]) torch.Size([1, 5]) torch.Size([5, 1])\n",
      "(2, 4, 3, 1) 3\n",
      "torch.Size([2, 6]) torch.Size([1, 7]) torch.Size([7, 1])\n",
      "(2, 4, 3, 1) 4\n",
      "torch.Size([2, 6]) torch.Size([1, 9]) torch.Size([9, 1])\n",
      "(2, 4, 3, 1) 5\n",
      "torch.Size([2, 6]) torch.Size([1, 11]) torch.Size([11, 1])\n",
      "(2, 4, 3, 1) 6\n",
      "torch.Size([2, 6]) torch.Size([1, 13]) torch.Size([13, 1])\n"
     ]
    }
   ],
   "source": [
    "coupled = a\n",
    "for coupledkey in coupled:\n",
    "    k = coupledkey[1]\n",
    "    print(coupledkey)\n",
    "    for L in coupled[coupledkey]:\n",
    "        print(coupledkey, L)\n",
    "                    # block_idx = tuple(idx) + (k, L)\n",
    "                    # skip blocks that are zero because of symmetry - TBD \n",
    "                    # if ai == aj and ni == nj and li == lj:\n",
    "                    #     parity = (-1) ** (li + lj + L)\n",
    "                    #     if ((parity == -1 and block_type in (0, 1)) or (parity == 1 and block_type == -1)) and not skip_symmetry:\n",
    "                    #         continue\n",
    "                    \n",
    "        print(block.samples.values.shape, coupled[coupledkey][L].shape, torch.moveaxis(coupled[coupledkey][L], -1, -2).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
