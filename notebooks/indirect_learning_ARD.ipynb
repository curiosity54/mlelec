{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162d0473-d1cf-4306-9a2b-d03218bbfe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c52587-7c8f-4b08-8508-8d45b56d9250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pegolo/micromamba/envs/sci/lib/python3.11/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    }
   ],
   "source": [
    "import hickle\n",
    "\n",
    "from ase.io import read\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from mlelec.data.dataset import QMDataset\n",
    "from mlelec.data.mldataset import MLDataset\n",
    "from mlelec.models.linear_integrated import LinearModelPeriodic\n",
    "from mlelec.utils.pbc_utils import blocks_to_matrix\n",
    "from mlelec.utils.twocenter_utils import _to_uncoupled_basis, unfix_orbital_order\n",
    "from mlelec.metrics import Eigval_loss, L2_loss_meanzero, L2_loss\n",
    "import metatensor.torch as mts\n",
    "from metatensor.learn import DataLoader\n",
    "\n",
    "import os\n",
    "os.environ[\"PYSCFAD_BACKEND\"] = \"torch\"\n",
    "from pyscf import gto\n",
    "from pyscfad import numpy as pynp\n",
    "from pyscfad import ops\n",
    "from pyscfad.ml.scf import hf\n",
    "import pyscf.pbc.tools.pyscf_ase as pyscf_ase\n",
    "from mlelec.data.pyscf_calculator import _instantiate_pyscf_mol\n",
    "\n",
    "import xitorch\n",
    "from xitorch.linalg import symeig\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.utils import io as ipy_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aaccef1-cad2-4284-9537-af28fa5b67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eigval_vec(dataset, batch, Hk, return_rho = False, return_eigenvectors = False):\n",
    "    eig = []\n",
    "    rho = []\n",
    "    eigvec = []\n",
    "    for A, H, S in zip(batch.sample_id, Hk, batch.overlap_realspace):\n",
    "        # Compute eigenvalues and eigenvectors\n",
    "        # eigvals, eigvecs = symeig(Ax, M = Mx)\n",
    "        eigvals, C = symeig(xitorch.LinearOperator.m(H), M = xitorch.LinearOperator.m(S))\n",
    "        if return_rho:\n",
    "            frame = dataset.structures[A]\n",
    "            natm = len(frame)\n",
    "            ncore = sum(dataset.ncore[s] for s in frame.numbers)\n",
    "            nelec = sum(frame.numbers) - ncore\n",
    "            occ = torch.tensor([2.0 if i < nelec//2 else 0.0 for i in range(C.shape[-1])], dtype = torch.float64, requires_grad = True, device = device)\n",
    "            # occ = torch.tensor([2.0 for i in range(C.shape[-1])], dtype = torch.float64, requires_grad = True, device = device)\n",
    "            rho.append(torch.einsum('n,...in,...jn->ij...', occ, C, C.conj()))\n",
    "        eig.append(eigvals)\n",
    "        if return_eigenvectors:\n",
    "            eigvec.append(C)\n",
    "\n",
    "    to_return = [eig]\n",
    "    if return_rho:\n",
    "        try:\n",
    "            rho = torch.stack(rho)\n",
    "        except:\n",
    "            pass\n",
    "        to_return.append(rho)\n",
    "    if return_eigenvectors:\n",
    "        try:\n",
    "            eigvec = torch.stack(eigvec)\n",
    "        except:\n",
    "            pass\n",
    "        to_return.append(eigvec)\n",
    "    return tuple(to_return)\n",
    "\n",
    "def compute_ard_vec(dataset, batch, HT, device, overlap = None):\n",
    "    basis = dataset.basis\n",
    "    ard_ = []\n",
    "    eig = []\n",
    "    Cs = []\n",
    "    rhos = []\n",
    "\n",
    "    overlap = batch.overlap_realspace if overlap is None else overlap\n",
    "    \n",
    "    for A, H, S in zip(batch.sample_id, HT, overlap):\n",
    "        frame = dataset.structures[A]\n",
    "        natm = len(frame)\n",
    "        ncore = sum(dataset.ncore[s] for s in frame.numbers)\n",
    "        nelec = sum(frame.numbers) - ncore\n",
    "        split_idx = [len(basis[s]) for s in frame.numbers]\n",
    "        needed = True if len(np.unique(split_idx)) > 1 else False\n",
    "        \n",
    "        max_dim = np.max(split_idx)\n",
    "        \n",
    "        eigvals, C = symeig(xitorch.LinearOperator.m(H), M=xitorch.LinearOperator.m(S), return_eigenvectors = True) # Has shape = (n_k, N, N)\n",
    "        \n",
    "        occ = torch.tensor([2.0 if i < nelec//2 else 0.0 for i in range(C.shape[-1])], dtype = torch.float64, requires_grad = True, device = device)\n",
    "        P = torch.einsum('n,...in,...jn->ij...', occ, C, C.conj())\n",
    "        rhos.append(P)\n",
    "        \n",
    "        slices = torch.split(P, split_idx, dim=0)\n",
    "        blocks = [torch.split(slice_, split_idx, dim=1) for slice_ in slices]\n",
    "        blocks_flat = [block for sublist in blocks for block in sublist]\n",
    "        \n",
    "        if needed:\n",
    "            squared_blocks = []\n",
    "            for block in blocks_flat:\n",
    "                pad_size = (0, max_dim - block.size(1), 0, max_dim - block.size(0))\n",
    "                squared_block = torch.nn.functional.pad(block, pad_size, \"constant\", 0)\n",
    "                squared_blocks.append(squared_block)\n",
    "            blocks_flat = squared_blocks\n",
    "\n",
    "\n",
    "        ard_.append(torch.stack(blocks_flat).norm(dim=(1,2)))\n",
    "        eig.append(eigvals)\n",
    "        Cs.append(C)\n",
    "\n",
    "    try:\n",
    "        ard_ = torch.stack(ard_)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        eig = torch.stack(eig)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        rhos = torch.stack(rhos)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        Cs = torch.stack(Cs)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return eig, ard_, Cs, rhos\n",
    "\n",
    "def compute_dipole_moment(frames, fock_predictions, overlaps, basis = 'sto-3g'):\n",
    "    assert (\n",
    "        len(frames) == len(fock_predictions) == len(overlaps)\n",
    "    ), \"Length of frames, fock_predictions, and overlaps must be the same\"\n",
    "    dipoles = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        mol = _instantiate_pyscf_mol(frame, basis = basis)\n",
    "        mf = hf.SCF(mol)\n",
    "        fock = torch.autograd.Variable(\n",
    "            fock_predictions[i].type(torch.float64), requires_grad=True\n",
    "        )\n",
    "\n",
    "        mo_energy, mo_coeff = mf.eig(fock, overlaps[i])\n",
    "        mo_occ = mf.get_occ(mo_energy)  # get_occ returns a numpy array\n",
    "        mo_occ = ops.convert_to_tensor(mo_occ)\n",
    "        dm1 = mf.make_rdm1(mo_coeff, mo_occ)\n",
    "        dip = mf.dip_moment(dm=dm1)\n",
    "        dipoles.append(dip)\n",
    "    return torch.stack(dipoles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d52ddf-8bd5-4385-802a-c533ac4f1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbitals = {\n",
    "    'sto-3g': {1: [[1,0,0]], \n",
    "               5: [[1,0,0],[2,0,0],[2,1,-1], [2,1,0],[2,1,1]], \n",
    "               6: [[1,0,0],[2,0,0],[2,1,-1], [2,1,0],[2,1,1]], \n",
    "               7: [[1,0,0],[2,0,0],[2,1,-1], [2,1,0],[2,1,1]],\n",
    "               8: [[1,0,0],[2,0,0],[2,1,-1], [2,1,0],[2,1,1]]\n",
    "               }, \n",
    "    \n",
    "    'def2svp': {1: [[1,0,0],[2,0,0],[2,1,-1], [2,1,0],[2,1,1]],\n",
    "                6: [[1,0,0],[2,0,0],[3,0,0],[2,1,1], [2,1,-1],[2,1,0], [3,1,1], [3,1,-1],[3,1,0], [3,2,-2], [3,2,-1],[3,2,0], [3,2,1],[3,2,2]],\n",
    "                8: [[1,0,0],[2,0,0],[3,0,0],[2,1,1], [2,1,-1],[2,1,0], [3,1,1], [3,1,-1],[3,1,0], [3,2,-2], [3,2,-1],[3,2,0], [3,2,1],[3,2,2]]\n",
    "                },\n",
    "}\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4998d7ce-9947-4561-8ed0-5e1aa203aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_radial  = 12\n",
    "max_angular = 6\n",
    "atomic_gaussian_width = 0.3\n",
    "cutoff = 3.5\n",
    "\n",
    "hypers_pair = {'cutoff': cutoff,\n",
    "               'max_radial': max_radial,\n",
    "               'max_angular': max_angular,\n",
    "               'atomic_gaussian_width': atomic_gaussian_width,\n",
    "               'center_atom_weight': 1,\n",
    "               \"radial_basis\": {\"Gto\": {}},\n",
    "               \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}}}\n",
    "\n",
    "hypers_atom = {'cutoff': cutoff,\n",
    "               'max_radial': max_radial,\n",
    "               'max_angular': max_angular,\n",
    "               'atomic_gaussian_width': 0.5,\n",
    "               'center_atom_weight': 1,\n",
    "               \"radial_basis\": {\"Gto\": {}},\n",
    "               \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}}}\n",
    "\n",
    "\n",
    "return_rho0ij = False\n",
    "both_centers = False\n",
    "LCUT = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d5bfc3-c835-45de-b318-c96150bfafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = '../examples/data/water_1000'\n",
    "every = 50\n",
    "frames = read(f'{workdir}/water_1000.xyz', f'::{every}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6d217-5003-47a7-bfd8-73acd29687cc",
   "metadata": {},
   "source": [
    "For the moment, we need to create multiple QMDataset (analogous to MoleculeDataset), one for the large basis, one for the small one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e3b2cb6-7c1f-416c-aaf7-7f3ebdaabcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fock = torch.from_numpy(np.load(f'{workdir}/def2svp/focks.npy', allow_pickle = True)[::every].astype(np.float64))\n",
    "over = torch.from_numpy(np.load(f'{workdir}/def2svp/overlaps.npy', allow_pickle=True)[::every].astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a37f4f5-6679-41c5-b01f-5b8243c87201",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmdata = QMDataset(frames = frames, \n",
    "                   dimension = 0,            # For molecules\n",
    "                   fock_realspace=fock.clone(),\n",
    "                   overlap_realspace=over.clone(),\n",
    "                   device = device, \n",
    "                   orbs = orbitals['def2svp'], \n",
    "                   orbs_name = 'def2svp',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be02c4fe-273e-46b5-9c04-7dae558b62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fock_small = hickle.load(f'{workdir}/sto-3g/fock.hickle')[::every]\n",
    "over_small = hickle.load(f'{workdir}/sto-3g/overlap.hickle')[::every]\n",
    "\n",
    "qmdata_sto3G = QMDataset(frames = frames, \n",
    "                         dimension = 0,\n",
    "                         fock_realspace=fock_small.clone(),\n",
    "                         overlap_realspace=over_small.clone(),\n",
    "                         device = device, \n",
    "                         orbs = orbitals['sto-3g'], \n",
    "                         orbs_name = 'sto-3g'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9ffb89-465f-44a3-806a-dd0b244aeba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu pair features\n",
      "cpu single center features\n",
      "cpu single center features\n"
     ]
    }
   ],
   "source": [
    "from mlelec.data.mldataset import MLDataset\n",
    "mldata = MLDataset(qmdata, \n",
    "                   item_names = ['fock_blocks', 'fock_realspace', 'overlap_realspace', 'eigenvalues', 'atom_resolved_density'],\n",
    "                   # features = mldata.features,\n",
    "                   cutoff = hypers_pair['cutoff'],\n",
    "                   hypers_atom = hypers_atom,\n",
    "                   hypers_pair = hypers_pair,\n",
    "                   lcut = 3,\n",
    "                   orbitals_to_properties = True,\n",
    "                   train_frac = 1,\n",
    "                   shuffle = False,\n",
    "                   model_basis = orbitals['sto-3g'],\n",
    "                   fix_p_orbital_order=True\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93531df-4e44-4dd8-8136-0d3595f342c5",
   "metadata": {},
   "source": [
    "The following cell is required to compute the metadata used to initialize the model (i.e., the model's submodels info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3b0e4-6227-46ae-b476-0b9ddc6db7c6",
   "metadata": {},
   "source": [
    "Instantiate the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0391ccbe-8be6-4084-991f-e1ab64a0f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(mldata.train_dataset, batch_size = 10, collate_fn = mldata.group_and_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dca2cf-2183-4b8e-820e-5a10e9e5a8b5",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abada533-7c2b-423c-bd6c-46516fc8fe74",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab9aa9e-f265-45b1-95c9-1c1b942c0eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = LinearModelPeriodic(twocfeat = mldata.features, \n",
    "                            target_blocks = mldata.model_metadata,\n",
    "                            frames = mldata.structures, \n",
    "                            orbitals = mldata.model_basis, \n",
    "                            device = device,\n",
    "                            nhidden = 4, \n",
    "                            nlayers = 1,\n",
    "                            activation = 'SiLU',\n",
    "                           apply_norm = True\n",
    "                           )\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b675a52-d827-434f-8bbc-797befc39cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-3, weight_decay = 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.8, patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2058f772-1313-49cd-bb3d-24b8f5bd7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N. of eigenvalues to match (this needs to be adapted for diverse datasets\n",
    "n_eig_to_match = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b28a8-9604-455f-a645-f5754a1a9bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch       0, train loss  126.5398719438; rmse_eig=0.2162972545 rmse_evec=0.0811165367 rmse_ard=0.2413048385 \n",
      "Epoch       1, train loss  124.8229157671; rmse_eig=0.2134879924 rmse_evec=0.0810009574 rmse_ard=0.2402433566 \n",
      "Epoch       2, train loss  123.1264185427; rmse_eig=0.2106375977 rmse_evec=0.0808875833 rmse_ard=0.2392082130 \n",
      "Epoch       3, train loss  121.4514259631; rmse_eig=0.2077840360 rmse_evec=0.0807701110 rmse_ard=0.2381832464 \n",
      "Epoch       4, train loss  119.7977138484; rmse_eig=0.2049590447 rmse_evec=0.0806416119 rmse_ard=0.2371542661 \n",
      "Epoch       5, train loss  118.1647175397; rmse_eig=0.2021758826 rmse_evec=0.0804960378 rmse_ard=0.2361157876 \n",
      "Epoch       6, train loss  116.5522874737; rmse_eig=0.1994261748 rmse_evec=0.0803281337 rmse_ard=0.2350732168 \n",
      "Epoch       7, train loss  114.9599272975; rmse_eig=0.1966863846 rmse_evec=0.0801310842 rmse_ard=0.2340386774 \n",
      "Epoch       8, train loss  113.3857901981; rmse_eig=0.1939306325 rmse_evec=0.0798936008 rmse_ard=0.2330237948 \n",
      "Epoch       9, train loss  111.8273244476; rmse_eig=0.1911444583 rmse_evec=0.0796012523 rmse_ard=0.2320339921 \n",
      "Epoch      10, train loss  110.2837886715; rmse_eig=0.1883343507 rmse_evec=0.0792487247 rmse_ard=0.2310658250 \n",
      "Epoch      11, train loss  108.7585286286; rmse_eig=0.1855291616 rmse_evec=0.0788577264 rmse_ard=0.2301069196 \n",
      "Epoch      12, train loss  107.2566441259; rmse_eig=0.1827682268 rmse_evec=0.0784654920 rmse_ard=0.2291406009 \n",
      "Epoch      13, train loss  105.7794771384; rmse_eig=0.1800755991 rmse_evec=0.0780819569 rmse_ard=0.2281572716 \n",
      "Epoch      14, train loss  104.3247407774; rmse_eig=0.1774405229 rmse_evec=0.0776850872 rmse_ard=0.2271634434 \n",
      "Epoch      15, train loss  102.8896872195; rmse_eig=0.1748255546 rmse_evec=0.0772509124 rmse_ard=0.2261764687 \n",
      "Epoch      16, train loss  101.4730116817; rmse_eig=0.1721960706 rmse_evec=0.0767761164 rmse_ard=0.2252100326 \n",
      "Epoch      17, train loss  100.0775148867; rmse_eig=0.1695494379 rmse_evec=0.0762939350 rmse_ard=0.2242631356 \n",
      "Epoch      18, train loss   98.7089117421; rmse_eig=0.1669209951 rmse_evec=0.0758612184 rmse_ard=0.2233191496 \n",
      "Epoch      19, train loss   97.3695588557; rmse_eig=0.1643549347 rmse_evec=0.0755073932 rmse_ard=0.2223586162 \n",
      "Epoch      20, train loss   96.0576022679; rmse_eig=0.1618607736 rmse_evec=0.0752151045 rmse_ard=0.2213792383 \n",
      "Epoch      21, train loss   94.7706719925; rmse_eig=0.1593988008 rmse_evec=0.0749543507 rmse_ard=0.2204001508 \n",
      "Epoch      22, train loss   93.5049308626; rmse_eig=0.1569067781 rmse_evec=0.0747036337 rmse_ard=0.2194447459 \n",
      "Epoch      23, train loss   92.2549234618; rmse_eig=0.1543422031 rmse_evec=0.0744462826 rmse_ard=0.2185239495 \n",
      "Epoch      24, train loss   91.0169861159; rmse_eig=0.1517074091 rmse_evec=0.0741666588 rmse_ard=0.2176329752 \n",
      "Epoch      25, train loss   89.7902055045; rmse_eig=0.1490428625 rmse_evec=0.0738540064 rmse_ard=0.2167558377 \n",
      "Epoch      26, train loss   88.5743470889; rmse_eig=0.1463998612 rmse_evec=0.0735094468 rmse_ard=0.2158721017 \n",
      "Epoch      27, train loss   87.3689972040; rmse_eig=0.1438143779 rmse_evec=0.0731463975 rmse_ard=0.2149654698 \n",
      "Epoch      28, train loss   86.1743821611; rmse_eig=0.1412945516 rmse_evec=0.0727800748 rmse_ard=0.2140312647 \n",
      "Epoch      29, train loss   84.9914531016; rmse_eig=0.1388216936 rmse_evec=0.0724179533 rmse_ard=0.2130773123 \n",
      "Epoch      30, train loss   83.8208491996; rmse_eig=0.1363620358 rmse_evec=0.0720622139 rmse_ard=0.2121169672 \n",
      "Epoch      31, train loss   82.6624757458; rmse_eig=0.1338841191 rmse_evec=0.0717182020 rmse_ard=0.2111603351 \n",
      "Epoch      32, train loss   81.5159641839; rmse_eig=0.1313716585 rmse_evec=0.0713949479 rmse_ard=0.2102104818 \n",
      "Epoch      33, train loss   80.3806331883; rmse_eig=0.1288236184 rmse_evec=0.0710953968 rmse_ard=0.2092655296 \n",
      "Epoch      34, train loss   79.2556279158; rmse_eig=0.1262437379 rmse_evec=0.0708163663 rmse_ard=0.2083227941 \n",
      "Epoch      35, train loss   78.1401232524; rmse_eig=0.1236319588 rmse_evec=0.0705533591 rmse_ard=0.2073811793 \n",
      "Epoch      36, train loss   77.0334991250; rmse_eig=0.1209837148 rmse_evec=0.0703026752 rmse_ard=0.2064412057 \n",
      "Epoch      37, train loss   75.9354019366; rmse_eig=0.1182941274 rmse_evec=0.0700620365 rmse_ard=0.2055035319 \n",
      "Epoch      38, train loss   74.8457451047; rmse_eig=0.1155626515 rmse_evec=0.0698301826 rmse_ard=0.2045675663 \n",
      "Epoch      39, train loss   73.7647626810; rmse_eig=0.1127945608 rmse_evec=0.0696062671 rmse_ard=0.2036313499 \n",
      "Epoch      40, train loss   72.6930301896; rmse_eig=0.1099987837 rmse_evec=0.0693894789 rmse_ard=0.2026925087 \n",
      "Epoch      41, train loss   71.6314241801; rmse_eig=0.1071844807 rmse_evec=0.0691789044 rmse_ard=0.2017493584 \n",
      "Epoch      42, train loss   70.5810779848; rmse_eig=0.1043590909 rmse_evec=0.0689735007 rmse_ard=0.2008014274 \n",
      "Epoch      43, train loss   69.5433286301; rmse_eig=0.1015287990 rmse_evec=0.0687720606 rmse_ard=0.1998492035 \n",
      "Epoch      44, train loss   68.5196310752; rmse_eig=0.0987003796 rmse_evec=0.0685731237 rmse_ard=0.1988934676 \n",
      "Epoch      45, train loss   67.5114729844; rmse_eig=0.0958827075 rmse_evec=0.0683748940 rmse_ard=0.1979347837 \n",
      "Epoch      46, train loss   66.5203220360; rmse_eig=0.0930870588 rmse_evec=0.0681752806 rmse_ard=0.1969733952 \n",
      "Epoch      47, train loss   65.5476025271; rmse_eig=0.0903265689 rmse_evec=0.0679721490 rmse_ard=0.1960093550 \n",
      "Epoch      48, train loss   64.5946981554; rmse_eig=0.0876156468 rmse_evec=0.0677638173 rmse_ard=0.1950426395 \n",
      "Epoch      49, train loss   63.6629968193; rmse_eig=0.0849696059 rmse_evec=0.0675499212 rmse_ard=0.1940731824 \n",
      "Epoch      50, train loss   62.7540230422; rmse_eig=0.0824039801 rmse_evec=0.0673331747 rmse_ard=0.1931009472 \n",
      "Epoch      51, train loss   61.8696821695; rmse_eig=0.0799326785 rmse_evec=0.0671222065 rmse_ard=0.1921262302 \n",
      "Epoch      52, train loss   61.0119438699; rmse_eig=0.0775649541 rmse_evec=0.0669283613 rmse_ard=0.1911503222 \n",
      "Epoch      53, train loss   60.1807283769; rmse_eig=0.0753039409 rmse_evec=0.0667451368 rmse_ard=0.1901758158 \n",
      "Epoch      54, train loss   59.3742035935; rmse_eig=0.0731497699 rmse_evec=0.0665535986 rmse_ard=0.1892051858 \n",
      "Epoch      55, train loss   58.5916312999; rmse_eig=0.0711026429 rmse_evec=0.0663504715 rmse_ard=0.1882397529 \n",
      "Epoch      56, train loss   57.8328309823; rmse_eig=0.0691635258 rmse_evec=0.0661402319 rmse_ard=0.1872801157 \n",
      "Epoch      57, train loss   57.0974211679; rmse_eig=0.0673342483 rmse_evec=0.0659264452 rmse_ard=0.1863264449 \n",
      "Epoch      58, train loss   56.3847578289; rmse_eig=0.0656165561 rmse_evec=0.0657111332 rmse_ard=0.1853786842 \n",
      "Epoch      59, train loss   55.6940181583; rmse_eig=0.0640108557 rmse_evec=0.0654953441 rmse_ard=0.1844368199 \n",
      "Epoch      60, train loss   55.0242596946; rmse_eig=0.0625158503 rmse_evec=0.0652794628 rmse_ard=0.1835009610 \n",
      "Epoch      61, train loss   54.3744310239; rmse_eig=0.0611292215 rmse_evec=0.0650633553 rmse_ard=0.1825711685 \n",
      "Epoch      62, train loss   53.7434021640; rmse_eig=0.0598484325 rmse_evec=0.0648465056 rmse_ard=0.1816473209 \n",
      "Epoch      63, train loss   53.1300200954; rmse_eig=0.0586708154 rmse_evec=0.0646281618 rmse_ard=0.1807291731 \n",
      "Epoch      64, train loss   52.5331397869; rmse_eig=0.0575929531 rmse_evec=0.0644074347 rmse_ard=0.1798165096 \n",
      "Epoch      65, train loss   51.9516462767; rmse_eig=0.0566099151 rmse_evec=0.0641833505 rmse_ard=0.1789093080 \n",
      "Epoch      66, train loss   51.3845024083; rmse_eig=0.0557148961 rmse_evec=0.0639549564 rmse_ard=0.1780078680 \n",
      "Epoch      67, train loss   50.8307963160; rmse_eig=0.0548994842 rmse_evec=0.0637215362 rmse_ard=0.1771128138 \n",
      "Epoch      68, train loss   50.2897547378; rmse_eig=0.0541543312 rmse_evec=0.0634828443 rmse_ard=0.1762249672 \n",
      "Epoch      69, train loss   49.7607228203; rmse_eig=0.0534697254 rmse_evec=0.0632391977 rmse_ard=0.1753452085 \n",
      "Epoch      70, train loss   49.2431197187; rmse_eig=0.0528357743 rmse_evec=0.0629913711 rmse_ard=0.1744743976 \n",
      "Epoch      71, train loss   48.7363915356; rmse_eig=0.0522423787 rmse_evec=0.0627403625 rmse_ard=0.1736133479 \n",
      "Epoch      72, train loss   48.2399971756; rmse_eig=0.0516794542 rmse_evec=0.0624871439 rmse_ard=0.1727628228 \n",
      "Epoch      73, train loss   47.7534312032; rmse_eig=0.0511376824 rmse_evec=0.0622325011 rmse_ard=0.1719235008 \n",
      "Epoch      74, train loss   47.2762529860; rmse_eig=0.0506095887 rmse_evec=0.0619770010 rmse_ard=0.1710958749 \n",
      "Epoch      75, train loss   46.8081002117; rmse_eig=0.0500903667 rmse_evec=0.0617210133 rmse_ard=0.1702801563 \n",
      "Epoch      76, train loss   46.3486795843; rmse_eig=0.0495779649 rmse_evec=0.0614646673 rmse_ard=0.1694762677 \n",
      "Epoch      77, train loss   45.8977344622; rmse_eig=0.0490724839 rmse_evec=0.0612077063 rmse_ard=0.1686839189 \n",
      "Epoch      78, train loss   45.4550079964; rmse_eig=0.0485754301 rmse_evec=0.0609493336 rmse_ard=0.1679026939 \n"
     ]
    }
   ],
   "source": [
    "nepoch = 1000\n",
    "losses = []\n",
    "losses_e = []\n",
    "losses_ard = []\n",
    "losses_evec = []\n",
    "\n",
    "for epoch in range(nepoch):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_e = 0\n",
    "    epoch_loss_evec = 0\n",
    "    epoch_loss_ard = 0\n",
    "    eig_sum = 0\n",
    "    \n",
    "\n",
    "    for ib, batch in enumerate(dl):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model.forward(batch.features, mldata.model_metadata)\n",
    "\n",
    "        HT = blocks_to_matrix(pred, qmdata_sto3G, detach = False)\n",
    "        HT = [HT[i][0,0,0] for i in batch.sample_id] # Required for now\n",
    "\n",
    "        pred_eigvals, pred_ard, pred_C, _ = compute_ard_vec(qmdata_sto3G, batch, HT, device, overlap = [qmdata_sto3G.overlap_realspace[i] for i in batch.sample_id])\n",
    "\n",
    "        loss_e = Eigval_loss(pred_eigvals[:, :n_eig_to_match], batch.eigenvalues[:, :n_eig_to_match])\n",
    "        \n",
    "        loss_ard = torch.sum((pred_ard - batch.atom_resolved_density)**2)\n",
    "        \n",
    "        pred_ev_0 = torch.norm(pred_C[:, :, :n_eig_to_match], dim = (1))\n",
    "        targ_ev_0 = torch.norm(batch.eigenvectors[:, :, :n_eig_to_match], dim = (1))\n",
    "        loss_evec = torch.sum((pred_ev_0 - targ_ev_0)**2)\n",
    "        \n",
    "        loss = loss_ard + loss_e + loss_evec\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss_e += loss_e.item()\n",
    "        epoch_loss_evec += loss_evec.item()\n",
    "        epoch_loss_ard += loss_ard.item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    scheduler.step(epoch_loss)\n",
    "    losses.append(epoch_loss)\n",
    "    losses_e.append(epoch_loss_e)\n",
    "    losses_evec.append(epoch_loss_evec)\n",
    "    losses_ard.append(epoch_loss_ard)\n",
    "    \n",
    "    if epoch >= 0: #% 10 == 0:\n",
    "        print(f\"Epoch {epoch:>7d}, train loss {epoch_loss:>15.10f}; rmse_eig={np.sqrt(epoch_loss_e/5/160):>12.10f} rmse_evec={np.sqrt(epoch_loss_evec/5/160):>12.10f} rmse_ard={np.sqrt(epoch_loss_ard/160/9):>12.10f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "966b60fd-d959-4820-b030-96042b1f5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.forward(batch.features, mldata.model_metadata)\n",
    "HT = blocks_to_matrix(pred, qmdata_sto3G, detach = False)\n",
    "HT = [HT[i][0,0,0] for i in batch.sample_id] # Required for now\n",
    "\n",
    "pred_eigvals, pred_ard, pred_C, _ = compute_ard_vec(qmdata_sto3G, batch, HT, device, overlap = [qmdata_sto3G.overlap_realspace[i] for i in batch.sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d42b83a1-a15b-48ee-8a26-519e37636e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n"
     ]
    }
   ],
   "source": [
    "print(batch.atom_resolved_density.shape)\n",
    "print(pred_ard.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58876e0-efb2-4174-8380-331772bcf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(mldata.test_dataset, batch_size = len(mldata.test_dataset), collate_fn=mldata.group_and_join)\n",
    "train_dl = DataLoader(mldata.train_dataset, batch_size = len(mldata.train_dataset), collate_fn=mldata.group_and_join)\n",
    "\n",
    "fig_e, ax_e = plt.subplots()\n",
    "fig_a, ax_a = plt.subplots()\n",
    "fig_evec, ax_evec = plt.subplots()\n",
    "\n",
    "data = {}\n",
    "for dl_, lbl in zip([train_dl, test_dl], ['train', 'test']):\n",
    "    batch = next(iter(dl_))\n",
    "    pred = model(batch.features, mldata.model_metadata)\n",
    "\n",
    "    HT = blocks_to_matrix(pred, qmdata, detach = True)\n",
    "    HT = [HT[i][0,0,0] for i in batch.sample_id]\n",
    "    \n",
    "    pred_eigvals, pred_ard, pred_eigvec, pred_rho = compute_ard_vec(qmdata, batch, HT, device, overlap = [qmdata.overlap_realspace[i] for i in batch.sample_id])\n",
    "\n",
    "    ax_e.plot(batch.eigenvalues[:,:n_eig_to_match].flatten(), pred_eigvals[:,:n_eig_to_match].detach().flatten(), '.', label = lbl)\n",
    "    ax_e.plot([-21, 2], [-21, 2], 'k')\n",
    "    ax_e.set_title('Eigenvalues')\n",
    "    ax_e.legend()\n",
    "\n",
    "    ax_a.plot(batch.atom_resolved_density.flatten(), pred_ard.detach().flatten(), '.', label = lbl)\n",
    "    ax_a.plot([0,7], [0,7], 'k')\n",
    "    ax_a.set_title('Mayer bond charges')\n",
    "    ax_a.legend()\n",
    "\n",
    "    pred_evn, targ_evn = torch.norm(pred_eigvec[:, :, :n_eig_to_match], dim = (1)), torch.norm(batch.eigenvectors[:, :, :n_eig_to_match], dim = (1))\n",
    "    \n",
    "    ax_evec.plot(targ_evn.flatten(), pred_evn.detach().flatten(), '.', label = lbl)\n",
    "    xmin, xmax = ax_evec.get_xlim()\n",
    "    ymin, ymax = ax_evec.get_ylim()\n",
    "    xmin = np.min([xmin,ymin])\n",
    "    xmax = np.max([xmax,ymax])\n",
    "    ax_evec.plot([xmin,xmax], [xmin,xmax], 'k')\n",
    "    ax_evec.set_title('evec')\n",
    "    ax_evec.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617430a-3515-4204-aa44-c9b8d0029e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_dl))\n",
    "print(batch.sample_id)\n",
    "dl_frames = [qmdata.structures[A] for A in batch.sample_id]\n",
    "\n",
    "pred = model(batch.features, mldata.model_metadata)\n",
    "\n",
    "HT = blocks_to_matrix(pred, qmdata, detach = True)\n",
    "HT = [HT[i][0,0,0] for i in batch.sample_id]\n",
    "\n",
    "fock_predictions = torch.stack(HT)\n",
    "\n",
    "fock_predictions = unfix_orbital_order(\n",
    "    fock_predictions,\n",
    "    dl_frames,\n",
    "    qmdata_sto3G.basis,\n",
    ")\n",
    "\n",
    "fock_targets = unfix_orbital_order(\n",
    "    batch.fock_realspace,\n",
    "    dl_frames,\n",
    "    mldata.qmdata.basis,\n",
    ")\n",
    "\n",
    "fock_sto3g = unfix_orbital_order(\n",
    "    qmdata_sto3G.fock_realspace,\n",
    "    dl_frames,\n",
    "    qmdata_sto3G.basis,\n",
    ")\n",
    "\n",
    "over_large = unfix_orbital_order(\n",
    "    batch.overlap_realspace,\n",
    "    dl_frames,\n",
    "    mldata.qmdata.basis,\n",
    ")\n",
    "\n",
    "over_small = unfix_orbital_order(\n",
    "    torch.stack([qmdata_sto3G.overlap_realspace[i] for i in batch.sample_id]),\n",
    "    dl_frames,\n",
    "    qmdata_sto3G.basis,\n",
    ")\n",
    "\n",
    "with ipy_io.capture_output():\n",
    "    dipole_targets = compute_dipole_moment(\n",
    "        dl_frames,\n",
    "        fock_targets,\n",
    "        over_large,\n",
    "        qmdata.basis_name\n",
    "    )\n",
    "\n",
    "with ipy_io.capture_output():\n",
    "    dipole_predictions = compute_dipole_moment(\n",
    "        dl_frames,\n",
    "        fock_predictions,\n",
    "        over_small,\n",
    "        qmdata_sto3G.basis_name\n",
    "    )\n",
    "\n",
    "with ipy_io.capture_output():\n",
    "    dipole_sto3g = compute_dipole_moment(\n",
    "        dl_frames,\n",
    "        fock_sto3g,\n",
    "        over_small,\n",
    "        qmdata_sto3G.basis_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60168fff-f183-4a70-b20c-daa9987beee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.units import Bohr, Debye\n",
    "au_to_debye = Bohr/Debye\n",
    "\n",
    "ms = 12\n",
    "mew = .7\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = dipole_targets.flatten().detach().cpu() * au_to_debye\n",
    "y_sto3g = dipole_sto3g.flatten().detach().cpu() * au_to_debye\n",
    "y_ml = dipole_predictions.flatten().detach().cpu() * au_to_debye\n",
    "\n",
    "rmse_sto3g = np.sqrt(torch.mean(y_sto3g - x)**2)\n",
    "rmse_ml = np.sqrt(torch.mean(y_ml - x)**2)\n",
    "\n",
    "ax.plot(x, y_sto3g, 'v', \n",
    "         markeredgewidth = mew,\n",
    "         markeredgecolor = 'k',\n",
    "         markersize = ms, \n",
    "         label = 'STO-3G', \n",
    "         alpha = 1)\n",
    "\n",
    "ax.plot(x, y_ml, 'o',\n",
    "         markeredgewidth = mew,\n",
    "         markeredgecolor = 'k',\n",
    "         markersize = ms, \n",
    "         label = 'ML', \n",
    "         alpha = 1)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "xm, xM = ax.get_xlim()\n",
    "ym, yM = ax.get_ylim()\n",
    "m = np.min([xm,ym])\n",
    "M = np.max([xM,yM])\n",
    "ax.plot([m,M], [m,M], '--k')\n",
    "ax.set_xlim(m, M)\n",
    "ax.set_ylim(m, M)\n",
    "\n",
    "ax.text(0.6, 0.3, fr'$\\mathrm{{RMSE_{{\\text{{STO-3G}}}}}}={rmse_sto3g:.3f}\\,$D', transform = ax.transAxes, ha = 'left')\n",
    "ax.text(0.6, 0.25, f'$\\mathrm{{RMSE_{{ML}}}}={rmse_ml:.3f}\\,$D', transform = ax.transAxes, ha = 'left')\n",
    "\n",
    "ax.set_xlabel('Target dipoles (D)')\n",
    "ax.set_ylabel('Predicted dipoles (D)')\n",
    "\n",
    "# ax.set_title('Indirect training from def2-svp to a STO-3G-like model.\\nTargets: eigenvalues; ARD; eigenvector norms over AOs\\nTest set contains 50 water molecules')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
