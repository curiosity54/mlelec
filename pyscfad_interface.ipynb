{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.data.dataset import precomputed_molecules, MoleculeDataset, MLDataset, get_dataloader\n",
    "import torch\n",
    "from ase.io import read\n",
    "import ase\n",
    "from mlelec.models.linear import LinearTargetModel\n",
    "from mlelec.features.acdc import compute_features_for_target\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=11, micro=5, releaselevel='final', serial=0)\n",
      "2.3.0\n",
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import pyscf, pyscfad\n",
    "print(sys.version_info)\n",
    "print(pyscf.__version__)\n",
    "print(pyscfad.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading structures\n",
      "examples/data/water_1000/sto-3g/fock.hickle\n",
      "examples/data/water_1000/sto-3g/dipole_moment.hickle\n",
      "Computing features with default hypers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/rascaline/systems/ase.py:57: UserWarning: periodic boundary conditions are disabled, but the cell matrix is not zero, we will set the cell to zero.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "water_data = MoleculeDataset(mol_name='water_1000', frame_slice=slice(0,200),  device='cuda', aux=['overlap', 'orbitals'], target=[\"fock\", \"dipole_moment\"])\n",
    "ml_data = MLDataset(molecule_data=water_data, device ='cuda', model_strategy = \"coupled\")\n",
    "\n",
    "ml_data._shuffle(random_seed=5380)\n",
    "ml_data._split_indices(train_frac=0.7, val_frac=0.2)\n",
    "#assumed args.model_type = 'acdc'\n",
    "if ml_data.features is None: \n",
    "    ml_data._set_features(compute_features_for_target(ml_data, device='cuda'))\n",
    "\n",
    "train_dl, val_dl, test_dl = get_dataloader(ml_data, model_return= 'tensor')\n",
    "# next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learn Hamiltonian then predict dipole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearTargetModel(dataset = ml_data, nlayers = 1, nhidden = 16, bias = False, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import inf\n",
    "best = inf\n",
    "early_stop_criteria =  10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, verbose=True)\n",
    "import mlelec.metrics as mlmetrics\n",
    "val_interval = 10\n",
    "loss_fn = getattr(mlmetrics, 'L2_loss')\n",
    "losses=[]\n",
    "early_stop_count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 462.95987853278535\n",
      "Epoch 0 val loss 441.6532839589898\n",
      "Epoch 10, train loss 5.8631769241150575\n",
      "Epoch 10 val loss 3.766819132877007\n",
      "Epoch 20, train loss 1.9318194083224345\n",
      "Epoch 20 val loss 1.8118898962798404\n",
      "Epoch 30, train loss 1.3506038389008153\n",
      "Epoch 30 val loss 1.2654273477733144\n",
      "Epoch 40, train loss 1.0305076747323796\n",
      "Epoch 40 val loss 0.9843053593080245\n",
      "Epoch 50, train loss 0.8857030108592749\n",
      "Epoch 50 val loss 0.7242746097896844\n",
      "Epoch 60, train loss 1.017152272278283\n",
      "Epoch 60 val loss 0.8919096019890216\n",
      "Epoch 70, train loss 0.8431376878419865\n",
      "Epoch 70 val loss 0.8994411199714145\n",
      "Epoch 80, train loss 0.9008245495295076\n",
      "Epoch 80 val loss 0.6799362415339285\n",
      "Epoch 90, train loss 0.8556155980885519\n",
      "Epoch 90 val loss 0.5966697051283202\n",
      "Epoch 100, train loss 0.964322425665469\n",
      "Epoch 100 val loss 0.7399460882062244\n",
      "Epoch 110, train loss 0.8939658596937357\n",
      "Epoch 110 val loss 0.8117343962133475\n",
      "Epoch 120, train loss 0.9059325448372387\n",
      "Epoch 120 val loss 0.6516525941604734\n",
      "Epoch 130, train loss 0.8927714889119762\n",
      "Epoch 130 val loss 0.8520664900579701\n",
      "Epoch 140, train loss 0.8076510166895274\n",
      "Epoch 140 val loss 0.7210013039828755\n",
      "Epoch 150, train loss 0.816149808276664\n",
      "Epoch 150 val loss 0.5934053580638556\n",
      "Epoch 160, train loss 0.8525910146368798\n",
      "Epoch 160 val loss 0.8351558104985736\n",
      "Epoch 170, train loss 0.8142712488801576\n",
      "Epoch 170 val loss 0.6317249291084156\n",
      "Epoch 180, train loss 0.8116636270815484\n",
      "Epoch 180 val loss 0.6801136938864685\n",
      "Epoch 190, train loss 0.8968036663072088\n",
      "Epoch 190 val loss 0.7669471997555187\n",
      "Epoch 200, train loss 0.7423259658782096\n",
      "Epoch 200 val loss 0.7675338050597986\n",
      "Epoch 210, train loss 0.8785674046951394\n",
      "Epoch 210 val loss 0.8154984316031436\n",
      "Epoch 220, train loss 0.8191864608628356\n",
      "Epoch 220 val loss 0.7608534150204522\n",
      "Epoch 230, train loss 0.868899928481906\n",
      "Epoch 230 val loss 0.6080807875479954\n",
      "Epoch 240, train loss 0.941864204595978\n",
      "Epoch 240 val loss 0.6333690693990474\n",
      "Epoch 250, train loss 0.8934368367123002\n",
      "Epoch 250 val loss 0.7956968286690584\n",
      "Early stopping at epoch 260\n",
      "Epoch 260, train loss 0.8221905966461716\n",
      "Epoch 260 val loss 0.7396394120085912\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(800):\n",
    "    # train_pred = []\n",
    "    # target=[]\n",
    "    model.train(True)\n",
    "    train_loss =0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data['input'], return_type='tensor', batch_indices=data['idx'])\n",
    "        # target.append(data['output'])\n",
    "        # train_pred.append(pred)\n",
    "        loss = loss_fn(pred, data['output'])\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # train_loss = loss_fn(torch.cat(train_pred), torch.cat(target))\n",
    "    # print(train_loss - epoch_loss)\n",
    "    losses.append(train_loss)\n",
    "    # scheduler.step(train_loss)\n",
    "    model.train(False)\n",
    "\n",
    "    if epoch% val_interval == 0:\n",
    "        # val_pred = []\n",
    "        # val= []\n",
    "        val_loss = 0\n",
    "        for i, data in enumerate(val_dl):\n",
    "            pred = model(data['input'], return_type='tensor', batch_indices=data['idx'])\n",
    "            vloss = loss_fn(pred, data['output'])\n",
    "            val_loss += vloss.item()\n",
    "            # val.append(data['output'])\n",
    "            # val_pred.append(pred)\n",
    "        new_best = val_loss < best \n",
    "        if new_best:\n",
    "            best = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count+=1\n",
    "        if early_stop_count > early_stop_criteria:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "            print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "            # Save last best model\n",
    "            break\n",
    "\n",
    "        # val_loss = loss_fn(torch.cat(val_pred), torch.cat(val))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "        print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2e19c40e90>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.loglog(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input model prediction into pyscf to compute dipole moment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSCFAD_BACKEND']='torch'\n",
    "\n",
    "import torch\n",
    "from pyscf import gto\n",
    "\n",
    "from pyscfad import numpy as pynp\n",
    "from pyscfad import ops\n",
    "from pyscfad.ml.scf import hf\n",
    "import pyscf.pbc.tools.pyscf_ase as pyscf_ase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.data.pyscf_calculator import _instantiate_pyscf_mol\n",
    "from mlelec.utils.twocenter_utils import fix_orbital_order, unfix_orbital_order\n",
    "import mlelec.metrics as mlmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys._jupyter_stdout = sys.stdout\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys._jupyter_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dipole_moment(frames, fock_predictions, overlaps):\n",
    "    assert len(frames) == len(fock_predictions) == len(overlaps), \"Length of frames, fock_predictions, and overlaps must be the same\"\n",
    "    dipoles  = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        mol = _instantiate_pyscf_mol(frame)\n",
    "        mf = hf.SCF(mol)\n",
    "        fock = torch.autograd.Variable(fock_predictions[i].type(torch.float64), requires_grad=True)\n",
    "\n",
    "        mo_energy, mo_coeff = mf.eig(fock, overlaps[i])\n",
    "        mo_occ = mf.get_occ(mo_energy) # get_occ returns a numpy array\n",
    "        mo_occ = ops.convert_to_tensor(mo_occ)\n",
    "        dm1 = mf.make_rdm1(mo_coeff, mo_occ)\n",
    "        dip = mf.dip_moment(dm=dm1)\n",
    "        dipoles.append(dip)\n",
    "    return torch.stack(dipoles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TEST) MSE on dipole tensor(0.3084, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#TEST set \n",
    "\n",
    "# with HiddenPrints():\n",
    "with io.capture_output() as captured:\n",
    "\n",
    "    fock_predictions = model.forward(ml_data.feat_test, return_type='tensor')\n",
    "    # convert prediction back to pyscf order\n",
    "    fock_predictions = unfix_orbital_order(fock_predictions, ml_data.test_frames, ml_data.molecule_data.aux_data['orbitals'])\n",
    "    \n",
    "    dipole_predictions = compute_dipole_moment(ml_data.test_frames, fock_predictions,ml_data.molecule_data.aux_data['overlap'][ml_data.test_idx])\n",
    "    # very imp to pass the right overlap matrix\n",
    "\n",
    "\n",
    "error = mlmetrics.L2_loss(dipole_predictions, ml_data.molecule_data.target['dipole_moment'][ml_data.test_idx])\n",
    "print('(TEST) MSE on dipole', error/len(dipole_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire dataset \n",
    "with io.capture_output() as captured:\n",
    "\n",
    "    fock_predictions = model.forward(ml_data.features, return_type='tensor')\n",
    "    # convert prediction back to pyscf order \n",
    "    fock_predictions = unfix_orbital_order(fock_predictions, ml_data.structures, ml_data.molecule_data.aux_data['orbitals'])\n",
    "    dipole_predictions = compute_dipole_moment(ml_data.structures, fock_predictions,ml_data.molecule_data.aux_data['overlap']); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on dipole tensor(0.2465, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "error = mlmetrics.L2_loss(dipole_predictions, ml_data.molecule_data.target['dipole_moment'])\n",
    "print('MSE on dipole', error/len(dipole_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Indirect learning of dipole moment through pyscfad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlelec.metrics as mlmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "def instantiate_mf(ml_data: MLDataset, fock_predictions, batch_indices):\n",
    "    if len(batch_indices) != len(fock_predictions):\n",
    "        warnings.warn('Converting shapes')\n",
    "        fock_predictions = fock_predictions.reshape(1,*fock_predictions.shape)\n",
    "    mfs = []\n",
    "    fockvar = []\n",
    "    for i, idx in enumerate(batch_indices):\n",
    "        mol = _instantiate_pyscf_mol(ml_data.structures[idx])\n",
    "        mf = hf.SCF(mol)\n",
    "        fock = torch.autograd.Variable(fock_predictions[i].type(torch.float64), requires_grad=True)\n",
    "        mfs.append(mf)\n",
    "        fockvar.append(fock)\n",
    "    return mfs, torch.stack(fockvar)\n",
    "\n",
    "def compute_dipole_moment_frommf(mfs, fock_vars, overlaps):\n",
    "    print(fock_vars.dtype, overlaps.dtype)\n",
    "    dipoles  = []\n",
    "    for i in range(len(mfs)):\n",
    "        mf = mfs[i]\n",
    "        fock = fock_vars[i]\n",
    "        overlaps[i] = overlaps[i].to(fock)\n",
    "        mo_energy, mo_coeff = mf.eig(fock, overlaps[i])\n",
    "        mo_occ = mf.get_occ(mo_energy) # get_occ returns a numpy array\n",
    "        mo_occ = ops.convert_to_tensor(mo_occ)\n",
    "        dm1 = mf.make_rdm1(mo_coeff, mo_occ)\n",
    "        dip = mf.dip_moment(dm=dm1)\n",
    "        dipoles.append(dip)\n",
    "    return torch.stack(dipoles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dipole_moment_from_batchidx(ml_data: MLDataset, batch_fockvars, batch_indices, mfs):\n",
    "    # Convert fock predictions back to pyscf order\n",
    "    # Compute dipole moment for each molecule in batch\n",
    "    batch_frames = [ml_data.structures[i] for i in batch_indices]\n",
    "    batch_fock = unfix_orbital_order(batch_fockvars, batch_frames, ml_data.molecule_data.aux_data['orbitals'])\n",
    "    batch_overlap = ml_data.molecule_data.aux_data['overlap'][batch_indices].to(batch_fock)\n",
    "    print(len(batch_frames), len(batch_fock), len(batch_overlap))\n",
    "    batch_mfs = [mfs[i] for i in batch_indices]\n",
    "    return compute_dipole_moment_frommf(batch_mfs, batch_fock, batch_overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import inf\n",
    "best = inf\n",
    "early_stop_criteria =  10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearTargetModel(dataset = ml_data, nlayers = 1, nhidden = 16, bias = False, device = 'cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "val_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_focks = model(ml_data.features , return_type='tensor').type(torch.float64)\n",
    "all_mfs = instantiate_mf(ml_data, all_focks, idx = list(range(len(ml_))))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_focks = model(ml_data.feat_train , return_type='tensor').type(torch.float64)\n",
    "\n",
    "train_mfs, train_focks = instantiate_mf(ml_data, train_focks, ml_data.train_idx)\n",
    "\n",
    "val_focks = model(ml_data.feat_val, return_type='tensor').type(torch.float64)\n",
    "\n",
    "val_mfs, val_focks = instantiate_mf(ml_data, val_focks, ml_data.val_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3]) torch.Size([4, 3]) [199, 107, 41, 32]\n",
      "torch.Size([4, 3]) torch.Size([4, 3]) [96, 95, 115, 147]\n",
      "torch.Size([4, 3]) torch.Size([4, 3]) [68, 143, 57, 117]\n",
      "torch.Size([4, 3]) torch.Size([4, 3]) [142, 24, 64, 140]\n",
      "torch.Size([4, 3]) torch.Size([4, 3]) [13, 26, 44, 35]\n",
      "torch.Size([4, 3]) torch.Size([4, 3]) [112, 9, 179, 14]\n",
      "torch.Size([4, 3]) torch.Size([4, 3]) [146, 149, 10, 49]\n",
      "torch.Size([4, 3]) torch.Size([4, 3]) [106, 94, 5, 89]\n",
      "torch.Size([4, 3]) torch.Size([4, 3]) [83, 137, 158, 28]\n",
      "torch.Size([3, 3]) torch.Size([3, 3]) [136, 144, 82]\n",
      "Epoch 0, train loss 0.02341648604221277\n",
      "Epoch 0 val loss 0.03470706547770126\n",
      "torch.Size([3, 3]) torch.Size([4, 3]) [95, 24, 9, 89]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y323sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         val_dip_pred \u001b[39m=\u001b[39m compute_dipole_moment_from_batchidx(ml_data, val_focks, batch_indices\u001b[39m=\u001b[39mbatch_indices, mfs\u001b[39m=\u001b[39mval_mfs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y323sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39mprint\u001b[39m(val_dip_pred\u001b[39m.\u001b[39mshape, ml_data\u001b[39m.\u001b[39mmolecule_data\u001b[39m.\u001b[39mtarget[\u001b[39m'\u001b[39m\u001b[39mdipole_moment\u001b[39m\u001b[39m'\u001b[39m][batch_indices]\u001b[39m.\u001b[39mshape, batch_indices)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y323sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     vloss \u001b[39m=\u001b[39m loss_fn(val_dip_pred, ml_data\u001b[39m.\u001b[39;49mmolecule_data\u001b[39m.\u001b[39;49mtarget[\u001b[39m'\u001b[39;49m\u001b[39mdipole_moment\u001b[39;49m\u001b[39m'\u001b[39;49m][batch_indices])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y323sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m vloss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y323sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m new_best \u001b[39m=\u001b[39m val_loss \u001b[39m<\u001b[39m best \n",
      "File \u001b[0;32m/media/nigam/b5749eb7-d3f1-4495-adeb-2c318fb7d0de/MAC/my_mlelec/src/mlelec/metrics.py:9\u001b[0m, in \u001b[0;36mL2_loss\u001b[0;34m(pred, target)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"L2 loss function\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# target = target.to(pred)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39msum((pred \u001b[39m-\u001b[39;49m target) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "loss_fn = getattr(mlmetrics, 'L2_loss')\n",
    "losses=[]\n",
    "early_stop_count = 0\n",
    "for epoch in range(300):\n",
    "    model.train(True)\n",
    "    train_loss =0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = data['idx']\n",
    "        # print(batch_indices)\n",
    "        train_focks = model(data['input'], return_type='tensor', batch_indices=batch_indices).type(torch.float64)\n",
    "        with io.capture_output() as captured:\n",
    "        # with HiddenPrints():\n",
    "            # if epoch == 0:\n",
    "            #     train_mfs, train_focks = instantiate_mf(ml_data, train_focks, batch_indices )\n",
    "            #     print(len(train_mfs), len(train_focks), len(batch_indices))\n",
    "            train_dip_pred = compute_dipole_moment_from_batchidx(ml_data, train_focks, batch_indices=batch_indices, mfs=train_mfs)\n",
    "        loss = loss_fn(train_dip_pred, ml_data.molecule_data.target['dipole_moment'][batch_indices])\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # train_loss = loss_fn(torch.cat(train_pred), torch.cat(target))\n",
    "    # print(train_loss - epoch_loss)\n",
    "    losses.append(train_loss)\n",
    "    # scheduler.step(train_loss)\n",
    "    model.train(False)\n",
    "\n",
    "    if epoch% val_interval == 0:\n",
    "        val_loss = 0\n",
    "        for i, data in enumerate(val_dl):\n",
    "            batch_indices = data['idx']\n",
    "            val_focks = model(data['input'], return_type='tensor', batch_indices=batch_indices).type(torch.float64)\n",
    "            with io.capture_output() as captured:\n",
    "            # with HiddenPrints():\n",
    "                if epoch == 0:\n",
    "                    val_mfs, val_focks = instantiate_mf(ml_data, val_focks, batch_indices )\n",
    "                val_dip_pred = compute_dipole_moment_from_batchidx(ml_data, val_focks, batch_indices=batch_indices, mfs=val_mfs)\n",
    "            print(val_dip_pred.shape, ml_data.molecule_data.target['dipole_moment'][batch_indices].shape, batch_indices)\n",
    "            vloss = loss_fn(val_dip_pred, ml_data.molecule_data.target['dipole_moment'][batch_indices])\n",
    "            val_loss += vloss.item()\n",
    "        new_best = val_loss < best \n",
    "        if new_best:\n",
    "            best = val_loss\n",
    "            # torch.save(model.state_dict(), 'best_model_dipole.pt')\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count+=1\n",
    "        if early_stop_count > early_stop_criteria:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "            print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "            # Save last best model\n",
    "            break\n",
    "\n",
    "        # val_loss = loss_fn(torch.cat(val_pred), torch.cat(val))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "        print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TEST) MSE on dipole tensor(3.6236e-12, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with io.capture_output() as captured:\n",
    "    batch_indices = ml_data.test_idx\n",
    "    test_fock_predictions = model.forward(ml_data.feat_test, return_type='tensor').type(torch.float64)\n",
    "    # convert prediction back to pyscf order\n",
    "    test_mfs, test_focks = instantiate_mf(ml_data, test_fock_predictions, batch_indices )\n",
    "    test_dip_pred = compute_dipole_moment_from_batchidx(ml_data, test_fock_predictions, batch_indices=batch_indices, mfs=test_mfs)\n",
    "    # very imp to pass the right overlap matrix\n",
    "\n",
    "\n",
    "error = mlmetrics.L2_loss(test_dip_pred, ml_data.molecule_data.target['dipole_moment'][ml_data.test_idx])\n",
    "print('(TEST) MSE on dipole', error/len(test_dip_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can overfit on just rotated structures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading structures\n",
      "examples/data/water_rotated/sto-3g/fock.hickle\n",
      "examples/data/water_rotated/sto-3g/dipole_moment.hickle\n",
      "Computing features with default hypers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/rascaline/systems/ase.py:57: UserWarning: periodic boundary conditions are disabled, but the cell matrix is not zero, we will set the cell to zero.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "water_data = MoleculeDataset(mol_name='water_rotated', frame_slice=slice(0,100),  device='cuda', aux=['overlap', 'orbitals'], target=[\"fock\", \"dipole_moment\"])\n",
    "ml_data = MLDataset(molecule_data=water_data, device ='cuda', model_strategy = \"coupled\")\n",
    "\n",
    "# ml_data._shuffle(random_seed=5380)\n",
    "ml_data._split_indices(train_frac=0.4, val_frac=0.33)\n",
    "#assumed args.model_type = 'acdc'\n",
    "if ml_data.features is None: \n",
    "    ml_data._set_features(compute_features_for_target(ml_data, device='cuda'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl = get_dataloader(ml_data, model_return= 'tensor')\n",
    "# next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training on rotated structures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearTargetModel(dataset = ml_data, nlayers = 1, nhidden = 16, bias = False, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import inf\n",
    "best = inf\n",
    "early_stop_criteria =  10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, verbose=True)\n",
    "import mlelec.metrics as mlmetrics\n",
    "val_interval = 10\n",
    "loss_fn = getattr(mlmetrics, 'L2_loss')\n",
    "losses=[]\n",
    "early_stop_count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 480.6221471109374\n",
      "Epoch 0 val loss 479.6697718800906\n",
      "Epoch 10, train loss 471.067940931348\n",
      "Epoch 10 val loss 470.07432046560285\n",
      "Epoch 20, train loss 460.5452746793023\n",
      "Epoch 20 val loss 459.41386976932336\n",
      "Epoch 30, train loss 448.51430957752297\n",
      "Epoch 30 val loss 447.2212151794173\n",
      "Epoch 40, train loss 434.8163762364184\n",
      "Epoch 40 val loss 433.35173403945134\n",
      "Epoch 50, train loss 419.394049535435\n",
      "Epoch 50 val loss 417.75839236533676\n",
      "Epoch 60, train loss 402.31622244719415\n",
      "Epoch 60 val loss 400.5242073677908\n",
      "Epoch 70, train loss 383.78575865653283\n",
      "Epoch 70 val loss 381.8637295122723\n",
      "Epoch 80, train loss 364.1001015139956\n",
      "Epoch 80 val loss 362.08097041657\n",
      "Epoch 90, train loss 343.5972824317196\n",
      "Epoch 90 val loss 341.51489354079655\n",
      "Epoch 100, train loss 322.60118737197865\n",
      "Epoch 100 val loss 320.48553902797124\n",
      "Epoch 110, train loss 301.38706441313224\n",
      "Epoch 110 val loss 299.2625421243271\n",
      "Epoch 120, train loss 280.17292045612527\n",
      "Epoch 120 val loss 278.05829901281874\n",
      "Epoch 130, train loss 259.1249612760588\n",
      "Epoch 130 val loss 257.0343781514643\n",
      "Epoch 140, train loss 238.36724031403483\n",
      "Epoch 140 val loss 236.31121093580407\n",
      "Epoch 150, train loss 217.99251486134105\n",
      "Epoch 150 val loss 215.97906654704028\n",
      "Epoch 160, train loss 198.0762107819464\n",
      "Epoch 160 val loss 196.11260204925392\n",
      "Epoch 170, train loss 178.69350050188095\n",
      "Epoch 170 val loss 176.78785831983802\n",
      "Epoch 180, train loss 159.93384293220115\n",
      "Epoch 180 val loss 158.09619549214355\n",
      "Epoch 190, train loss 141.90665180448767\n",
      "Epoch 190 val loss 140.14891308143552\n",
      "Epoch 200, train loss 124.73659394317214\n",
      "Epoch 200 val loss 123.0717261264063\n",
      "Epoch 210, train loss 108.55220101124699\n",
      "Epoch 210 val loss 106.99271259488519\n",
      "Epoch 220, train loss 93.47254904497245\n",
      "Epoch 220 val loss 92.02936690506182\n",
      "Epoch 230, train loss 79.59626112842915\n",
      "Epoch 230 val loss 78.27781176063128\n",
      "Epoch 240, train loss 66.99418725029865\n",
      "Epoch 240 val loss 65.80585439464825\n",
      "Epoch 250, train loss 55.705655318225354\n",
      "Epoch 250 val loss 54.64959234288684\n",
      "Epoch 260, train loss 45.737404124866394\n",
      "Epoch 260 val loss 44.81250137496227\n",
      "Epoch 270, train loss 37.064639028382935\n",
      "Epoch 270 val loss 36.266770276668666\n",
      "Epoch 280, train loss 29.633923407857132\n",
      "Epoch 280 val loss 28.956339836269017\n",
      "Epoch 290, train loss 23.367322987455452\n",
      "Epoch 290 val loss 22.801077623055797\n",
      "Epoch 300, train loss 18.167595893211928\n",
      "Epoch 300 val loss 17.702121316630567\n",
      "Epoch 310, train loss 13.92400440396401\n",
      "Epoch 310 val loss 13.547730224704392\n",
      "Epoch 320, train loss 10.518564705489238\n",
      "Epoch 320 val loss 10.219489035551165\n",
      "Epoch 330, train loss 7.831725362167545\n",
      "Epoch 330 val loss 7.5980359750066695\n",
      "Epoch 340, train loss 5.74757659350204\n",
      "Epoch 340 val loss 5.5680680275896215\n",
      "Epoch 350, train loss 4.158098689219944\n",
      "Epoch 350 val loss 4.0225039422569795\n",
      "Epoch 360, train loss 2.9660037584865058\n",
      "Epoch 360 val loss 2.865273336756371\n",
      "Epoch 370, train loss 2.0865388331682513\n",
      "Epoch 370 val loss 2.01291596395469\n",
      "Epoch 380, train loss 1.4480674493223942\n",
      "Epoch 380 val loss 1.3951050864712433\n",
      "Epoch 390, train loss 0.9917601308730389\n",
      "Epoch 390 val loss 0.9542425056049562\n",
      "Epoch 400, train loss 0.6705474058123113\n",
      "Epoch 400 val loss 0.6443625709467616\n",
      "Epoch 410, train loss 0.44772901025879625\n",
      "Epoch 410 val loss 0.42971204592156614\n",
      "Epoch 420, train loss 0.2953320690962386\n",
      "Epoch 420 val loss 0.283111847004136\n",
      "Epoch 430, train loss 0.19251518619057434\n",
      "Epoch 430 val loss 0.184332327061375\n",
      "Epoch 440, train loss 0.1240532589152218\n",
      "Epoch 440 val loss 0.11864514265112773\n",
      "Epoch 450, train loss 0.07904095590088342\n",
      "Epoch 450 val loss 0.07551205979652757\n",
      "Epoch 460, train loss 0.0498092305779583\n",
      "Epoch 460 val loss 0.04753291140824228\n",
      "Epoch 470, train loss 0.03104977000997539\n",
      "Epoch 470 val loss 0.029599068865213025\n",
      "Epoch 480, train loss 0.01915141380757535\n",
      "Epoch 480 val loss 0.01823665051030572\n",
      "Epoch 490, train loss 0.011688070711021563\n",
      "Epoch 490 val loss 0.011118226190472218\n",
      "Epoch 500, train loss 0.007058982840221053\n",
      "Epoch 500 val loss 0.0067077075533684945\n",
      "Epoch 510, train loss 0.0042192443791439415\n",
      "Epoch 510 val loss 0.004005216557278323\n",
      "Epoch 520, train loss 0.002495824607427838\n",
      "Epoch 520 val loss 0.0023668017643400574\n",
      "Epoch 530, train loss 0.0014610909838555855\n",
      "Epoch 530 val loss 0.0013841218244743784\n",
      "Epoch 540, train loss 0.0008464458229658755\n",
      "Epoch 540 val loss 0.0008010140574677754\n",
      "Epoch 550, train loss 0.00048527343538476864\n",
      "Epoch 550 val loss 0.00045875516584494583\n",
      "Epoch 560, train loss 0.0002752636639301316\n",
      "Epoch 560 val loss 0.000259914482921553\n",
      "Epoch 570, train loss 0.00015443852694061754\n",
      "Epoch 570 val loss 0.00014570071496888397\n",
      "Epoch 580, train loss 8.576855164733978e-05\n",
      "Epoch 580 val loss 8.079097267728772e-05\n",
      "Epoch 590, train loss 4.7082745938259946e-05\n",
      "Epoch 590 val loss 4.4298245138272815e-05\n",
      "Epoch 600, train loss 2.5557351118934664e-05\n",
      "Epoch 600 val loss 2.4037835770633934e-05\n",
      "Epoch 610, train loss 1.3727213000173732e-05\n",
      "Epoch 610 val loss 1.2905994633345818e-05\n",
      "Epoch 620, train loss 7.289206669055451e-06\n",
      "Epoch 620 val loss 6.84308685775311e-06\n",
      "Epoch 630, train loss 3.8184301431629254e-06\n",
      "Epoch 630 val loss 3.5836195396507624e-06\n",
      "Epoch 640, train loss 1.978726664834227e-06\n",
      "Epoch 640 val loss 1.85203740339039e-06\n",
      "Epoch 650, train loss 1.0122980250102664e-06\n",
      "Epoch 650 val loss 9.443916639293617e-07\n",
      "Epoch 660, train loss 5.129637398748813e-07\n",
      "Epoch 660 val loss 4.780614319663422e-07\n",
      "Epoch 670, train loss 2.5260106294956355e-07\n",
      "Epoch 670 val loss 2.3749690337278292e-07\n",
      "Epoch 680, train loss 1.2519196488590848e-07\n",
      "Epoch 680 val loss 1.1592325827692871e-07\n",
      "Epoch 690, train loss 6.101811283661752e-08\n",
      "Epoch 690 val loss 5.639888089999499e-08\n",
      "Epoch 700, train loss 2.9148783310280205e-08\n",
      "Epoch 700 val loss 2.722893010694e-08\n",
      "Epoch 710, train loss 1.3767425601053512e-08\n",
      "Epoch 710 val loss 1.2888131460337695e-08\n",
      "Epoch 720, train loss 6.273250330401877e-09\n",
      "Epoch 720 val loss 5.685017568512125e-09\n",
      "Epoch 730, train loss 2.5625431465731515e-09\n",
      "Epoch 730 val loss 2.19262484125471e-09\n",
      "Epoch 740, train loss 1.2528848644384963e-09\n",
      "Epoch 740 val loss 1.2540507693273925e-09\n",
      "Epoch 750, train loss 1.1218992540376975e-09\n",
      "Epoch 750 val loss 1.1230874421539308e-09\n",
      "Epoch 760, train loss 1.1219203335403971e-09\n",
      "Epoch 760 val loss 1.1230852906681012e-09\n",
      "Epoch 770, train loss 1.1220061142835945e-09\n",
      "Epoch 770 val loss 1.1230870600397601e-09\n",
      "Epoch 780, train loss 1.1218990518260406e-09\n",
      "Epoch 780 val loss 1.1230885915626679e-09\n",
      "Epoch 790, train loss 1.1220078074766654e-09\n",
      "Epoch 790 val loss 1.1230831874809509e-09\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(800):\n",
    "    # train_pred = []\n",
    "    # target=[]\n",
    "    model.train(True)\n",
    "    train_loss =0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data['input'], return_type='tensor', batch_indices=data['idx'])\n",
    "        # target.append(data['output'])\n",
    "        # train_pred.append(pred)\n",
    "        loss = loss_fn(pred, data['output'])\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # train_loss = loss_fn(torch.cat(train_pred), torch.cat(target))\n",
    "    # print(train_loss - epoch_loss)\n",
    "    losses.append(train_loss)\n",
    "    # scheduler.step(train_loss)\n",
    "    model.train(False)\n",
    "\n",
    "    if epoch% val_interval == 0:\n",
    "        # val_pred = []\n",
    "        # val= []\n",
    "        val_loss = 0\n",
    "        for i, data in enumerate(val_dl):\n",
    "            pred = model(data['input'], return_type='tensor', batch_indices=data['idx'])\n",
    "            vloss = loss_fn(pred, data['output'])\n",
    "            val_loss += vloss.item()\n",
    "            # val.append(data['output'])\n",
    "            # val_pred.append(pred)\n",
    "        new_best = val_loss < best \n",
    "        if new_best:\n",
    "            best = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count+=1\n",
    "        if early_stop_count > early_stop_criteria:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "            print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "            # Save last best model\n",
    "            break\n",
    "\n",
    "        # val_loss = loss_fn(torch.cat(val_pred), torch.cat(val))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "        print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2e20c95910>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.loglog(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input model prediction into pyscf to compute dipole moment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSCFAD_BACKEND']='torch'\n",
    "\n",
    "import torch\n",
    "from pyscf import gto\n",
    "\n",
    "from pyscfad import numpy as pynp\n",
    "from pyscfad import ops\n",
    "from pyscfad.ml.scf import hf\n",
    "import pyscf.pbc.tools.pyscf_ase as pyscf_ase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.data.pyscf_calculator import _instantiate_pyscf_mol\n",
    "from mlelec.utils.twocenter_utils import fix_orbital_order, unfix_orbital_order\n",
    "import mlelec.metrics as mlmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys._jupyter_stdout = sys.stdout\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys._jupyter_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dipole_moment(frames, fock_predictions, overlaps):\n",
    "    assert len(frames) == len(fock_predictions) == len(overlaps), \"Length of frames, fock_predictions, and overlaps must be the same\"\n",
    "    dipoles  = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        mol = _instantiate_pyscf_mol(frame)\n",
    "        mf = hf.SCF(mol)\n",
    "        fock = torch.autograd.Variable(fock_predictions[i].type(torch.float64), requires_grad=True)\n",
    "\n",
    "        mo_energy, mo_coeff = mf.eig(fock, overlaps[i])\n",
    "        mo_occ = mf.get_occ(mo_energy) # get_occ returns a numpy array\n",
    "        mo_occ = ops.convert_to_tensor(mo_occ)\n",
    "        dm1 = mf.make_rdm1(mo_coeff, mo_occ)\n",
    "        dip = mf.dip_moment(dm=dm1)\n",
    "        dipoles.append(dip)\n",
    "    return torch.stack(dipoles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y125sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# with HiddenPrints():\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y125sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39mcapture_output() \u001b[39mas\u001b[39;00m captured:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y125sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     fock_predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(ml_data\u001b[39m.\u001b[39mfeat_test, return_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensor\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y125sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# convert prediction back to pyscf order\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y125sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     test_structures \u001b[39m=\u001b[39m [ml_data\u001b[39m.\u001b[39mstructures[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ml_data\u001b[39m.\u001b[39mtest_idx] \n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#TEST set \n",
    "\n",
    "# with HiddenPrints():\n",
    "with io.capture_output() as captured:\n",
    "\n",
    "    fock_predictions = model.forward(ml_data.feat_test, return_type='tensor')\n",
    "    # convert prediction back to pyscf order\n",
    "    fock_predictions = unfix_orbital_order(fock_predictions, ml_data.test_structures, ml_data.molecule_data.aux_data['orbitals'])\n",
    "    \n",
    "    dipole_predictions = compute_dipole_moment(ml_data.test_structures, fock_predictions,ml_data.molecule_data.aux_data['overlap'][ml_data.test_idx])\n",
    "    # very imp to pass the right overlap matrix\n",
    "\n",
    "\n",
    "error = mlmetrics.L2_loss(dipole_predictions, ml_data.molecule_data.target['dipole_moment'][ml_data.test_idx])\n",
    "print('(TEST) MSE on dipole', error/len(dipole_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire dataset \n",
    "with io.capture_output() as captured:\n",
    "\n",
    "    fock_predictions = model.forward(ml_data.features, return_type='tensor')\n",
    "    # convert prediction back to pyscf order \n",
    "    fock_predictions = unfix_orbital_order(fock_predictions, ml_data.structures, ml_data.molecule_data.aux_data['orbitals'])\n",
    "    dipole_predictions = compute_dipole_moment(ml_data.structures, fock_predictions,ml_data.molecule_data.aux_data['overlap']); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on dipole tensor(1.3298e-12, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "error = mlmetrics.L2_loss(dipole_predictions, ml_data.molecule_data.target['dipole_moment'])\n",
    "print('MSE on dipole', error/len(dipole_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test equivariance of prediction/features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle\n",
    "rotations = hickle.load('examples/data/water_rotated/rotations.hickle')\n",
    "r1 = model.forward(ml_data.features, return_type='coupled_blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = ml_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.metatensor_utils import labels_where\n",
    "from mlelec.utils.symmetry import _wigner_d_real\n",
    "import numpy as np \n",
    "from metatensor import Labels\n",
    "for i, (k,b) in enumerate(r1.items()):\n",
    "    unrot_idx  = labels_where(b.samples, selection = Labels(['structure'], values = np.asarray([[0]]).reshape(-1,1)), \n",
    "    return_idx=True )[-1]\n",
    "    rot_idx = labels_where(b.samples, selection = Labels(['structure'], values = np.asarray([[ml_data.test_idx]]).reshape(-1,1)), return_idx=True)[-1]\n",
    "    # L = k['L']\n",
    "    L = k['spherical_harmonics_l']\n",
    "    wd = _wigner_d_real(L, *rotations[ml_data.test_idx-1]).to(b.values)\n",
    "    if torch.linalg.norm(wd@b.values[unrot_idx] - b.values[rot_idx])>1e-7:\n",
    "        print(torch.linalg.norm(wd@b.values[unrot_idx] - b.values[rot_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect learning of dipole moment through pyscfad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlelec.metrics as mlmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "def instantiate_mf(ml_data: MLDataset, fock_predictions, batch_indices):\n",
    "    if len(batch_indices) != len(fock_predictions):\n",
    "        warnings.warn('Converting shapes')\n",
    "        fock_predictions = fock_predictions.reshape(1,*fock_predictions.shape)\n",
    "    mfs = []\n",
    "    fockvar = []\n",
    "    for i, idx in enumerate(batch_indices):\n",
    "        mol = _instantiate_pyscf_mol(ml_data.structures[idx])\n",
    "        mf = hf.SCF(mol)\n",
    "        fock = torch.autograd.Variable(fock_predictions[i].type(torch.float64), requires_grad=True)\n",
    "        mfs.append(mf)\n",
    "        fockvar.append(fock)\n",
    "    return mfs, torch.cat(fockvar)\n",
    "\n",
    "def compute_dipole_moment_frommf(mfs, fock_vars, overlaps):\n",
    "    print(fock_vars.dtype, overlaps.dtype)\n",
    "    dipoles  = []\n",
    "    for i in range(len(mfs)):\n",
    "        mf = mfs[i]\n",
    "        fock = fock_vars[i]\n",
    "        overlaps[i] = overlaps[i].to(fock)\n",
    "        mo_energy, mo_coeff = mf.eig(fock, overlaps[i])\n",
    "        mo_occ = mf.get_occ(mo_energy) # get_occ returns a numpy array\n",
    "        mo_occ = ops.convert_to_tensor(mo_occ)\n",
    "        dm1 = mf.make_rdm1(mo_coeff, mo_occ)\n",
    "        dip = mf.dip_moment(dm=dm1)\n",
    "        dipoles.append(dip)\n",
    "    return torch.stack(dipoles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dipole_moment_from_batchidx(ml_data: MLDataset, batch_fockvars, batch_indices, mfs):\n",
    "    # Convert fock predictions back to pyscf order\n",
    "    # Compute dipole moment for each molecule in batch\n",
    "    batch_frames = [ml_data.structures[i] for i in batch_indices]\n",
    "    batch_fock = unfix_orbital_order(batch_fockvars, batch_frames, ml_data.molecule_data.aux_data['orbitals'])\n",
    "    batch_overlap = ml_data.molecule_data.aux_data['overlap'][batch_indices].to(batch_fock)\n",
    "    print(len(batch_frames), len(batch_fock), len(batch_overlap))\n",
    "    return compute_dipole_moment_frommf(mfs, batch_fock, batch_overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import inf\n",
    "best = inf\n",
    "early_stop_criteria =  10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearTargetModel(dataset = ml_data, nlayers = 1, nhidden = 16, bias = False, device = 'cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "val_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_focks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 23.890822617507865\n",
      "Epoch 0 val loss 23.890827610345298\n",
      "Epoch 10, train loss 0.25844257845675\n",
      "Epoch 10 val loss 0.2808343047151666\n",
      "Epoch 20, train loss 0.07868898373478944\n",
      "Epoch 20 val loss 0.056642496020292366\n",
      "Epoch 30, train loss 0.0030995529533909684\n",
      "Epoch 30 val loss 0.005510526882811492\n",
      "Epoch 40, train loss 0.014536936556569131\n",
      "Epoch 40 val loss 0.013285529380427562\n",
      "Epoch 50, train loss 0.0010134080183643297\n",
      "Epoch 50 val loss 0.0004910347735883092\n",
      "Epoch 60, train loss 0.00106229340354553\n",
      "Epoch 60 val loss 0.001180861165248113\n",
      "Epoch 70, train loss 0.0004542081681794029\n",
      "Epoch 70 val loss 0.0003260449352048469\n",
      "Epoch 80, train loss 4.7677173606573505e-05\n",
      "Epoch 80 val loss 7.065522318653241e-05\n",
      "Epoch 90, train loss 7.915291068666748e-05\n",
      "Epoch 90 val loss 6.283436181653282e-05\n",
      "Epoch 100, train loss 2.127319029450375e-06\n",
      "Epoch 100 val loss 4.63705931478635e-06\n",
      "Epoch 110, train loss 1.0708887809057119e-05\n",
      "Epoch 110 val loss 8.727589505492225e-06\n",
      "Epoch 120, train loss 2.403014203490348e-07\n",
      "Epoch 120 val loss 5.701865883884525e-07\n",
      "Epoch 130, train loss 1.3102374100861605e-06\n",
      "Epoch 130 val loss 1.0356571458630192e-06\n",
      "Epoch 140, train loss 7.216712145911522e-08\n",
      "Epoch 140 val loss 1.2692791141304945e-07\n",
      "Epoch 150, train loss 1.3779659434889915e-07\n",
      "Epoch 150 val loss 9.843194332139979e-08\n",
      "Epoch 160, train loss 2.4351050180029117e-08\n",
      "Epoch 160 val loss 3.194040208731063e-08\n",
      "Epoch 170, train loss 9.806474134499067e-09\n",
      "Epoch 170 val loss 5.395607161134187e-09\n",
      "Epoch 180, train loss 6.170391047569166e-09\n",
      "Epoch 180 val loss 6.466949815282122e-09\n",
      "Epoch 190, train loss 1.793740354206311e-10\n",
      "Epoch 190 val loss 1.5703071407531457e-11\n",
      "Epoch 200, train loss 9.97007724561119e-10\n",
      "Epoch 200 val loss 8.755541046240304e-10\n",
      "Epoch 210, train loss 3.765663423846066e-11\n",
      "Epoch 210 val loss 7.529584281605097e-11\n",
      "Epoch 220, train loss 9.404085720603172e-11\n",
      "Epoch 220 val loss 6.345609558895895e-11\n",
      "Epoch 230, train loss 2.5561345744374286e-11\n",
      "Epoch 230 val loss 3.081183157889612e-11\n",
      "Epoch 240, train loss 8.512056108605322e-12\n",
      "Epoch 240 val loss 6.887087700706133e-12\n",
      "Epoch 250, train loss 6.729639063688606e-12\n",
      "Epoch 250 val loss 7.536690746909916e-12\n",
      "Epoch 260, train loss 4.1475466444536875e-12\n",
      "Epoch 260 val loss 4.60197190620545e-12\n",
      "Epoch 270, train loss 4.058320346684626e-12\n",
      "Epoch 270 val loss 4.791822586722678e-12\n",
      "Epoch 280, train loss 4.0317516311540785e-12\n",
      "Epoch 280 val loss 4.8403112651203744e-12\n",
      "Epoch 290, train loss 3.7679114363345674e-12\n",
      "Epoch 290 val loss 4.788251473065859e-12\n"
     ]
    }
   ],
   "source": [
    "loss_fn = getattr(mlmetrics, 'L2_loss')\n",
    "losses=[]\n",
    "early_stop_count = 0\n",
    "for epoch in range(300):\n",
    "    model.train(True)\n",
    "    train_loss =0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = data['idx']\n",
    "        # print(batch_indices)\n",
    "        train_focks = model(data['input'], return_type='tensor', batch_indices=batch_indices).type(torch.float64)\n",
    "        with io.capture_output() as captured:\n",
    "        # with HiddenPrints():\n",
    "            if epoch == 0:\n",
    "                train_mfs, train_focks = instantiate_mf(ml_data, train_focks, batch_indices )\n",
    "            train_dip_pred = compute_dipole_moment_from_batchidx(ml_data, train_focks, batch_indices=batch_indices, mfs=train_mfs)\n",
    "            loss = loss_fn(train_dip_pred, ml_data.molecule_data.target['dipole_moment'][batch_indices])\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    # train_loss = loss_fn(torch.cat(train_pred), torch.cat(target))\n",
    "    # print(train_loss - epoch_loss)\n",
    "    losses.append(train_loss)\n",
    "    # scheduler.step(train_loss)\n",
    "    model.train(False)\n",
    "\n",
    "    if epoch% val_interval == 0:\n",
    "        val_loss = 0\n",
    "        for i, data in enumerate(val_dl):\n",
    "            batch_indices = data['idx']\n",
    "            val_focks = model(data['input'], return_type='tensor', batch_indices=batch_indices).type(torch.float64)\n",
    "            with io.capture_output() as captured:\n",
    "            # with HiddenPrints():\n",
    "                if epoch == 0:\n",
    "                    val_mfs, train_focks = instantiate_mf(ml_data, val_focks, batch_indices )\n",
    "                val_dip_pred = compute_dipole_moment_from_batchidx(ml_data, val_focks, batch_indices=batch_indices, mfs=val_mfs)\n",
    "            vloss = loss_fn(val_dip_pred, ml_data.molecule_data.target['dipole_moment'][batch_indices])\n",
    "            val_loss += vloss.item()\n",
    "        new_best = val_loss < best \n",
    "        if new_best:\n",
    "            best = val_loss\n",
    "            # torch.save(model.state_dict(), 'best_model_dipole.pt')\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count+=1\n",
    "        if early_stop_count > early_stop_criteria:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "            print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "            # Save last best model\n",
    "            break\n",
    "\n",
    "        # val_loss = loss_fn(torch.cat(val_pred), torch.cat(val))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "        print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TEST) MSE on dipole tensor(3.6236e-12, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with io.capture_output() as captured:\n",
    "    batch_indices = ml_data.test_idx\n",
    "    test_fock_predictions = model.forward(ml_data.feat_test, return_type='tensor').type(torch.float64)\n",
    "    # convert prediction back to pyscf order\n",
    "    test_mfs, test_focks = instantiate_mf(ml_data, test_fock_predictions, batch_indices )\n",
    "    test_dip_pred = compute_dipole_moment_from_batchidx(ml_data, test_fock_predictions, batch_indices=batch_indices, mfs=test_mfs)\n",
    "    # very imp to pass the right overlap matrix\n",
    "\n",
    "\n",
    "error = mlmetrics.L2_loss(test_dip_pred, ml_data.molecule_data.target['dipole_moment'][ml_data.test_idx])\n",
    "print('(TEST) MSE on dipole', error/len(test_dip_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the target dipole moment of water molecule in case data not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Number of frames:  1\n",
      "['0 O 1s    ', '0 O 2s    ', '0 O 2px   ', '0 O 2py   ', '0 O 2pz   ', '1 H 1s    ', '2 H 1s    ']\n",
      "converged: True\n",
      "Dipole moment(X, Y, Z, Debye):  1.50259,  1.24095,  0.00000\n"
     ]
    }
   ],
   "source": [
    "from mlelec.data.pyscf_calculator import calculator\n",
    "\n",
    "calc= calculator(\n",
    "        path=\"examples/data/water_1000/\",\n",
    "        mol_name=\"water_1000\",\n",
    "        frame_slice=\"0:1\",\n",
    "        target = ['fock', 'dipole_moment'],\n",
    "    )\n",
    "calc.calculate(   basis_set=\"sto-3g\", verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {8: ['1s', '2s', '2px', '2py', '2pz'], 1: ['1s']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc.ao_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 s\n",
      "2 s\n",
      "2 px\n",
      "2 py\n",
      "2 pz\n",
      "1 s\n",
      "{8: [[1, 0, 0], [2, 0, 0], [2, 1, 1], [2, 1, -1], [2, 1, 0]], 1: [[1, 0, 0]]}\n",
      "All done, results saved at:  examples/data/water/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/hickle/lookup.py:1491: SerializedWarning: 'Tensor' type not understood, data is serialized:\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "calc.save_results(path= 'examples/data/water/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad of dipole moment vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/62067400/understanding-accumulated-gradients-in-pytorch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_xyz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb Cell 33\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# grad of dipole moment\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m ifr, pred \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(predicted_xyz[:]):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m#gradient of the x component of the p vector\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     gradients[ifr][:, \u001b[39m0\u001b[39m,:] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(pred[\u001b[39m0\u001b[39m], systems[ifr]\u001b[39m.\u001b[39mpositions, retain_graph \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m#gradient of the y component of the p vector\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_xyz' is not defined"
     ]
    }
   ],
   "source": [
    "# grad of dipole moment\n",
    "\n",
    "\n",
    "for ifr, pred in enumerate(predicted_xyz[:]):\n",
    "    #gradient of the x component of the p vector\n",
    "    gradients[ifr][:, 0,:] = torch.autograd.grad(pred[0], systems[ifr].positions, retain_graph = True)[0]\n",
    "    #gradient of the y component of the p vector\n",
    "    gradients[ifr][:, 1,:] = torch.autograd.grad(pred[1], systems[ifr].positions, retain_graph = True)[0]\n",
    "    #gradient of the z component of the p vector\n",
    "    gradients[ifr][:, 2,:] = torch.autograd.grad(pred[2], systems[ifr].positions, retain_graph = True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
