{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.data.dataset import precomputed_molecules, MoleculeDataset, MLDataset\n",
    "import torch\n",
    "from ase.io import read\n",
    "import ase\n",
    "from mlelec.models.linear import LinearTargetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading structures\n",
      "examples/data/water_1000/sto-3g/fock.hickle\n"
     ]
    }
   ],
   "source": [
    "h_data = MoleculeDataset(mol_name='water_1000', frame_slice=slice(0,10), data_path = 'examples/data/water_1000/sto-3g', aux_path = 'examples/data/water_1000/sto-3g', device='cuda', aux=['overlap', 'orbitals']) #frames =frames, frame_slice=':4', target_data={'fock': h}, aux=['overlap', 'orbitals'],aux_data = {'overlap': over, 'orbitals':orbs }\n",
    "h_ml = MLDataset(molecule_data=h_data, device ='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_ml._shuffle(random_seed=5381)\n",
    "# h_ml._split_indices(train_frac=0.7, val_frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in h_ml.structures:\n",
    "    f.pbc = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training on a tiny dataset for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features with default hypers\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=448, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linmod = LinearTargetModel(dataset = h_ml, metrics = \"l2_loss\", nlayers = 1, nout = 1, nhidden = 10, bias = False, device = 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0\n",
      "tensor(69.3377, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(64.0011, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(54.5849, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(43.9524, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(37.2064, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(22.7818, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(34.2746, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(63.1520, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(72.0622, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(51.5382, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(linmod.parameters(), lr=0.01)\n",
    "for epoch in range(100):\n",
    "    loss = linmod.forward()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print(torch.sqrt(loss.detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default features and model is quite bad - so no wonder losses are high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0\n",
      "torch.Size([10, 7, 7])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "linmod.forward()\n",
    "fock = linmod.reconstructed_tensor\n",
    "print(fock.shape)\n",
    "print(fock.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fock = fock.type(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plugging in predicted fock matrix into pyscfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['PYSCFAD_BACKEND']='torch'\n",
    "\n",
    "import torch\n",
    "from pyscf import gto\n",
    "\n",
    "from pyscfad import numpy as np\n",
    "from pyscfad import ops\n",
    "from pyscfad.ml.scf import hf\n",
    "import pyscf.pbc.tools.pyscf_ase as pyscf_ase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mol = gto.Mole()\n",
    "mol.atom = pyscf_ase.ase_atoms_to_pyscf(h_ml.structures[0])\n",
    "mol.basis = 'sto-3g'\n",
    "mol.build()\n",
    "fock = linmod.reconstructed_tensor[0].type(torch.float64)\n",
    "\n",
    "\n",
    "mf = hf.SCF(mol)\n",
    "\n",
    "mo_energy, mo_coeff = mf.eig(fock, s = torch.eye(fock.shape[-1], dtype = fock.dtype))\n",
    "mo_occ = mf.get_occ(mo_energy) # get_occ returns a numpy array\n",
    "mo_occ = ops.convert_to_tensor(mo_occ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fock.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dipole moment(X, Y, Z, Debye):  2.58983,  2.45573,  0.05366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243680/3406526284.py:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(fock.grad)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dm1 = mf.make_rdm1(mo_coeff, mo_occ)\n",
    "dip = mf.dip_moment(dm=dm1)\n",
    "dip_norm = np.linalg.norm(dip)\n",
    "dip_norm.backward()\n",
    "print(fock.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mocc = mo_coeff[:, mo_occ>0]\n",
    "dm = np.dot(mocc*mo_occ[mo_occ>0], mocc.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(mocc.dtype)\n",
    "print(mo_occ[mo_occ>0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(mocc.conj().T.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
