{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.data.dataset import precomputed_molecules, MoleculeDataset, MLDataset\n",
    "import torch\n",
    "from ase.io import read\n",
    "import ase\n",
    "from mlelec.models.linear import LinearTargetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=11, micro=5, releaselevel='final', serial=0)\n",
      "2.3.0\n",
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import pyscf, pyscfad\n",
    "print(sys.version_info)\n",
    "print(pyscf.__version__)\n",
    "print(pyscfad.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading structures\n",
      "examples/data/water_1000/sto-3g/fock.hickle\n"
     ]
    }
   ],
   "source": [
    "h_data = MoleculeDataset(mol_name='water_1000', frame_slice=slice(0,10), data_path = 'examples/data/water_1000/sto-3g', aux_path = 'examples/data/water_1000/sto-3g', device='cuda', aux=['overlap', 'orbitals']) #frames =frames, frame_slice=':4', target_data={'fock': h}, aux=['overlap', 'orbitals'],aux_data = {'overlap': over, 'orbitals':orbs }\n",
    "h_ml = MLDataset(molecule_data=h_data, device ='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_ml._shuffle(random_seed=5381)\n",
    "# h_ml._split_indices(train_frac=0.7, val_frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in h_ml.structures:\n",
    "    f.pbc = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training on a tiny dataset for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features with default hypers\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=448, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "cuda:0 cuda\n",
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=10, bias=False)\n",
      "    (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linmod = LinearTargetModel(dataset = h_ml, metrics = \"l2_loss\", nlayers = 1, nout = 1, nhidden = 10, bias = False, device = 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0\n",
      "tensor(69.5520, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(64.4067, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(55.1426, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(44.9666, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(38.5308, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(23.0004, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(32.7668, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(62.2783, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(72.8176, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "tensor(52.2252, device='cuda:0', dtype=torch.float64)\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n",
      "cuda:0 cuda:0\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(linmod.parameters(), lr=0.01)\n",
    "for epoch in range(100):\n",
    "    loss = linmod.forward()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print(torch.sqrt(loss.detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default features and model is quite bad - so no wonder losses are high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0\n",
      "torch.Size([10, 7, 7])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "linmod.forward()\n",
    "fock = linmod.reconstructed_tensor\n",
    "print(fock.shape)\n",
    "print(fock.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plugging in predicted fock matrix into pyscfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['PYSCFAD_BACKEND']='torch'\n",
    "\n",
    "import torch\n",
    "from pyscf import gto\n",
    "\n",
    "from pyscfad import numpy as np\n",
    "from pyscfad import ops\n",
    "from pyscfad.ml.scf import hf\n",
    "import pyscf.pbc.tools.pyscf_ase as pyscf_ase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-23.2849,  -2.7638,   0.7262,   0.0000,   0.8035,  -1.1535,  -1.3145],\n",
       "        [ -2.7638,  -8.5905,   0.7166,   0.0000,   0.8957,  -2.0820,  -2.2938],\n",
       "        [  0.7262,   0.7166,  -1.8219,   0.0000,   0.2043,  -0.6207,   0.9639],\n",
       "        [  0.0000,   0.0000,   0.0000,  -4.7920,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.8035,   0.8957,   0.2043,   0.0000,  -1.9606,   0.9687,  -0.3907],\n",
       "        [ -1.1535,  -2.0820,  -0.6207,   0.0000,   0.9687,  -3.2221,  -1.4339],\n",
       "        [ -1.3145,  -2.2938,   0.9639,   0.0000,  -0.3907,  -1.4339,  -3.1479]],\n",
       "       device='cuda:0', dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mol = gto.Mole()\n",
    "mol.atom = pyscf_ase.ase_atoms_to_pyscf(h_ml.structures[0])\n",
    "mol.basis = 'sto-3g'\n",
    "mol.build()\n",
    "f = linmod.reconstructed_tensor[0].type(torch.float64)\n",
    "f = torch.autograd.Variable(linmod.reconstructed_tensor[0].type(torch.float64), requires_grad=True)\n",
    "\n",
    "mf = hf.SCF(mol)\n",
    "\n",
    "mo_energy, mo_coeff = mf.eig(f, s = torch.eye(f.shape[-1], dtype = f.dtype))\n",
    "mo_occ = mf.get_occ(mo_energy) # get_occ returns a numpy array\n",
    "mo_occ = ops.convert_to_tensor(mo_occ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dipole moment(X, Y, Z, Debye): -3.31932, -2.92907,  0.84495\n"
     ]
    }
   ],
   "source": [
    "dm1 = mf.make_rdm1(mo_coeff, mo_occ)\n",
    "dip = mf.dip_moment(dm=dm1)\n",
    "dip_norm = np.linalg.norm(dip)\n",
    "dip_norm.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7105e-03,  6.3625e-03,  2.9021e-02, -2.2379e-03,  1.1759e-02,\n",
      "         -3.4497e-02,  9.9262e-03],\n",
      "        [ 6.3625e-03,  2.6275e-02, -4.1789e-03, -9.8700e-03,  1.0243e-01,\n",
      "         -7.3472e-02, -4.3468e-02],\n",
      "        [ 2.9021e-02, -4.1789e-03,  1.0441e-01, -1.0558e-01, -3.9019e-01,\n",
      "         -5.5819e-01, -2.6806e-01],\n",
      "        [-2.2379e-03, -9.8700e-03, -1.0558e-01,  6.9081e-18, -7.8187e-03,\n",
      "          5.6591e-02, -5.4898e-02],\n",
      "        [ 1.1759e-02,  1.0243e-01, -3.9019e-01, -7.8187e-03,  5.4390e-01,\n",
      "         -2.1696e-01, -9.5179e-02],\n",
      "        [-3.4497e-02, -7.3472e-02, -5.5819e-01,  5.6591e-02, -2.1696e-01,\n",
      "         -1.5031e-02,  3.6295e-01],\n",
      "        [ 9.9262e-03, -4.3468e-02, -2.6806e-01, -5.4898e-02, -9.5179e-02,\n",
      "          3.6295e-01, -6.6127e-01]], device='cuda:0', dtype=torch.float64)\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_276342/1385404797.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(fock.grad)\n"
     ]
    }
   ],
   "source": [
    "print(f.grad)\n",
    "print(fock.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5068, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dip_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dip_norm.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:244\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    235\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    236\u001b[0m     (inputs,)\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    241\u001b[0m )\n\u001b[1;32m    243\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 244\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:117\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_floating_point:\n\u001b[1;32m    121\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "fock.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
