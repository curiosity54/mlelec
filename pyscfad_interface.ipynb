{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.data.dataset import precomputed_molecules, MoleculeDataset, MLDataset, get_dataloader\n",
    "import torch\n",
    "from ase.io import read\n",
    "import ase\n",
    "from mlelec.models.linear import LinearTargetModel\n",
    "from mlelec.features.acdc import compute_features_for_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=11, micro=5, releaselevel='final', serial=0)\n",
      "2.3.0\n",
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import pyscf, pyscfad\n",
    "print(sys.version_info)\n",
    "print(pyscf.__version__)\n",
    "print(pyscfad.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading structures\n",
      "examples/data/water_1000/sto-3g/fock.hickle\n",
      "examples/data/water_1000/sto-3g/dipole_moment.hickle\n",
      "Computing features with default hypers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/rascaline/systems/ase.py:57: UserWarning: periodic boundary conditions are disabled, but the cell matrix is not zero, we will set the cell to zero.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "water_data = MoleculeDataset(mol_name='water_1000', frame_slice=slice(0,100),  device='cuda', aux=['overlap', 'orbitals'], target=[\"fock\", \"dipole_moment\"])\n",
    "ml_data = MLDataset(molecule_data=water_data, device ='cuda', model_strategy = \"coupled\")\n",
    "\n",
    "ml_data._shuffle(random_seed=5380)\n",
    "ml_data._split_indices(train_frac=0.7, val_frac=0.2)\n",
    "#assumed args.model_type = 'acdc'\n",
    "if ml_data.features is None: \n",
    "    ml_data._set_features(compute_features_for_target(ml_data, device='cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl = get_dataloader(ml_data, model_return= 'tensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training on a tiny dataset for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearTargetModel(dataset = ml_data, nlayers = 1, nhidden = 16, bias = False, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import inf\n",
    "best = inf\n",
    "early_stop_criteria =  10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y101sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mif\u001b[39;00m epoch\u001b[39m%\u001b[39m val_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y101sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# val_pred = []\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y101sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# val= []\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y101sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     val_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y101sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, data \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(val_dl):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y101sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         pred \u001b[39m=\u001b[39;49m model(data[\u001b[39m'\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m'\u001b[39;49m], return_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtensor\u001b[39;49m\u001b[39m'\u001b[39;49m, batch_indices\u001b[39m=\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39midx\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#Y101sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         vloss \u001b[39m=\u001b[39;49m loss_fn(pred, data[\u001b[39m'\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/media/nigam/b5749eb7-d3f1-4495-adeb-2c318fb7d0de/MAC/my_mlelec/src/mlelec/data/dataset.py:270\u001b[0m, in \u001b[0;36mMLDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    268\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mFeatures not set, call _set_features() first\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 270\u001b[0m     x \u001b[39m=\u001b[39m operations\u001b[39m.\u001b[39;49mslice(\n\u001b[1;32m    271\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures,\n\u001b[1;32m    272\u001b[0m         axis\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msamples\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    273\u001b[0m         labels\u001b[39m=\u001b[39;49mLabels(\n\u001b[1;32m    274\u001b[0m             names\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mstructure\u001b[39;49m\u001b[39m\"\u001b[39;49m], values\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49masarray([idx])\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    275\u001b[0m         ),\n\u001b[1;32m    276\u001b[0m     )\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_return \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblocks\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    278\u001b[0m         y \u001b[39m=\u001b[39m operations\u001b[39m.\u001b[39mslice(\n\u001b[1;32m    279\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mblocks,\n\u001b[1;32m    280\u001b[0m             axis\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m             ),\n\u001b[1;32m    284\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/metatensor/operations/slice.py:87\u001b[0m, in \u001b[0;36mslice\u001b[0;34m(tensor, axis, labels)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     80\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`tensor` must be a metatensor TensorMap, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     83\u001b[0m _check_args(tensor\u001b[39m.\u001b[39mblock(\u001b[39m0\u001b[39m), axis\u001b[39m=\u001b[39maxis, labels\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m TensorMap(\n\u001b[1;32m     86\u001b[0m     keys\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mkeys,\n\u001b[0;32m---> 87\u001b[0m     blocks\u001b[39m=\u001b[39m[\n\u001b[1;32m     88\u001b[0m         _slice_block(tensor[tensor\u001b[39m.\u001b[39;49mkeys\u001b[39m.\u001b[39;49mentry(i)], axis, labels)\n\u001b[1;32m     89\u001b[0m         \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(tensor\u001b[39m.\u001b[39;49mkeys))\n\u001b[1;32m     90\u001b[0m     ],\n\u001b[1;32m     91\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/metatensor/operations/slice.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     80\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`tensor` must be a metatensor TensorMap, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     83\u001b[0m _check_args(tensor\u001b[39m.\u001b[39mblock(\u001b[39m0\u001b[39m), axis\u001b[39m=\u001b[39maxis, labels\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m TensorMap(\n\u001b[1;32m     86\u001b[0m     keys\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mkeys,\n\u001b[1;32m     87\u001b[0m     blocks\u001b[39m=\u001b[39m[\n\u001b[0;32m---> 88\u001b[0m         _slice_block(tensor[tensor\u001b[39m.\u001b[39;49mkeys\u001b[39m.\u001b[39;49mentry(i)], axis, labels)\n\u001b[1;32m     89\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(tensor\u001b[39m.\u001b[39mkeys))\n\u001b[1;32m     90\u001b[0m     ],\n\u001b[1;32m     91\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/metatensor/operations/slice.py:219\u001b[0m, in \u001b[0;36m_slice_block\u001b[0;34m(block, axis, labels)\u001b[0m\n\u001b[1;32m    214\u001b[0m sample_map \u001b[39m=\u001b[39m _dispatch\u001b[39m.\u001b[39mint_array_like(\n\u001b[1;32m    215\u001b[0m     int_list\u001b[39m=\u001b[39m[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(samples_mask),\n\u001b[1;32m    216\u001b[0m     like\u001b[39m=\u001b[39msamples_mask,\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m last \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 219\u001b[0m \u001b[39mfor\u001b[39;00m i, picked \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(samples_mask):\n\u001b[1;32m    220\u001b[0m     \u001b[39mif\u001b[39;00m picked:\n\u001b[1;32m    221\u001b[0m         sample_map[i] \u001b[39m=\u001b[39m last\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:1000\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state():\n\u001b[1;32m    992\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    993\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    994\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a tensor of different shape won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt change the number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[0;32m-> 1000\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munbind(\u001b[39m0\u001b[39;49m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, verbose=True)\n",
    "import mlelec.metrics as mlmetrics\n",
    "val_interval = 10\n",
    "loss_fn = getattr(mlmetrics, 'L2_loss')\n",
    "losses=[]\n",
    "early_stop_count = 0\n",
    "for epoch in range(300):\n",
    "    # train_pred = []\n",
    "    # target=[]\n",
    "    model.train(True)\n",
    "    train_loss =0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data['input'], return_type='tensor', batch_indices=data['idx'])\n",
    "        # target.append(data['output'])\n",
    "        # train_pred.append(pred)\n",
    "        loss = loss_fn(pred, data['output'])\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # train_loss = loss_fn(torch.cat(train_pred), torch.cat(target))\n",
    "    # print(train_loss - epoch_loss)\n",
    "    losses.append(train_loss)\n",
    "    # scheduler.step(train_loss)\n",
    "    model.train(False)\n",
    "\n",
    "    if epoch% val_interval == 0:\n",
    "        # val_pred = []\n",
    "        # val= []\n",
    "        val_loss = 0\n",
    "        for i, data in enumerate(val_dl):\n",
    "            pred = model(data['input'], return_type='tensor', batch_indices=data['idx'])\n",
    "            vloss = loss_fn(pred, data['output'])\n",
    "            val_loss += vloss.item()\n",
    "            # val.append(data['output'])\n",
    "            # val_pred.append(pred)\n",
    "        new_best = val_loss < best \n",
    "        if new_best:\n",
    "            best = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count+=1\n",
    "        if early_stop_count > early_stop_criteria:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "            print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "            # Save last best model\n",
    "            break\n",
    "\n",
    "        # val_loss = loss_fn(torch.cat(val_pred), torch.cat(val))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "        print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nigam/scratch/MAC/my_mlelec/pyscfad_interface.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mloglog(losses)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.loglog(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input model prediction into pyscf to compute dipole moment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSCFAD_BACKEND']='torch'\n",
    "\n",
    "import torch\n",
    "from pyscf import gto\n",
    "\n",
    "from pyscfad import numpy as np\n",
    "from pyscfad import ops\n",
    "from pyscfad.ml.scf import hf\n",
    "import pyscf.pbc.tools.pyscf_ase as pyscf_ase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.data.pyscf_calculator import _instantiate_pyscf_mol\n",
    "from mlelec.utils.twocenter_utils import fix_orbital_order, unfix_orbital_order\n",
    "import mlelec.metrics as mlmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys._jupyter_stdout = sys.stdout\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys._jupyter_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dipole_moment(frames, fock_predictions, overlaps):\n",
    "    dipoles  = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        mol = _instantiate_pyscf_mol(frame)\n",
    "        mf = hf.SCF(mol)\n",
    "        fock = torch.autograd.Variable(fock_predictions[i].type(torch.float64), requires_grad=True)\n",
    "\n",
    "        mo_energy, mo_coeff = mf.eig(fock, overlaps[i])\n",
    "        mo_occ = mf.get_occ(mo_energy) # get_occ returns a numpy array\n",
    "        mo_occ = ops.convert_to_tensor(mo_occ)\n",
    "        dm1 = mf.make_rdm1(mo_coeff, mo_occ)\n",
    "        dip = mf.dip_moment(dm=dm1)\n",
    "        dipoles.append(dip)\n",
    "    return torch.stack(dipoles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.utils import io\n",
    "# with HiddenPrints():\n",
    "with io.capture_output() as captured:\n",
    "\n",
    "    fock_predictions = model.forward(ml_data.features, return_type='tensor')\n",
    "    # convert prediction back to pyscf order \n",
    "    fock_predictions = unfix_orbital_order(fock_predictions, ml_data.structures, ml_data.molecule_data.aux_data['orbitals'])\n",
    "    dipole_predictions = compute_dipole_moment(ml_data.structures, fock_predictions,ml_data.molecule_data.aux_data['overlap']); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on dipole tensor(1.2969, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "error = mlmetrics.L2_loss(dipole_predictions, ml_data.molecule_data.target['dipole_moment'])\n",
    "print('MSE on dipole', error/len(dipole_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect learning of dipole moment through pyscfad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlelec.metrics as mlmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dipole_moment_from_batchidx(ml_data: MLDataset, batch_fock, batch_indices):\n",
    "    # Convert fock predictions back to pyscf order\n",
    "    # Compute dipole moment for each molecule in batch\n",
    "    batch_frames = [ml_data.structures[i] for i in batch_indices]\n",
    "    batch_fock = unfix_orbital_order(batch_fock, batch_frames, ml_data.molecule_data.aux_data['orbitals'])\n",
    "    batch_overlap = ml_data.molecule_data.aux_data['overlap'][batch_indices]\n",
    "    return compute_dipole_moment(batch_frames, batch_fock, batch_overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import inf\n",
    "best = inf\n",
    "early_stop_criteria =  10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearTargetModel(dataset = ml_data, nlayers = 1, nhidden = 16, bias = False, device = 'cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "val_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 5.532426070307148\n",
      "Epoch 0 val loss 3.5213770260359607\n",
      "Epoch 10, train loss 5.544810590305144\n",
      "Epoch 10 val loss 4.055684175440703\n",
      "Epoch 20, train loss 4.964313791188237\n",
      "Epoch 20 val loss 6.295765874356405\n"
     ]
    }
   ],
   "source": [
    "loss_fn = getattr(mlmetrics, 'L2_loss')\n",
    "losses=[]\n",
    "early_stop_count = 0\n",
    "for epoch in range(300):\n",
    "    model.train(True)\n",
    "    train_loss =0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = data['idx']\n",
    "        pred = model(data['input'], return_type='tensor', batch_indices=batch_indices)\n",
    "        with io.capture_output() as captured:\n",
    "        # with HiddenPrints():\n",
    "            train_dip_pred = compute_dipole_moment_from_batchidx(ml_data, pred, batch_indices=batch_indices)\n",
    "        loss = loss_fn(train_dip_pred, ml_data.molecule_data.target['dipole_moment'][batch_indices])\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # train_loss = loss_fn(torch.cat(train_pred), torch.cat(target))\n",
    "    # print(train_loss - epoch_loss)\n",
    "    losses.append(train_loss)\n",
    "    # scheduler.step(train_loss)\n",
    "    model.train(False)\n",
    "\n",
    "    if epoch% val_interval == 0:\n",
    "        val_loss = 0\n",
    "        for i, data in enumerate(val_dl):\n",
    "            batch_indices = data['idx']\n",
    "            pred = model(data['input'], return_type='tensor', batch_indices=batch_indices)\n",
    "            with io.capture_output() as captured:\n",
    "            # with HiddenPrints():\n",
    "                val_dip_pred = compute_dipole_moment_from_batchidx(ml_data, pred, batch_indices=batch_indices)\n",
    "            vloss = loss_fn(val_dip_pred, ml_data.molecule_data.target['dipole_moment'][batch_indices])\n",
    "            val_loss += vloss.item()\n",
    "        new_best = val_loss < best \n",
    "        if new_best:\n",
    "            best = val_loss\n",
    "            # torch.save(model.state_dict(), 'best_model_dipole.pt')\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count+=1\n",
    "        if early_stop_count > early_stop_criteria:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "            print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "            # Save last best model\n",
    "            break\n",
    "\n",
    "        # val_loss = loss_fn(torch.cat(val_pred), torch.cat(val))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, train loss {train_loss/len(ml_data.train_idx)}')\n",
    "\n",
    "        print(f'Epoch {epoch} val loss {val_loss/len(ml_data.val_idx)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default features and model is quite bad - so no wonder losses are high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/62067400/understanding-accumulated-gradients-in-pytorch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad of dipole moment\n",
    "\n",
    "\n",
    "for ifr, pred in enumerate(predicted_xyz[:]):\n",
    "    #gradient of the x component of the p vector\n",
    "    gradients[ifr][:, 0,:] = torch.autograd.grad(pred[0], systems[ifr].positions, retain_graph = True)[0]\n",
    "    #gradient of the y component of the p vector\n",
    "    gradients[ifr][:, 1,:] = torch.autograd.grad(pred[1], systems[ifr].positions, retain_graph = True)[0]\n",
    "    #gradient of the z component of the p vector\n",
    "    gradients[ifr][:, 2,:] = torch.autograd.grad(pred[2], systems[ifr].positions, retain_graph = True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the target dipole moment of water molecule in case data not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Number of frames:  1\n",
      "['0 O 1s    ', '0 O 2s    ', '0 O 2px   ', '0 O 2py   ', '0 O 2pz   ', '1 H 1s    ', '2 H 1s    ']\n",
      "converged: True\n",
      "Dipole moment(X, Y, Z, Debye):  1.50259,  1.24095,  0.00000\n"
     ]
    }
   ],
   "source": [
    "from mlelec.data.pyscf_calculator import calculator\n",
    "\n",
    "calc= calculator(\n",
    "        path=\"examples/data/water_1000/\",\n",
    "        mol_name=\"water_1000\",\n",
    "        frame_slice=\"0:1\",\n",
    "        target = ['fock', 'dipole_moment'],\n",
    "    )\n",
    "calc.calculate(   basis_set=\"sto-3g\", verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {8: ['1s', '2s', '2px', '2py', '2pz'], 1: ['1s']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc.ao_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 s\n",
      "2 s\n",
      "2 px\n",
      "2 py\n",
      "2 pz\n",
      "1 s\n",
      "{8: [[1, 0, 0], [2, 0, 0], [2, 1, 1], [2, 1, -1], [2, 1, 0]], 1: [[1, 0, 0]]}\n",
      "All done, results saved at:  examples/data/water/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigam/miniconda3/lib/python3.11/site-packages/hickle/lookup.py:1491: SerializedWarning: 'Tensor' type not understood, data is serialized:\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "calc.save_results(path= 'examples/data/water/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
