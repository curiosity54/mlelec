{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78f2d86-1a50-4563-a7e3-5030f90b9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff7f489-6851-4c0c-b338-ebc5c0b876b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a81961a6-71b7-45ac-972a-c25502f8a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_list = torch.from_numpy(np.array([p for p in product(range(4), range(4), range(1))], dtype = np.float64))\n",
    "k = torch.Tensor([1.,2.,0.]).to(T_list).reshape(1,-1)\n",
    "H_T = torch.randn(T_list.shape[0], 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d01c5c34-7c61-4a1f-9589-7e96951dbcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b099e71f-1da8-4bf4-b567-3cfab8dceb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc9a3bd1-2e69-44d4-a128-a1ba0c7cda7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): the number of subscripts in the equation (2) does not match the number of dimensions (1) for operand 1 and no ellipsis was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTa,ka->Tk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/sci/lib/python3.11/site-packages/torch/functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (2) does not match the number of dimensions (1) for operand 1 and no ellipsis was given"
     ]
    }
   ],
   "source": [
    "torch.einsum('Ta,ka->Tk', T_list, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c18382b5-1ce2-4011-819a-3ef313ca1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = torch.exp(2j * np.pi * torch.tensordot(T_list, k, dims = ([-1],[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95b90d09-be21-4dd1-97dd-3aa137082097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed486e83-a21e-49ab-b47e-0db7325d9a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 10])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5edfcbe-f5a6-477f-a106-61ff7f9517d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensordot(H_T.to(phase), phase, dims = ([0], [0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1f3d534-5b08-4a67-872a-82c78822782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "he=torch.einsum('Tab,Tk->kab', H_T.to(phase), phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00989939-6cd0-4fa8-8131-d9aba0a31abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = torch.tensordot(H_T.to(phase), phase, dims = ([0], [0])).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbd5a5f8-937a-4c11-a68a-6f343cedc09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2 µs ± 13.2 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "torch.einsum('Ta,a->T', T_list, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e138d1c8-618d-45c2-97b0-17798acd258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9 µs ± 34.7 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "torch.tensordot(T_list, k, dims = ([1],[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff84274a-981b-4bb7-86f0-eadf1e6ae409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "from ase.visualize import view\n",
    "import numpy as np \n",
    "import torch \n",
    "import metatensor \n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e3f35a-1f9b-4a49-a7a2-a87d35808a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pegolo/micromamba/envs/sci/lib/python3.11/site-packages/pyscf/dft/libxc.py:771: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, corresponding to the original definition by Stephens et al. (issue 1480) and the same as the B3LYP functional in Gaussian. To restore the VWN5 definition, you can put the setting \"B3LYP_WITH_VWN5 = True\" in pyscf_conf.py\n",
      "  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '\n"
     ]
    }
   ],
   "source": [
    "from metatensor import Labels, TensorBlock, TensorMap\n",
    "from mlelec.data.dataset import QMDataset\n",
    "from mlelec.utils.twocenter_utils import fix_orbital_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3a65d4-9d55-4229-b59c-31d4d6a44bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbitals = {'sto-3g': {6: [[1,0,0],[2,0,0],[2,1,1], [2,1,-1],[2,1,0]]}, \n",
    "            'def2svp': {6: [[1,0,0],[2,0,0],[3,0,0],[2,1,1], [2,1,-1],[2,1,0], [3,1,1], [3,1,-1],[3,1,0], [3,2,-2], [3,2,-1],[3,2,0], [3,2,1],[3,2,2]]},\n",
    "           'gthszvmolopt': {6: [[2, 0, 0], \n",
    "                         [2, 1, 1], [2, 1, -1], [2, 1, 0]]\n",
    "                            }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1809e8e9-e0c6-42cf-aaec-65a986b42fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING!\n",
      "  Very diffused basis functions are found in the basis set. They may lead to severe\n",
      "  linear dependence and numerical instability.  You can set  cell.exp_to_discard=0.1\n",
      "  to remove the diffused Gaussians whose exponents are less than 0.1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workdir = '/home/pegolo/Software/my_mlelec/'\n",
    "root = f'{workdir}/examples/data/periodic/c2'\n",
    "ORBS = 'gthszvmolopt'\n",
    "START = 0\n",
    "STOP = 1\n",
    "frames = read(f'{root}/C2_174.extxyz', slice(START, STOP))\n",
    "for f in frames: \n",
    "    f.pbc = True\n",
    "\n",
    "kmesh = [15,15,1]\n",
    "kfock = [1/15*np.load(f\"{root}/cp2k/fock_{i}.npy\") for i in range(START, STOP)]\n",
    "kover = [1/15*np.load(f\"{root}/cp2k/overlap_{i}.npy\") for i in range(START, STOP)]\n",
    "for ifr in range(len(frames)):\n",
    "    for ik, k in enumerate(kfock[ifr]):\n",
    "        kfock[ifr][ik] = fix_orbital_order(k, frames[ifr], orbitals[ORBS]) #### TODO <<\n",
    "        kover[ifr][ik] = fix_orbital_order(kover[ifr][ik], frames[ifr], orbitals[ORBS]) #### TODO <<\n",
    "\n",
    "dataset = QMDataset(frames = frames, kmesh = kmesh, fock_kspace = kfock, overlap_kspace = kover, device = \"cpu\", orbs = orbitals[ORBS], orbs_name = ORBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97646a42-ed95-47a6-aedf-df03b14aad5a",
   "metadata": {},
   "source": [
    "# Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "581bd550-3137-474d-b482-ee8e40a1adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatensor import load \n",
    "from mlelec.utils.twocenter_utils import _to_coupled_basis\n",
    "from mlelec.utils.pbc_utils import matrix_to_blocks \n",
    "from mlelec.utils.symmetry import ClebschGordanReal\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "def get_targets(dataset, device =\"cpu\", cutoff = None, target='fock', cg = None):\n",
    "    if target.lower() == 'fock':\n",
    "        matrices_negative = dataset._fock_realspace_negative_translations\n",
    "    elif target.lower() == 'overlap':\n",
    "        matrices_negative = dataset._overlap_realspace_negative_translations\n",
    "    else: \n",
    "        raise ValueError('target must be fock or overlap')\n",
    "    blocks = matrix_to_blocks(dataset, matrices_negative , device = 'cpu', cutoff = cutoff, all_pairs = True, target= target)\n",
    "    coupled_blocks = _to_coupled_basis(blocks, skip_symmetry = True, device = device, translations = True, cg = cg)\n",
    "\n",
    "    blocks = blocks.keys_to_samples('cell_shift_a')\n",
    "    blocks = blocks.keys_to_samples('cell_shift_b')\n",
    "    blocks = blocks.keys_to_samples('cell_shift_c')\n",
    "\n",
    "    coupled_blocks = coupled_blocks.keys_to_samples('cell_shift_a')\n",
    "    coupled_blocks = coupled_blocks.keys_to_samples('cell_shift_b')\n",
    "    coupled_blocks = coupled_blocks.keys_to_samples('cell_shift_c')\n",
    "    return blocks, coupled_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "254c2686-e4c1-48e8-b2f8-1d72b18b54f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6\n",
    "CG = ClebschGordanReal(lmax = 3, device = device)\n",
    "target_blocks, target_coupled_blocks = get_targets(dataset, cutoff = cutoff, cg = CG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a0e548-c495-40c9-a7d6-d724651dc57f",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bdf210b-2edd-469e-a682-32500d00d568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cutoff': 6, 'max_radial': 10, 'max_angular': 4, 'atomic_gaussian_width': 0.3, 'center_atom_weight': 1, 'radial_basis': {'Gto': {}}, 'cutoff_function': {'ShiftedCosine': {'width': 0.1}}}\n",
      "torch.Size([92, 1, 10]) 1\n",
      "torch.Size([182, 1, 10]) 2\n",
      "torch.Size([92, 3, 10]) 1\n",
      "torch.Size([182, 3, 10]) 2\n",
      "torch.Size([92, 5, 10]) 1\n",
      "torch.Size([182, 5, 10]) 2\n",
      "torch.Size([92, 7, 10]) 1\n",
      "torch.Size([182, 7, 10]) 2\n",
      "torch.Size([92, 9, 10]) 1\n",
      "torch.Size([182, 9, 10]) 2\n"
     ]
    }
   ],
   "source": [
    "from mlelec.features.acdc import pair_features, single_center_features, twocenter_features_periodic_NH\n",
    "\n",
    "hypers_pair = {'cutoff': cutoff,\n",
    "               'max_radial': 10,\n",
    "               'max_angular': 4,\n",
    "               'atomic_gaussian_width': 0.3,\n",
    "               'center_atom_weight': 1,\n",
    "               \"radial_basis\": {\"Gto\": {}},\n",
    "               \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.1}}}\n",
    "\n",
    "hypers_atom = {'cutoff': 4,\n",
    "               'max_radial': 10,\n",
    "               'max_angular': 4,\n",
    "               'atomic_gaussian_width': 0.3,\n",
    "               'center_atom_weight': 1,\n",
    "               \"radial_basis\": {\"Gto\": {}},\n",
    "               \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.1}}}\n",
    "\n",
    "return_rho0ij = False\n",
    "both_centers = False\n",
    "all_pairs = False\n",
    "LCUT = 3\n",
    "\n",
    "rhoij = pair_features(dataset.structures, hypers_atom, hypers_pair, order_nu = 1, all_pairs = all_pairs, both_centers = both_centers, mic = False,\n",
    "                      kmesh = dataset.kmesh, device=\"cpu\", lcut = LCUT, return_rho0ij = return_rho0ij, counter = dataset._translation_counter, \n",
    "                      T_dict = dataset._translation_dict)\n",
    "\n",
    "if both_centers and not return_rho0ij:\n",
    "    NU = 3\n",
    "else:\n",
    "    NU = 2\n",
    "rhonui = single_center_features(dataset.structures, hypers_atom, order_nu = NU, lcut = LCUT, device = 'cpu',\n",
    "                                feature_names = rhoij.property_names)\n",
    "\n",
    "hfeat = twocenter_features_periodic_NH(single_center = rhonui, pair = rhoij, all_pairs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "610cd108-9ae2-4a78-a32a-577b8e8dae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatensor import slice as mts_slice\n",
    "trainidx = list(range(6))\n",
    "testidx = list(range(6,10))\n",
    "train_label = Labels(names=[\"structure\"], values = np.array(trainidx).reshape(-1,1))\n",
    "test_label = Labels(names=[\"structure\"], values = np.array(testidx).reshape(-1,1))\n",
    "\n",
    "hfeat_train = mts_slice(hfeat, 'samples', train_label)\n",
    "hfeat_test =  mts_slice(hfeat, 'samples', test_label)\n",
    "target_train = mts_slice(target_coupled_blocks, 'samples', train_label)\n",
    "target_test = mts_slice(target_coupled_blocks, 'samples', test_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022d47c-ab76-4f8e-8dcf-b723ec0ca0d7",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8db97c7b-9fb8-4d04-a178-5f71b043c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.metrics import L2_loss, L2_kspace_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "08976598-e775-4a41-8a87-c1dacec8462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.models.linear import LinearModelPeriodic\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71867f41-9a3e-43e0-9d34-0294be993f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModelPeriodic(twocfeat = hfeat_train, \n",
    "                                  target_blocks = target_train,\n",
    "                                  frames = dataset.structures, orbitals = dataset.basis, \n",
    "                                  device = device,\n",
    "                           nhidden=16, nlayers=3)\n",
    "\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b023f128-d71c-4fdf-b921-6589af41c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.5, patience = 30, verbose=True)\n",
    "\n",
    "# optimizer = torch.optim.LBFGS(model.parameters(), lr=1e-4, history_size=10, \n",
    "#                     max_iter=4, \n",
    "#                     line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, factor=0.5, patience=10, verbose=True\n",
    "# )\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)# last_epoch=-1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "539d7a41-0565-4bf9-b54f-566ca0d6a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.pbc_utils import blocks_to_matrix\n",
    "target_kspace = dataset.compute_matrices_kspace(blocks_to_matrix(target_train, dataset, cg = CG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9595c01-5772-465f-8cb2-6baea689b389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# losses =[]\n",
    "\n",
    "def train_model(model, optimizer, loss_func = 'kspace', scheduler = None, nepoch = 1000, dataset = None):\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(nepoch):\n",
    "        \n",
    "        model.train(True)\n",
    "        # def closure():\n",
    "        #     optimizer.zero_grad()\n",
    "        #     pred = model.forward()\n",
    "        #     loss = L2_loss(pred, target_train)\n",
    "        #     # loss = torch.linalg.norm(rmat - matrices)**2\n",
    "        #     loss.backward()\n",
    "        #     return loss\n",
    "    \n",
    "        # optimizer.step(closure)\n",
    "        # train_loss = closure().item()\n",
    "        #ADAM \n",
    "        optimizer.zero_grad()\n",
    "        pred = model()\n",
    "        # target.append(data['output'])\n",
    "        # train_pred.append(pred)\n",
    "        if loss_func == 'kspace':\n",
    "            loss = L2_kspace_loss(pred, target_kspace, dataset, cg = CG)\n",
    "        else:\n",
    "            loss = L2_loss(pred, target_train)\n",
    "        train_loss = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # train_loss = loss_fn(torch.cat(train_pred), torch.cat(target))\n",
    "        # print(train_loss - epoch_loss)\n",
    "        losses.append(train_loss)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "    \n",
    "            # val_loss = loss_fn(torch.cat(val_pred), torch.cat(val))\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, train loss on all blocks {train_loss}\")\n",
    "        #     # validate \n",
    "        #     valpred = model.predict(hfeat_test, target_test)\n",
    "        #     if loss_func == 'kspace':\n",
    "        #         val_loss = L2_kspace_loss(valpred, target_test, dataset)\n",
    "        #     else:\n",
    "        #         val_loss = L2_loss(valpred, target_test)\n",
    "            \n",
    "        #     print(f\"Epoch {epoch} val loss {val_loss}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a589463e-1ea4-48a2-82bd-eca979026ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3950ade9-1032-4d65-9803-2633e1e968dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss on all blocks 8.821527092795904\n",
      "Epoch 10, train loss on all blocks 6.468852516265518\n",
      "Epoch 20, train loss on all blocks 6.194685044848282\n",
      "Epoch 30, train loss on all blocks 5.795473398258038\n",
      "Epoch 40, train loss on all blocks 5.175903720884815\n",
      "Epoch 50, train loss on all blocks 4.698580369774456\n",
      "Epoch 60, train loss on all blocks 4.32300506635068\n",
      "Epoch 70, train loss on all blocks 4.045034636532593\n",
      "Epoch 80, train loss on all blocks 3.7575880447607286\n",
      "Epoch 90, train loss on all blocks 3.5833314900431104\n",
      "Epoch 100, train loss on all blocks 3.555305064125962\n",
      "Epoch 110, train loss on all blocks 3.4238795021693136\n",
      "Epoch 120, train loss on all blocks 3.386747940197523\n",
      "Epoch 130, train loss on all blocks 3.377197009452977\n",
      "Epoch 140, train loss on all blocks 3.3004596818377956\n",
      "Epoch 150, train loss on all blocks 3.305247898395405\n",
      "Epoch 160, train loss on all blocks 3.2919865672194946\n",
      "Epoch 170, train loss on all blocks 3.275875886539988\n",
      "Epoch 180, train loss on all blocks 3.228446827817991\n",
      "Epoch 190, train loss on all blocks 3.2129782528720128\n",
      "Epoch 200, train loss on all blocks 3.248572107776722\n",
      "Epoch 210, train loss on all blocks 3.278558914816351\n",
      "Epoch 220, train loss on all blocks 3.197944659813237\n",
      "Epoch 230, train loss on all blocks 3.180149469987544\n",
      "Epoch 240, train loss on all blocks 3.3895700045660675\n",
      "Epoch 250, train loss on all blocks 3.1745717287116086\n",
      "Epoch 260, train loss on all blocks 3.154843959953517\n",
      "Epoch 270, train loss on all blocks 3.2593738157477676\n",
      "Epoch 280, train loss on all blocks 3.14336968548291\n",
      "Epoch 290, train loss on all blocks 3.0923996236576086\n",
      "Epoch 300, train loss on all blocks 3.064985419184798\n",
      "Epoch 310, train loss on all blocks 3.355781413934932\n",
      "Epoch 320, train loss on all blocks 3.1825369326843886\n",
      "Epoch 330, train loss on all blocks 3.0865443750812704\n",
      "Epoch 340, train loss on all blocks 3.1356706495752906\n",
      "Epoch 350, train loss on all blocks 3.0649995029736825\n",
      "Epoch 360, train loss on all blocks 3.0404821527310837\n",
      "Epoch 370, train loss on all blocks 3.028350501835847\n",
      "Epoch 380, train loss on all blocks 3.4138258824799625\n",
      "Epoch 390, train loss on all blocks 3.1518429519573026\n",
      "Epoch 400, train loss on all blocks 3.099439509374702\n",
      "Epoch 410, train loss on all blocks 3.02945146134622\n",
      "Epoch 420, train loss on all blocks 3.063199462403428\n",
      "Epoch 430, train loss on all blocks 3.0209873550302317\n",
      "Epoch 440, train loss on all blocks 3.0255184653743097\n",
      "Epoch 450, train loss on all blocks 3.007197245429883\n",
      "Epoch 460, train loss on all blocks 3.478374328358437\n",
      "Epoch 470, train loss on all blocks 3.0573330567886585\n",
      "Epoch 480, train loss on all blocks 3.0705634945621694\n",
      "Epoch 490, train loss on all blocks 3.012852750931611\n",
      "Epoch 500, train loss on all blocks 2.9782534372689144\n",
      "Epoch 510, train loss on all blocks 3.0116404312315748\n",
      "Epoch 520, train loss on all blocks 3.1066077647699286\n",
      "Epoch 530, train loss on all blocks 3.0213068793441\n",
      "Epoch 540, train loss on all blocks 2.992293081475657\n",
      "Epoch 550, train loss on all blocks 3.0493628356253164\n",
      "Epoch 560, train loss on all blocks 3.018386222937658\n",
      "Epoch 570, train loss on all blocks 3.0266299249504915\n",
      "Epoch 580, train loss on all blocks 3.0224566708449414\n",
      "Epoch 590, train loss on all blocks 2.979556568921475\n",
      "Epoch 600, train loss on all blocks 2.945961493120879\n",
      "Epoch 610, train loss on all blocks 3.1528753851416114\n",
      "Epoch 620, train loss on all blocks 2.9892211682235468\n",
      "Epoch 630, train loss on all blocks 3.3971282144582746\n",
      "Epoch 640, train loss on all blocks 3.0922451487519567\n",
      "Epoch 650, train loss on all blocks 2.9885201149379634\n",
      "Epoch 660, train loss on all blocks 3.0099230624872866\n",
      "Epoch 670, train loss on all blocks 3.2745094427266084\n",
      "Epoch 680, train loss on all blocks 3.345511866060134\n",
      "Epoch 690, train loss on all blocks 3.0208385970202514\n",
      "Epoch 700, train loss on all blocks 2.956484399903776\n",
      "Epoch 710, train loss on all blocks 2.9298044936194456\n",
      "Epoch 720, train loss on all blocks 2.9136856745097863\n",
      "Epoch 730, train loss on all blocks 2.912880051624721\n",
      "Epoch 740, train loss on all blocks 3.0434025234897293\n",
      "Epoch 750, train loss on all blocks 2.992191872156643\n",
      "Epoch 760, train loss on all blocks 3.1373598663495255\n",
      "Epoch 770, train loss on all blocks 3.1559655223629424\n",
      "Epoch 780, train loss on all blocks 2.9601983699789827\n",
      "Epoch 790, train loss on all blocks 2.94118432369744\n",
      "Epoch 800, train loss on all blocks 2.9532942232084674\n",
      "Epoch 810, train loss on all blocks 2.9158064695932193\n",
      "Epoch 820, train loss on all blocks 2.8905791460020698\n",
      "Epoch 830, train loss on all blocks 2.880914508539977\n",
      "Epoch 840, train loss on all blocks 2.967094462129581\n",
      "Epoch 850, train loss on all blocks 3.070228738200967\n",
      "Epoch 860, train loss on all blocks 3.1840283683567074\n",
      "Epoch 870, train loss on all blocks 3.270004253432676\n",
      "Epoch 880, train loss on all blocks 3.030631112517729\n",
      "Epoch 890, train loss on all blocks 2.9263820210088434\n",
      "Epoch 900, train loss on all blocks 3.0458186861455916\n",
      "Epoch 910, train loss on all blocks 2.8977132223034827\n",
      "Epoch 920, train loss on all blocks 2.8808656444926717\n",
      "Epoch 930, train loss on all blocks 2.864461048094914\n",
      "Epoch 940, train loss on all blocks 3.034706398855362\n",
      "Epoch 950, train loss on all blocks 2.9900226939450842\n",
      "Epoch 960, train loss on all blocks 3.0582714222300624\n",
      "Epoch 970, train loss on all blocks 2.957244967658871\n",
      "Epoch 980, train loss on all blocks 3.0665581728863645\n",
      "Epoch 990, train loss on all blocks 2.9983387085304676\n",
      "Epoch 1000, train loss on all blocks 2.9640176764447377\n",
      "Epoch 1010, train loss on all blocks 2.9237089414250508\n",
      "Epoch 1020, train loss on all blocks 2.8840496117147882\n",
      "Epoch 1030, train loss on all blocks 2.8551109979846236\n",
      "Epoch 1040, train loss on all blocks 2.8411304317917727\n",
      "Epoch 1050, train loss on all blocks 3.2752636022898267\n",
      "Epoch 1060, train loss on all blocks 2.9261122237512858\n",
      "Epoch 1070, train loss on all blocks 2.893929080328962\n",
      "Epoch 1080, train loss on all blocks 2.859187312632531\n",
      "Epoch 1090, train loss on all blocks 3.253988724488666\n",
      "Epoch 1100, train loss on all blocks 3.0926712094317454\n",
      "Epoch 1110, train loss on all blocks 2.930629387143844\n",
      "Epoch 1120, train loss on all blocks 2.88979767701286\n",
      "Epoch 1130, train loss on all blocks 2.84183125657533\n",
      "Epoch 1140, train loss on all blocks 2.8321377355431503\n",
      "Epoch 1150, train loss on all blocks 3.063087882006399\n",
      "Epoch 1160, train loss on all blocks 2.90965406080542\n",
      "Epoch 1170, train loss on all blocks 2.890462667424903\n",
      "Epoch 1180, train loss on all blocks 2.8339406738026653\n",
      "Epoch 1190, train loss on all blocks 2.8424715672318093\n",
      "Epoch 1200, train loss on all blocks 2.849323758874709\n",
      "Epoch 1210, train loss on all blocks 3.0567329891892356\n",
      "Epoch 1220, train loss on all blocks 2.902228602845139\n",
      "Epoch 1230, train loss on all blocks 2.933127845978125\n",
      "Epoch 1240, train loss on all blocks 4.00665264130934\n",
      "Epoch 1250, train loss on all blocks 3.212901502100931\n",
      "Epoch 1260, train loss on all blocks 2.910293661031901\n",
      "Epoch 1270, train loss on all blocks 2.841047112344004\n",
      "Epoch 1280, train loss on all blocks 2.8179917795266407\n",
      "Epoch 1290, train loss on all blocks 2.8034123692812067\n",
      "Epoch 1300, train loss on all blocks 2.8024776595124394\n",
      "Epoch 1310, train loss on all blocks 3.215372225362956\n",
      "Epoch 1320, train loss on all blocks 3.0130855448838023\n",
      "Epoch 1330, train loss on all blocks 3.0841316903634564\n",
      "Epoch 1340, train loss on all blocks 2.85665435947016\n",
      "Epoch 1350, train loss on all blocks 2.8198050755307738\n",
      "Epoch 1360, train loss on all blocks 2.7992533510894964\n",
      "Epoch 1370, train loss on all blocks 2.7967125456089246\n",
      "Epoch 1380, train loss on all blocks 2.8074101430634277\n",
      "Epoch 1390, train loss on all blocks 3.0227116464486548\n",
      "Epoch 1400, train loss on all blocks 2.8563913508992913\n",
      "Epoch 1410, train loss on all blocks 3.4907293939420505\n",
      "Epoch 1420, train loss on all blocks 3.065295725005834\n",
      "Epoch 1430, train loss on all blocks 2.8544500931283228\n",
      "Epoch 1440, train loss on all blocks 2.8170409264777536\n",
      "Epoch 1450, train loss on all blocks 2.776657039657005\n",
      "Epoch 1460, train loss on all blocks 2.842068992878822\n",
      "Epoch 1470, train loss on all blocks 2.9095962550467314\n",
      "Epoch 1480, train loss on all blocks 2.8227819250429103\n",
      "Epoch 1490, train loss on all blocks 2.930895877089804\n",
      "Epoch 1500, train loss on all blocks 2.865796835931299\n",
      "Epoch 1510, train loss on all blocks 3.0016044727055435\n",
      "Epoch 1520, train loss on all blocks 2.817246295461847\n",
      "Epoch 1530, train loss on all blocks 2.782502707107594\n",
      "Epoch 1540, train loss on all blocks 2.824570327686754\n",
      "Epoch 1550, train loss on all blocks 2.9759529184493214\n",
      "Epoch 1560, train loss on all blocks 2.887696123360649\n",
      "Epoch 1570, train loss on all blocks 2.8294703983213942\n",
      "Epoch 1580, train loss on all blocks 2.7769908435308386\n",
      "Epoch 1590, train loss on all blocks 2.760404317434264\n",
      "Epoch 1600, train loss on all blocks 3.0530246798929266\n",
      "Epoch 1610, train loss on all blocks 2.8489500405305757\n",
      "Epoch 1620, train loss on all blocks 2.7693316265522037\n",
      "Epoch 1630, train loss on all blocks 2.836612990814859\n",
      "Epoch 1640, train loss on all blocks 3.445014900948162\n",
      "Epoch 1650, train loss on all blocks 2.980898427963687\n",
      "Epoch 1660, train loss on all blocks 2.870738430190628\n",
      "Epoch 1670, train loss on all blocks 2.8246790581779715\n",
      "Epoch 1680, train loss on all blocks 2.9456841882276263\n",
      "Epoch 1690, train loss on all blocks 2.8837702948701422\n",
      "Epoch 1700, train loss on all blocks 2.7906334921981024\n",
      "Epoch 1710, train loss on all blocks 2.761831521561393\n",
      "Epoch 1720, train loss on all blocks 2.7350787824669496\n",
      "Epoch 1730, train loss on all blocks 2.9254213529185296\n",
      "Epoch 1740, train loss on all blocks 2.784511111627257\n",
      "Epoch 1750, train loss on all blocks 3.6156928482392594\n",
      "Epoch 1760, train loss on all blocks 3.0246527548496283\n",
      "Epoch 1770, train loss on all blocks 3.0563627893037104\n",
      "Epoch 1780, train loss on all blocks 2.870700011129678\n",
      "Epoch 1790, train loss on all blocks 2.805022021436859\n",
      "Epoch 1800, train loss on all blocks 2.7584986847010775\n",
      "Epoch 1810, train loss on all blocks 2.7393347276477513\n",
      "Epoch 1820, train loss on all blocks 2.921727830636887\n",
      "Epoch 1830, train loss on all blocks 2.752781164024092\n",
      "Epoch 1840, train loss on all blocks 2.725598358029469\n",
      "Epoch 1850, train loss on all blocks 2.707890938226133\n",
      "Epoch 1860, train loss on all blocks 3.2513663374419766\n",
      "Epoch 1870, train loss on all blocks 3.086335690263316\n",
      "Epoch 1880, train loss on all blocks 2.850315304697239\n",
      "Epoch 1890, train loss on all blocks 2.7621466441902207\n",
      "Epoch 1900, train loss on all blocks 2.821297231983863\n",
      "Epoch 1910, train loss on all blocks 2.7447365248310103\n",
      "Epoch 1920, train loss on all blocks 2.841559382875287\n",
      "Epoch 1930, train loss on all blocks 2.7490184323905256\n",
      "Epoch 1940, train loss on all blocks 2.8893575985130164\n",
      "Epoch 1950, train loss on all blocks 3.175079932457784\n",
      "Epoch 1960, train loss on all blocks 2.998508820728957\n",
      "Epoch 1970, train loss on all blocks 3.738140701014019\n",
      "Epoch 1980, train loss on all blocks 2.953793404586301\n",
      "Epoch 1990, train loss on all blocks 2.8392691030941153\n",
      "Epoch 2000, train loss on all blocks 2.7440512711562555\n",
      "Epoch 2010, train loss on all blocks 2.716186236875169\n",
      "Epoch 2020, train loss on all blocks 2.7022926996499352\n",
      "Epoch 2030, train loss on all blocks 2.7916531747289133\n",
      "Epoch 2040, train loss on all blocks 2.720622531370717\n",
      "Epoch 2050, train loss on all blocks 3.3397967112246425\n",
      "Epoch 2060, train loss on all blocks 2.896111096196817\n",
      "Epoch 2070, train loss on all blocks 3.8013759835871497\n",
      "Epoch 2080, train loss on all blocks 2.9244303344888354\n",
      "Epoch 2090, train loss on all blocks 2.7895269090993215\n",
      "Epoch 2100, train loss on all blocks 2.742072863202414\n",
      "Epoch 2110, train loss on all blocks 2.778004957573631\n",
      "Epoch 2120, train loss on all blocks 2.7622643030993004\n",
      "Epoch 2130, train loss on all blocks 2.7108327608254252\n",
      "Epoch 2140, train loss on all blocks 2.728688906846995\n",
      "Epoch 2150, train loss on all blocks 2.773184661798883\n",
      "Epoch 2160, train loss on all blocks 2.6983368261802783\n",
      "Epoch 2170, train loss on all blocks 2.7006309158183317\n",
      "Epoch 2180, train loss on all blocks 2.6958805053768318\n",
      "Epoch 2190, train loss on all blocks 2.8418249392626915\n",
      "Epoch 2200, train loss on all blocks 2.8251945877968154\n",
      "Epoch 2210, train loss on all blocks 2.7510739216527282\n",
      "Epoch 2220, train loss on all blocks 2.721803872178696\n",
      "Epoch 2230, train loss on all blocks 2.9397864899138217\n",
      "Epoch 2240, train loss on all blocks 2.788632644843527\n",
      "Epoch 2250, train loss on all blocks 2.7156068329828775\n",
      "Epoch 2260, train loss on all blocks 3.212338204393687\n",
      "Epoch 2270, train loss on all blocks 2.841964041952333\n",
      "Epoch 2280, train loss on all blocks 2.882493045731656\n",
      "Epoch 2290, train loss on all blocks 2.7196731061510615\n",
      "Epoch 2300, train loss on all blocks 2.7189258779699337\n",
      "Epoch 2310, train loss on all blocks 3.0465496521054733\n",
      "Epoch 2320, train loss on all blocks 2.7561387128937254\n",
      "Epoch 2330, train loss on all blocks 2.7276458487681277\n",
      "Epoch 2340, train loss on all blocks 2.6818938095551736\n",
      "Epoch 2350, train loss on all blocks 3.2594802064053727\n",
      "Epoch 2360, train loss on all blocks 2.867131508329229\n",
      "Epoch 2370, train loss on all blocks 2.7941898253746666\n",
      "Epoch 2380, train loss on all blocks 2.7090776025685335\n",
      "Epoch 2390, train loss on all blocks 2.6775306330070316\n",
      "Epoch 2400, train loss on all blocks 2.7499576018372105\n",
      "Epoch 2410, train loss on all blocks 2.870453186194508\n",
      "Epoch 2420, train loss on all blocks 2.8930699964804507\n",
      "Epoch 2430, train loss on all blocks 2.716149048812375\n",
      "Epoch 2440, train loss on all blocks 2.9386999801197655\n",
      "Epoch 2450, train loss on all blocks 2.775678294678913\n",
      "Epoch 2460, train loss on all blocks 2.7005370964127207\n",
      "Epoch 2470, train loss on all blocks 2.6804220490474857\n",
      "Epoch 2480, train loss on all blocks 2.6526084849209632\n",
      "Epoch 2490, train loss on all blocks 3.0555036939318097\n",
      "Epoch 2500, train loss on all blocks 2.7023681766299243\n",
      "Epoch 2510, train loss on all blocks 2.673417769490838\n",
      "Epoch 2520, train loss on all blocks 2.950723320447527\n",
      "Epoch 2530, train loss on all blocks 2.820306239035104\n",
      "Epoch 2540, train loss on all blocks 2.807502699234452\n",
      "Epoch 2550, train loss on all blocks 2.693253500416367\n",
      "Epoch 2560, train loss on all blocks 2.68183463132623\n",
      "Epoch 2570, train loss on all blocks 2.8087323397396755\n",
      "Epoch 2580, train loss on all blocks 2.6970065895250093\n",
      "Epoch 2590, train loss on all blocks 2.650420359915385\n",
      "Epoch 2600, train loss on all blocks 2.658866834933127\n",
      "Epoch 2610, train loss on all blocks 2.75910973943558\n",
      "Epoch 2620, train loss on all blocks 3.0004631071091685\n",
      "Epoch 2630, train loss on all blocks 2.75984257184245\n",
      "Epoch 2640, train loss on all blocks 2.6692451811608793\n",
      "Epoch 2650, train loss on all blocks 3.1740665857703325\n",
      "Epoch 2660, train loss on all blocks 2.7037787734590792\n",
      "Epoch 2670, train loss on all blocks 2.740776987109754\n",
      "Epoch 2680, train loss on all blocks 2.712730347699064\n",
      "Epoch 2690, train loss on all blocks 2.689710747721673\n",
      "Epoch 2700, train loss on all blocks 2.6571452207410005\n",
      "Epoch 2710, train loss on all blocks 3.7114784579248097\n",
      "Epoch 2720, train loss on all blocks 3.54914745447347\n",
      "Epoch 2730, train loss on all blocks 3.0396245094947454\n",
      "Epoch 2740, train loss on all blocks 2.8077100689587597\n",
      "Epoch 2750, train loss on all blocks 2.6969373039159157\n",
      "Epoch 2760, train loss on all blocks 2.687892582202324\n",
      "Epoch 2770, train loss on all blocks 2.705475388168723\n",
      "Epoch 2780, train loss on all blocks 2.6565848154684053\n",
      "Epoch 2790, train loss on all blocks 2.629223251662639\n",
      "Epoch 2800, train loss on all blocks 2.616941162999451\n",
      "Epoch 2810, train loss on all blocks 2.8761701061088827\n",
      "Epoch 2820, train loss on all blocks 2.7219634606290817\n",
      "Epoch 2830, train loss on all blocks 2.6661017941343657\n",
      "Epoch 2840, train loss on all blocks 2.8080147587632704\n",
      "Epoch 2850, train loss on all blocks 2.700635647881838\n",
      "Epoch 2860, train loss on all blocks 2.657871836819688\n",
      "Epoch 2870, train loss on all blocks 2.6261216658388777\n",
      "Epoch 2880, train loss on all blocks 3.273619804157717\n",
      "Epoch 2890, train loss on all blocks 2.83226240796124\n",
      "Epoch 2900, train loss on all blocks 2.6885909687601544\n",
      "Epoch 2910, train loss on all blocks 2.6491628138536027\n",
      "Epoch 2920, train loss on all blocks 2.8777288681654505\n",
      "Epoch 2930, train loss on all blocks 2.813235429374864\n",
      "Epoch 2940, train loss on all blocks 2.8388267098124054\n",
      "Epoch 2950, train loss on all blocks 2.6508237472004126\n",
      "Epoch 2960, train loss on all blocks 2.6351617927242783\n",
      "Epoch 2970, train loss on all blocks 2.970725696144439\n",
      "Epoch 2980, train loss on all blocks 2.769291390621568\n",
      "Epoch 2990, train loss on all blocks 2.7122747565403187\n",
      "Epoch 3000, train loss on all blocks 2.9943319237596846\n",
      "Epoch 3010, train loss on all blocks 2.719698305353099\n",
      "Epoch 3020, train loss on all blocks 2.628182178040656\n",
      "Epoch 3030, train loss on all blocks 2.620419259918749\n",
      "Epoch 3040, train loss on all blocks 2.6070713118514774\n",
      "Epoch 3050, train loss on all blocks 2.6325327192084353\n",
      "Epoch 3060, train loss on all blocks 2.5907739673483943\n",
      "Epoch 3070, train loss on all blocks 3.966460532541742\n",
      "Epoch 3080, train loss on all blocks 2.976891231875586\n",
      "Epoch 3090, train loss on all blocks 2.8081557434583058\n",
      "Epoch 3100, train loss on all blocks 2.7289852127512404\n",
      "Epoch 3110, train loss on all blocks 2.6460225491955502\n",
      "Epoch 3120, train loss on all blocks 2.6430481970033304\n",
      "Epoch 3130, train loss on all blocks 2.5950455012056626\n",
      "Epoch 3140, train loss on all blocks 2.5864553861055612\n",
      "Epoch 3150, train loss on all blocks 2.5747092408985113\n",
      "Epoch 3160, train loss on all blocks 3.1764762960875905\n",
      "Epoch 3170, train loss on all blocks 2.7815785703912064\n",
      "Epoch 3180, train loss on all blocks 2.6859663226980257\n",
      "Epoch 3190, train loss on all blocks 2.628160251982098\n",
      "Epoch 3200, train loss on all blocks 2.593339057330078\n",
      "Epoch 3210, train loss on all blocks 2.598256617950242\n",
      "Epoch 3220, train loss on all blocks 2.6078885331100166\n",
      "Epoch 3230, train loss on all blocks 3.205799074021887\n",
      "Epoch 3240, train loss on all blocks 3.127752036553646\n",
      "Epoch 3250, train loss on all blocks 2.7867288647605184\n",
      "Epoch 3260, train loss on all blocks 2.7041371083615897\n",
      "Epoch 3270, train loss on all blocks 2.636770492205997\n",
      "Epoch 3280, train loss on all blocks 2.6055777756637486\n",
      "Epoch 3290, train loss on all blocks 2.5743604441729455\n",
      "Epoch 3300, train loss on all blocks 2.754157187724771\n",
      "Epoch 3310, train loss on all blocks 2.7885411038585985\n",
      "Epoch 3320, train loss on all blocks 2.6162901657979423\n",
      "Epoch 3330, train loss on all blocks 2.6508673150897186\n",
      "Epoch 3340, train loss on all blocks 2.6686541273109743\n",
      "Epoch 3350, train loss on all blocks 2.625885777596862\n",
      "Epoch 3360, train loss on all blocks 2.571884718089838\n",
      "Epoch 3370, train loss on all blocks 2.586641418495672\n",
      "Epoch 3380, train loss on all blocks 3.295592382964712\n",
      "Epoch 3390, train loss on all blocks 2.9828788842963267\n",
      "Epoch 3400, train loss on all blocks 2.8280920875656914\n",
      "Epoch 3410, train loss on all blocks 2.722048053571754\n",
      "Epoch 3420, train loss on all blocks 2.63582155673265\n",
      "Epoch 3430, train loss on all blocks 2.589511916173143\n",
      "Epoch 3440, train loss on all blocks 2.58501611214142\n",
      "Epoch 3450, train loss on all blocks 2.709537109040764\n",
      "Epoch 3460, train loss on all blocks 2.5888398517135105\n",
      "Epoch 3470, train loss on all blocks 2.592643425099905\n",
      "Epoch 3480, train loss on all blocks 2.564802554914393\n",
      "Epoch 3490, train loss on all blocks 2.817784709634052\n",
      "Epoch 3500, train loss on all blocks 2.7749784873703582\n",
      "Epoch 3510, train loss on all blocks 2.83195717382437\n",
      "Epoch 3520, train loss on all blocks 2.663132749019898\n",
      "Epoch 3530, train loss on all blocks 2.58852792471551\n",
      "Epoch 3540, train loss on all blocks 2.564092421406519\n",
      "Epoch 3550, train loss on all blocks 2.7811086072978553\n",
      "Epoch 3560, train loss on all blocks 2.5668221896817984\n",
      "Epoch 3570, train loss on all blocks 2.593753712905988\n",
      "Epoch 3580, train loss on all blocks 2.7291168364836778\n",
      "Epoch 3590, train loss on all blocks 2.7522512672042656\n",
      "Epoch 3600, train loss on all blocks 2.573381661263834\n",
      "Epoch 3610, train loss on all blocks 2.6009895340533\n",
      "Epoch 3620, train loss on all blocks 2.6366619529431765\n",
      "Epoch 3630, train loss on all blocks 2.6374663343877476\n",
      "Epoch 3640, train loss on all blocks 2.6833049137307814\n",
      "Epoch 3650, train loss on all blocks 2.728707533064738\n",
      "Epoch 3660, train loss on all blocks 2.609095861336855\n",
      "Epoch 3670, train loss on all blocks 2.7266748518439323\n",
      "Epoch 3680, train loss on all blocks 2.6305594174815474\n",
      "Epoch 3690, train loss on all blocks 2.580834125070373\n",
      "Epoch 3700, train loss on all blocks 2.5504306326954382\n",
      "Epoch 3710, train loss on all blocks 4.207630353441126\n",
      "Epoch 3720, train loss on all blocks 3.0844771854541606\n",
      "Epoch 3730, train loss on all blocks 2.775720563211994\n",
      "Epoch 3740, train loss on all blocks 2.627769370275481\n",
      "Epoch 3750, train loss on all blocks 2.626079010875406\n",
      "Epoch 3760, train loss on all blocks 2.7753393821132333\n",
      "Epoch 3770, train loss on all blocks 2.6517855258130023\n",
      "Epoch 3780, train loss on all blocks 2.5800554572088306\n",
      "Epoch 3790, train loss on all blocks 2.575641402115206\n",
      "Epoch 3800, train loss on all blocks 2.8451160947505123\n",
      "Epoch 3810, train loss on all blocks 2.5949152421438364\n",
      "Epoch 3820, train loss on all blocks 2.549285428066783\n",
      "Epoch 3830, train loss on all blocks 2.560516562743647\n",
      "Epoch 3840, train loss on all blocks 2.815563302087243\n",
      "Epoch 3850, train loss on all blocks 2.7965454119195057\n",
      "Epoch 3860, train loss on all blocks 2.6760104523232626\n",
      "Epoch 3870, train loss on all blocks 2.595338150071358\n",
      "Epoch 3880, train loss on all blocks 2.560133801073815\n",
      "Epoch 3890, train loss on all blocks 2.524831871988349\n",
      "Epoch 3900, train loss on all blocks 2.83337068073033\n",
      "Epoch 3910, train loss on all blocks 3.461127454415244\n",
      "Epoch 3920, train loss on all blocks 3.03600745295052\n",
      "Epoch 3930, train loss on all blocks 2.742167063746412\n",
      "Epoch 3940, train loss on all blocks 2.7392908709756654\n",
      "Epoch 3950, train loss on all blocks 2.604749089638409\n",
      "Epoch 3960, train loss on all blocks 2.545840646881609\n",
      "Epoch 3970, train loss on all blocks 2.532479982131844\n",
      "Epoch 3980, train loss on all blocks 2.870533965546736\n",
      "Epoch 3990, train loss on all blocks 2.6918115086470045\n",
      "Epoch 4000, train loss on all blocks 2.595760523378151\n",
      "Epoch 4010, train loss on all blocks 2.569668521732443\n",
      "Epoch 4020, train loss on all blocks 2.5629495550093546\n",
      "Epoch 4030, train loss on all blocks 2.5108619273704145\n",
      "Epoch 4040, train loss on all blocks 3.4682516538871466\n",
      "Epoch 4050, train loss on all blocks 2.747862110626743\n",
      "Epoch 4060, train loss on all blocks 2.7608800746890254\n",
      "Epoch 4070, train loss on all blocks 2.6351122700519394\n",
      "Epoch 4080, train loss on all blocks 2.655649828266273\n",
      "Epoch 4090, train loss on all blocks 2.5803098606853245\n",
      "Epoch 4100, train loss on all blocks 2.518627101972667\n",
      "Epoch 4110, train loss on all blocks 2.5449874085327435\n",
      "Epoch 4120, train loss on all blocks 2.7718176229427893\n",
      "Epoch 4130, train loss on all blocks 2.787541163205484\n",
      "Epoch 4140, train loss on all blocks 2.602287166934821\n",
      "Epoch 4150, train loss on all blocks 2.52521546290681\n",
      "Epoch 4160, train loss on all blocks 2.511853162589688\n",
      "Epoch 4170, train loss on all blocks 2.5091466027385305\n",
      "Epoch 4180, train loss on all blocks 2.7060668059451265\n",
      "Epoch 4190, train loss on all blocks 2.831810889699012\n",
      "Epoch 4200, train loss on all blocks 2.707863809581837\n",
      "Epoch 4210, train loss on all blocks 2.638724757785554\n",
      "Epoch 4220, train loss on all blocks 2.6251012009380315\n",
      "Epoch 4230, train loss on all blocks 2.5453523097958026\n",
      "Epoch 4240, train loss on all blocks 2.5358308734988677\n",
      "Epoch 4250, train loss on all blocks 2.6602386415020547\n",
      "Epoch 4260, train loss on all blocks 2.6552339275852246\n",
      "Epoch 4270, train loss on all blocks 2.533598613420824\n",
      "Epoch 4280, train loss on all blocks 2.8958407253110465\n",
      "Epoch 4290, train loss on all blocks 2.6350243177466277\n",
      "Epoch 4300, train loss on all blocks 2.5488673893182354\n",
      "Epoch 4310, train loss on all blocks 2.8706404031556705\n",
      "Epoch 4320, train loss on all blocks 2.622966217097708\n",
      "Epoch 4330, train loss on all blocks 2.5701064674375953\n",
      "Epoch 4340, train loss on all blocks 2.532315425976135\n",
      "Epoch 4350, train loss on all blocks 2.5153649505574838\n",
      "Epoch 4360, train loss on all blocks 2.546620318189669\n",
      "Epoch 4370, train loss on all blocks 2.8307165797264284\n",
      "Epoch 4380, train loss on all blocks 2.9096620962363082\n",
      "Epoch 4390, train loss on all blocks 2.670365925606661\n",
      "Epoch 4400, train loss on all blocks 2.5503410755469105\n",
      "Epoch 4410, train loss on all blocks 2.5168939546958713\n",
      "Epoch 4420, train loss on all blocks 2.520532813068835\n",
      "Epoch 4430, train loss on all blocks 2.94527714325248\n",
      "Epoch 4440, train loss on all blocks 2.6308401361020337\n",
      "Epoch 4450, train loss on all blocks 2.5872439329037746\n",
      "Epoch 4460, train loss on all blocks 2.860732806999551\n",
      "Epoch 4470, train loss on all blocks 2.6183189190413683\n",
      "Epoch 4480, train loss on all blocks 2.555847290907174\n",
      "Epoch 4490, train loss on all blocks 2.553035301242554\n",
      "Epoch 4500, train loss on all blocks 2.509473373820291\n",
      "Epoch 4510, train loss on all blocks 3.31932391088608\n",
      "Epoch 4520, train loss on all blocks 2.631635654741686\n",
      "Epoch 4530, train loss on all blocks 2.600551070613136\n",
      "Epoch 4540, train loss on all blocks 2.892511006477612\n",
      "Epoch 4550, train loss on all blocks 2.608678360952003\n",
      "Epoch 4560, train loss on all blocks 2.5535574510404873\n",
      "Epoch 4570, train loss on all blocks 2.496431217057439\n",
      "Epoch 4580, train loss on all blocks 2.5141198395491795\n",
      "Epoch 4590, train loss on all blocks 2.7477851790086447\n",
      "Epoch 4600, train loss on all blocks 2.707004077134851\n",
      "Epoch 4610, train loss on all blocks 2.6964328073451567\n",
      "Epoch 4620, train loss on all blocks 2.7809314387669897\n",
      "Epoch 4630, train loss on all blocks 2.6374216216098567\n",
      "Epoch 4640, train loss on all blocks 2.532487657740762\n",
      "Epoch 4650, train loss on all blocks 2.506835801018176\n",
      "Epoch 4660, train loss on all blocks 2.5009490896693523\n",
      "Epoch 4670, train loss on all blocks 2.4995166970665337\n",
      "Epoch 4680, train loss on all blocks 2.5108700873278904\n",
      "Epoch 4690, train loss on all blocks 3.7320874411498215\n",
      "Epoch 4700, train loss on all blocks 2.912592626882151\n",
      "Epoch 4710, train loss on all blocks 2.667042302202809\n",
      "Epoch 4720, train loss on all blocks 2.5971654060568534\n",
      "Epoch 4730, train loss on all blocks 2.665422282264685\n",
      "Epoch 4740, train loss on all blocks 2.5429207987754454\n",
      "Epoch 4750, train loss on all blocks 2.4978593773712467\n",
      "Epoch 4760, train loss on all blocks 2.5182897075832082\n",
      "Epoch 4770, train loss on all blocks 2.4762625571988433\n",
      "Epoch 4780, train loss on all blocks 2.563685283194144\n",
      "Epoch 4790, train loss on all blocks 2.7506778495143864\n",
      "Epoch 4800, train loss on all blocks 2.562322511785271\n",
      "Epoch 4810, train loss on all blocks 2.6711878300174448\n",
      "Epoch 4820, train loss on all blocks 2.5457657309183515\n",
      "Epoch 4830, train loss on all blocks 2.5241664927489014\n",
      "Epoch 4840, train loss on all blocks 2.789105027353667\n",
      "Epoch 4850, train loss on all blocks 2.6238173646701086\n",
      "Epoch 4860, train loss on all blocks 2.598554411205156\n",
      "Epoch 4870, train loss on all blocks 2.5330125665599046\n",
      "Epoch 4880, train loss on all blocks 2.90081767198801\n",
      "Epoch 4890, train loss on all blocks 2.660125583909151\n",
      "Epoch 4900, train loss on all blocks 2.56976369450042\n",
      "Epoch 4910, train loss on all blocks 2.511864586305667\n",
      "Epoch 4920, train loss on all blocks 2.9319454119872908\n",
      "Epoch 4930, train loss on all blocks 2.674398869213727\n",
      "Epoch 4940, train loss on all blocks 2.59737005220123\n",
      "Epoch 4950, train loss on all blocks 2.6966139758149197\n",
      "Epoch 4960, train loss on all blocks 2.5145721103872587\n",
      "Epoch 4970, train loss on all blocks 2.4724335459806976\n",
      "Epoch 4980, train loss on all blocks 2.9731897762280766\n",
      "Epoch 4990, train loss on all blocks 2.6218795359608578\n",
      "Epoch 5000, train loss on all blocks 3.2050860030057464\n",
      "Epoch 5010, train loss on all blocks 2.7099919628843034\n",
      "Epoch 5020, train loss on all blocks 2.6004380436201258\n",
      "Epoch 5030, train loss on all blocks 2.523381156894594\n",
      "Epoch 5040, train loss on all blocks 2.4829497806625724\n",
      "Epoch 5050, train loss on all blocks 2.5466880298422145\n",
      "Epoch 5060, train loss on all blocks 2.5092013293245863\n",
      "Epoch 5070, train loss on all blocks 2.4780933802382528\n",
      "Epoch 5080, train loss on all blocks 2.6050772642470004\n",
      "Epoch 5090, train loss on all blocks 2.505970417864856\n",
      "Epoch 5100, train loss on all blocks 2.505399110627355\n",
      "Epoch 5110, train loss on all blocks 2.4676065358381556\n",
      "Epoch 5120, train loss on all blocks 2.870477880913663\n",
      "Epoch 5130, train loss on all blocks 2.733934897932187\n",
      "Epoch 5140, train loss on all blocks 2.7701412412943682\n",
      "Epoch 5150, train loss on all blocks 2.5299477815117966\n",
      "Epoch 5160, train loss on all blocks 2.4898928485445415\n",
      "Epoch 5170, train loss on all blocks 3.0701325875078354\n",
      "Epoch 5180, train loss on all blocks 2.658312615288981\n",
      "Epoch 5190, train loss on all blocks 2.5108030448766856\n",
      "Epoch 5200, train loss on all blocks 2.4626036119034134\n",
      "Epoch 5210, train loss on all blocks 3.0373894580458156\n",
      "Epoch 5220, train loss on all blocks 2.5648034247134497\n",
      "Epoch 5230, train loss on all blocks 2.6067312146008073\n",
      "Epoch 5240, train loss on all blocks 2.5562880960580507\n",
      "Epoch 5250, train loss on all blocks 2.809806968547191\n",
      "Epoch 5260, train loss on all blocks 2.7569561194646717\n",
      "Epoch 5270, train loss on all blocks 2.5867296779330946\n",
      "Epoch 5280, train loss on all blocks 2.865839638623997\n",
      "Epoch 5290, train loss on all blocks 2.7124593202310674\n",
      "Epoch 5300, train loss on all blocks 2.6379207451653044\n",
      "Epoch 5310, train loss on all blocks 2.568248727624267\n",
      "Epoch 5320, train loss on all blocks 2.546835674286222\n",
      "Epoch 5330, train loss on all blocks 2.4691793496977175\n",
      "Epoch 5340, train loss on all blocks 2.5134819001947415\n",
      "Epoch 5350, train loss on all blocks 2.5862339485209453\n",
      "Epoch 5360, train loss on all blocks 2.6010332118073483\n",
      "Epoch 5370, train loss on all blocks 2.5326313638509967\n",
      "Epoch 5380, train loss on all blocks 3.0020701830338226\n",
      "Epoch 5390, train loss on all blocks 2.7106015744511325\n",
      "Epoch 5400, train loss on all blocks 2.585206545207366\n",
      "Epoch 5410, train loss on all blocks 2.484750171999903\n",
      "Epoch 5420, train loss on all blocks 2.4588594972909172\n",
      "Epoch 5430, train loss on all blocks 2.453378022602367\n",
      "Epoch 5440, train loss on all blocks 2.669638644403373\n",
      "Epoch 5450, train loss on all blocks 2.5347247099590637\n",
      "Epoch 5460, train loss on all blocks 2.5481317228808535\n",
      "Epoch 5470, train loss on all blocks 2.5141462927145177\n",
      "Epoch 5480, train loss on all blocks 2.5115151993731133\n",
      "Epoch 5490, train loss on all blocks 2.4945077800064084\n",
      "Epoch 5500, train loss on all blocks 2.468458098334114\n",
      "Epoch 5510, train loss on all blocks 2.58398708471957\n",
      "Epoch 5520, train loss on all blocks 2.8425301845025066\n",
      "Epoch 5530, train loss on all blocks 2.5369832170596824\n",
      "Epoch 5540, train loss on all blocks 2.4910897110682564\n",
      "Epoch 5550, train loss on all blocks 2.7279630846488914\n",
      "Epoch 5560, train loss on all blocks 2.645716629050856\n",
      "Epoch 5570, train loss on all blocks 2.510177313700946\n",
      "Epoch 5580, train loss on all blocks 2.492283904712666\n",
      "Epoch 5590, train loss on all blocks 2.456493403996122\n",
      "Epoch 5600, train loss on all blocks 2.6968423371820336\n",
      "Epoch 5610, train loss on all blocks 2.643930104051644\n",
      "Epoch 5620, train loss on all blocks 2.525128051759449\n",
      "Epoch 5630, train loss on all blocks 2.528174305037829\n",
      "Epoch 5640, train loss on all blocks 3.303278398469697\n",
      "Epoch 5650, train loss on all blocks 2.649589871028585\n",
      "Epoch 5660, train loss on all blocks 2.518033933797062\n",
      "Epoch 5670, train loss on all blocks 2.4718196459841373\n",
      "Epoch 5680, train loss on all blocks 2.4535186322389175\n",
      "Epoch 5690, train loss on all blocks 2.4278129841296066\n",
      "Epoch 5700, train loss on all blocks 2.711879531607482\n",
      "Epoch 5710, train loss on all blocks 2.5707345032054443\n",
      "Epoch 5720, train loss on all blocks 2.474274019411257\n",
      "Epoch 5730, train loss on all blocks 2.502921628119294\n",
      "Epoch 5740, train loss on all blocks 2.6108567200840875\n",
      "Epoch 5750, train loss on all blocks 2.4608045868043718\n",
      "Epoch 5760, train loss on all blocks 2.501989463808124\n",
      "Epoch 5770, train loss on all blocks 2.654152481144998\n",
      "Epoch 5780, train loss on all blocks 2.5722548376405117\n",
      "Epoch 5790, train loss on all blocks 2.541330369147741\n",
      "Epoch 5800, train loss on all blocks 2.4840728695960435\n",
      "Epoch 5810, train loss on all blocks 2.493227099232147\n",
      "Epoch 5820, train loss on all blocks 2.879221751215315\n",
      "Epoch 5830, train loss on all blocks 2.6166880606666867\n",
      "Epoch 5840, train loss on all blocks 2.556797507474993\n",
      "Epoch 5850, train loss on all blocks 2.592234269464589\n",
      "Epoch 5860, train loss on all blocks 3.0130985644810933\n",
      "Epoch 5870, train loss on all blocks 2.741617754865099\n",
      "Epoch 5880, train loss on all blocks 2.5632242673061727\n",
      "Epoch 5890, train loss on all blocks 2.4829243702121033\n",
      "Epoch 5900, train loss on all blocks 2.495414261280023\n",
      "Epoch 5910, train loss on all blocks 3.365651140540491\n",
      "Epoch 5920, train loss on all blocks 2.77694999263234\n",
      "Epoch 5930, train loss on all blocks 2.5796832133513012\n",
      "Epoch 5940, train loss on all blocks 2.5621511712276597\n",
      "Epoch 5950, train loss on all blocks 2.664577477881682\n",
      "Epoch 5960, train loss on all blocks 2.5086284080368175\n",
      "Epoch 5970, train loss on all blocks 2.6524341638865923\n",
      "Epoch 5980, train loss on all blocks 2.5035773875276046\n",
      "Epoch 5990, train loss on all blocks 2.44622944821473\n",
      "Epoch 6000, train loss on all blocks 3.366891026091496\n",
      "Epoch 6010, train loss on all blocks 2.6762184469361125\n",
      "Epoch 6020, train loss on all blocks 2.5278131775423063\n",
      "Epoch 6030, train loss on all blocks 2.46683074084993\n",
      "Epoch 6040, train loss on all blocks 2.5306909453520627\n",
      "Epoch 6050, train loss on all blocks 2.6465455524412773\n",
      "Epoch 6060, train loss on all blocks 2.5146565317806777\n",
      "Epoch 6070, train loss on all blocks 2.4880754072002587\n",
      "Epoch 6080, train loss on all blocks 2.5318474177452828\n",
      "Epoch 6090, train loss on all blocks 2.429058495236518\n",
      "Epoch 6100, train loss on all blocks 2.531091640032497\n",
      "Epoch 6110, train loss on all blocks 2.5328602870214065\n",
      "Epoch 6120, train loss on all blocks 2.4771062803120376\n",
      "Epoch 6130, train loss on all blocks 2.653093806404035\n",
      "Epoch 6140, train loss on all blocks 2.491341723682261\n",
      "Epoch 6150, train loss on all blocks 2.468847075101423\n",
      "Epoch 6160, train loss on all blocks 2.450617290994807\n",
      "Epoch 6170, train loss on all blocks 2.439361057467614\n",
      "Epoch 6180, train loss on all blocks 2.4858592845152954\n",
      "Epoch 6190, train loss on all blocks 2.6025526413493143\n",
      "Epoch 6200, train loss on all blocks 2.488250407369756\n",
      "Epoch 6210, train loss on all blocks 3.1461473402422353\n",
      "Epoch 6220, train loss on all blocks 2.494260624013081\n",
      "Epoch 6230, train loss on all blocks 2.6410695490564473\n",
      "Epoch 6240, train loss on all blocks 2.609337683536285\n",
      "Epoch 6250, train loss on all blocks 2.448888035825139\n",
      "Epoch 6260, train loss on all blocks 2.4176507856554803\n",
      "Epoch 6270, train loss on all blocks 3.1575010358681155\n",
      "Epoch 6280, train loss on all blocks 2.5210816096756212\n",
      "Epoch 6290, train loss on all blocks 2.8831335221871663\n",
      "Epoch 6300, train loss on all blocks 2.5985105120804732\n",
      "Epoch 6310, train loss on all blocks 2.498311334553157\n",
      "Epoch 6320, train loss on all blocks 2.449042515498753\n",
      "Epoch 6330, train loss on all blocks 2.5027336373149613\n",
      "Epoch 6340, train loss on all blocks 2.4130667836103297\n",
      "Epoch 6350, train loss on all blocks 2.7702984771658734\n",
      "Epoch 6360, train loss on all blocks 2.553206398844183\n",
      "Epoch 6370, train loss on all blocks 3.2712988544856447\n",
      "Epoch 6380, train loss on all blocks 2.4955867742024704\n",
      "Epoch 6390, train loss on all blocks 2.646483542315545\n",
      "Epoch 6400, train loss on all blocks 2.59347701213572\n",
      "Epoch 6410, train loss on all blocks 2.4852880779191127\n",
      "Epoch 6420, train loss on all blocks 2.4174663795647913\n",
      "Epoch 6430, train loss on all blocks 3.171117170371368\n",
      "Epoch 6440, train loss on all blocks 2.652561842888093\n",
      "Epoch 6450, train loss on all blocks 2.5864911884808843\n",
      "Epoch 6460, train loss on all blocks 2.4802917888934584\n",
      "Epoch 6470, train loss on all blocks 2.4306024242444995\n",
      "Epoch 6480, train loss on all blocks 3.1207713327575064\n",
      "Epoch 6490, train loss on all blocks 2.539935069891929\n",
      "Epoch 6500, train loss on all blocks 2.4507737924328796\n",
      "Epoch 6510, train loss on all blocks 2.4872963471457705\n",
      "Epoch 6520, train loss on all blocks 2.4052475540541813\n",
      "Epoch 6530, train loss on all blocks 2.4253098915742237\n",
      "Epoch 6540, train loss on all blocks 2.8275780117071507\n",
      "Epoch 6550, train loss on all blocks 2.476968629670415\n",
      "Epoch 6560, train loss on all blocks 3.182339546151059\n",
      "Epoch 6570, train loss on all blocks 2.913695500203522\n",
      "Epoch 6580, train loss on all blocks 2.631855489728214\n",
      "Epoch 6590, train loss on all blocks 2.4929596981308038\n",
      "Epoch 6600, train loss on all blocks 2.8593474771806195\n",
      "Epoch 6610, train loss on all blocks 2.4807410427989813\n",
      "Epoch 6620, train loss on all blocks 2.4808420777059075\n",
      "Epoch 6630, train loss on all blocks 2.427451771233919\n",
      "Epoch 6640, train loss on all blocks 2.7301985728847167\n",
      "Epoch 6650, train loss on all blocks 2.4595217779702345\n",
      "Epoch 6660, train loss on all blocks 2.412529399994872\n",
      "Epoch 6670, train loss on all blocks 2.5630361558087698\n",
      "Epoch 6680, train loss on all blocks 2.5963214557962226\n",
      "Epoch 6690, train loss on all blocks 2.454702979852933\n",
      "Epoch 6700, train loss on all blocks 2.4161113401307532\n",
      "Epoch 6710, train loss on all blocks 2.3763430043280067\n",
      "Epoch 6720, train loss on all blocks 3.3558443175732933\n",
      "Epoch 6730, train loss on all blocks 2.5593614375896037\n",
      "Epoch 6740, train loss on all blocks 2.5325765677845764\n",
      "Epoch 6750, train loss on all blocks 2.4402093624027783\n",
      "Epoch 6760, train loss on all blocks 2.430953477592398\n",
      "Epoch 6770, train loss on all blocks 2.445002752258368\n",
      "Epoch 6780, train loss on all blocks 2.4172563847120703\n",
      "Epoch 6790, train loss on all blocks 2.665004947204486\n",
      "Epoch 6800, train loss on all blocks 2.7914044942661844\n",
      "Epoch 6810, train loss on all blocks 2.483899562486764\n",
      "Epoch 6820, train loss on all blocks 2.456241864466697\n",
      "Epoch 6830, train loss on all blocks 2.409400482967736\n",
      "Epoch 6840, train loss on all blocks 2.3850716389377307\n",
      "Epoch 6850, train loss on all blocks 3.867870195383461\n",
      "Epoch 6860, train loss on all blocks 2.7957882828714666\n",
      "Epoch 6870, train loss on all blocks 2.583863160663634\n",
      "Epoch 6880, train loss on all blocks 3.063108605672066\n",
      "Epoch 6890, train loss on all blocks 2.6679392966416526\n",
      "Epoch 6900, train loss on all blocks 2.5063623787656018\n",
      "Epoch 6910, train loss on all blocks 2.4310597390505997\n",
      "Epoch 6920, train loss on all blocks 2.419315158088332\n",
      "Epoch 6930, train loss on all blocks 2.3940478765486386\n",
      "Epoch 6940, train loss on all blocks 2.3666522117575015\n",
      "Epoch 6950, train loss on all blocks 2.381872767195653\n",
      "Epoch 6960, train loss on all blocks 2.7235270477102533\n",
      "Epoch 6970, train loss on all blocks 2.918717305509723\n",
      "Epoch 6980, train loss on all blocks 2.5733672813089563\n",
      "Epoch 6990, train loss on all blocks 2.5173389944268263\n",
      "Epoch 7000, train loss on all blocks 2.533611808062907\n",
      "Epoch 7010, train loss on all blocks 2.4189871627800326\n",
      "Epoch 7020, train loss on all blocks 4.684421195918361\n",
      "Epoch 7030, train loss on all blocks 2.9509158082436366\n",
      "Epoch 7040, train loss on all blocks 2.575605670862765\n",
      "Epoch 7050, train loss on all blocks 3.1407528261908073\n",
      "Epoch 7060, train loss on all blocks 2.5009029713550506\n",
      "Epoch 7070, train loss on all blocks 2.50491987898216\n",
      "Epoch 7080, train loss on all blocks 2.4007835974411478\n",
      "Epoch 7090, train loss on all blocks 2.3766134933190797\n",
      "Epoch 7100, train loss on all blocks 2.363781511848768\n",
      "Epoch 7110, train loss on all blocks 2.6140194978234863\n",
      "Epoch 7120, train loss on all blocks 2.4226391957629394\n",
      "Epoch 7130, train loss on all blocks 2.6343361027107464\n",
      "Epoch 7140, train loss on all blocks 2.473482412070907\n",
      "Epoch 7150, train loss on all blocks 2.424778412464523\n",
      "Epoch 7160, train loss on all blocks 2.4356180538442764\n",
      "Epoch 7170, train loss on all blocks 2.8079014587473643\n",
      "Epoch 7180, train loss on all blocks 2.453404485045868\n",
      "Epoch 7190, train loss on all blocks 2.450094761833573\n",
      "Epoch 7200, train loss on all blocks 2.406327850693959\n",
      "Epoch 7210, train loss on all blocks 2.684049257614757\n",
      "Epoch 7220, train loss on all blocks 2.4997650062411423\n",
      "Epoch 7230, train loss on all blocks 2.4023050544377105\n",
      "Epoch 7240, train loss on all blocks 2.8396229709102134\n",
      "Epoch 7250, train loss on all blocks 2.4734361441192085\n",
      "Epoch 7260, train loss on all blocks 2.384718332743511\n",
      "Epoch 7270, train loss on all blocks 2.3840972365447994\n",
      "Epoch 7280, train loss on all blocks 3.9925305053594995\n",
      "Epoch 7290, train loss on all blocks 2.6828624118211852\n",
      "Epoch 7300, train loss on all blocks 3.0296629257592587\n",
      "Epoch 7310, train loss on all blocks 2.712714776835914\n",
      "Epoch 7320, train loss on all blocks 2.4614137173496307\n",
      "Epoch 7330, train loss on all blocks 2.426883972973253\n",
      "Epoch 7340, train loss on all blocks 2.3998214416376564\n",
      "Epoch 7350, train loss on all blocks 2.3982761508640156\n",
      "Epoch 7360, train loss on all blocks 2.6692955890052286\n",
      "Epoch 7370, train loss on all blocks 2.4272952962829932\n",
      "Epoch 7380, train loss on all blocks 2.396220119699587\n",
      "Epoch 7390, train loss on all blocks 2.506873858536113\n",
      "Epoch 7400, train loss on all blocks 2.381670350839613\n",
      "Epoch 7410, train loss on all blocks 2.610106720621453\n",
      "Epoch 7420, train loss on all blocks 2.5296848048304486\n",
      "Epoch 7430, train loss on all blocks 2.4287293802312835\n",
      "Epoch 7440, train loss on all blocks 2.4068615000104945\n",
      "Epoch 7450, train loss on all blocks 2.9216862132282984\n",
      "Epoch 7460, train loss on all blocks 2.5118209834749585\n",
      "Epoch 7470, train loss on all blocks 2.444461764100624\n",
      "Epoch 7480, train loss on all blocks 2.490921500183372\n",
      "Epoch 7490, train loss on all blocks 2.715668326871177\n",
      "Epoch 7500, train loss on all blocks 2.4614109735681176\n",
      "Epoch 7510, train loss on all blocks 2.3920590884810813\n",
      "Epoch 7520, train loss on all blocks 2.452691793832109\n",
      "Epoch 7530, train loss on all blocks 2.3979820179696913\n",
      "Epoch 7540, train loss on all blocks 2.727448534519617\n",
      "Epoch 7550, train loss on all blocks 2.4890956107162667\n",
      "Epoch 7560, train loss on all blocks 3.5703197999281695\n",
      "Epoch 7570, train loss on all blocks 2.540909997434317\n",
      "Epoch 7580, train loss on all blocks 2.502166594856896\n",
      "Epoch 7590, train loss on all blocks 2.4418800689661033\n",
      "Epoch 7600, train loss on all blocks 2.374056931571981\n",
      "Epoch 7610, train loss on all blocks 2.422240464463669\n",
      "Epoch 7620, train loss on all blocks 3.0676992784563764\n",
      "Epoch 7630, train loss on all blocks 2.4177177584111744\n",
      "Epoch 7640, train loss on all blocks 2.376818343348782\n",
      "Epoch 7650, train loss on all blocks 2.357499234451047\n",
      "Epoch 7660, train loss on all blocks 2.458207884881323\n",
      "Epoch 7670, train loss on all blocks 2.465175610736466\n",
      "Epoch 7680, train loss on all blocks 2.568563264294679\n",
      "Epoch 7690, train loss on all blocks 2.585962006774089\n",
      "Epoch 7700, train loss on all blocks 2.5464996627993903\n",
      "Epoch 7710, train loss on all blocks 2.422291477149077\n",
      "Epoch 7720, train loss on all blocks 2.432922117678478\n",
      "Epoch 7730, train loss on all blocks 2.387391668372654\n",
      "Epoch 7740, train loss on all blocks 2.3533059298483883\n",
      "Epoch 7750, train loss on all blocks 2.465805444753343\n",
      "Epoch 7760, train loss on all blocks 2.4297173582521356\n",
      "Epoch 7770, train loss on all blocks 2.423917557571657\n",
      "Epoch 7780, train loss on all blocks 2.613657354502239\n",
      "Epoch 7790, train loss on all blocks 2.4522009767953827\n",
      "Epoch 7800, train loss on all blocks 2.398718396087305\n",
      "Epoch 7810, train loss on all blocks 2.3572031602252412\n",
      "Epoch 7820, train loss on all blocks 2.7105837773581394\n",
      "Epoch 7830, train loss on all blocks 2.67827954797784\n",
      "Epoch 7840, train loss on all blocks 2.387475955341525\n",
      "Epoch 7850, train loss on all blocks 2.368976535227242\n",
      "Epoch 7860, train loss on all blocks 2.410591683948983\n",
      "Epoch 7870, train loss on all blocks 2.325533541800966\n",
      "Epoch 7880, train loss on all blocks 2.3990184330993323\n",
      "Epoch 7890, train loss on all blocks 3.4090054961238105\n",
      "Epoch 7900, train loss on all blocks 3.0221926958918184\n",
      "Epoch 7910, train loss on all blocks 2.5629543963713823\n",
      "Epoch 7920, train loss on all blocks 2.4909239386474242\n",
      "Epoch 7930, train loss on all blocks 2.4017712955888095\n",
      "Epoch 7940, train loss on all blocks 2.4879908940085436\n",
      "Epoch 7950, train loss on all blocks 2.362129589298406\n",
      "Epoch 7960, train loss on all blocks 2.3191617790816066\n",
      "Epoch 7970, train loss on all blocks 2.431487905803872\n",
      "Epoch 7980, train loss on all blocks 2.817212555545936\n",
      "Epoch 7990, train loss on all blocks 2.6079221649294313\n",
      "Epoch 8000, train loss on all blocks 2.443826179274427\n",
      "Epoch 8010, train loss on all blocks 2.355105975160331\n",
      "Epoch 8020, train loss on all blocks 2.3561182800479417\n",
      "Epoch 8030, train loss on all blocks 2.4424131850157345\n",
      "Epoch 8040, train loss on all blocks 2.45503744921902\n",
      "Epoch 8050, train loss on all blocks 2.3559207394945387\n",
      "Epoch 8060, train loss on all blocks 2.3300100651919053\n",
      "Epoch 8070, train loss on all blocks 2.429449661652497\n",
      "Epoch 8080, train loss on all blocks 2.5355258533940326\n",
      "Epoch 8090, train loss on all blocks 2.696975538251902\n",
      "Epoch 8100, train loss on all blocks 2.548230033871387\n",
      "Epoch 8110, train loss on all blocks 2.421535244863722\n",
      "Epoch 8120, train loss on all blocks 2.3824441784490107\n",
      "Epoch 8130, train loss on all blocks 2.360032807337541\n",
      "Epoch 8140, train loss on all blocks 2.324879821863452\n",
      "Epoch 8150, train loss on all blocks 2.333956467580645\n",
      "Epoch 8160, train loss on all blocks 2.564998963077593\n",
      "Epoch 8170, train loss on all blocks 3.1253157412816517\n",
      "Epoch 8180, train loss on all blocks 2.410471136022948\n",
      "Epoch 8190, train loss on all blocks 2.548222830911656\n",
      "Epoch 8200, train loss on all blocks 2.3877313171093792\n",
      "Epoch 8210, train loss on all blocks 2.3358719226952775\n",
      "Epoch 8220, train loss on all blocks 2.479490126356935\n",
      "Epoch 8230, train loss on all blocks 2.4609285578306315\n",
      "Epoch 8240, train loss on all blocks 2.821287307597195\n",
      "Epoch 8250, train loss on all blocks 2.612926601754743\n",
      "Epoch 8260, train loss on all blocks 2.476666891139687\n",
      "Epoch 8270, train loss on all blocks 2.37684076839751\n",
      "Epoch 8280, train loss on all blocks 2.3481549694078443\n",
      "Epoch 8290, train loss on all blocks 2.908544119521418\n",
      "Epoch 8300, train loss on all blocks 2.4513277173994146\n",
      "Epoch 8310, train loss on all blocks 2.381658645339905\n",
      "Epoch 8320, train loss on all blocks 2.343777076334355\n",
      "Epoch 8330, train loss on all blocks 2.415265558119024\n",
      "Epoch 8340, train loss on all blocks 2.3400926380100753\n",
      "Epoch 8350, train loss on all blocks 2.7242171733951768\n",
      "Epoch 8360, train loss on all blocks 2.482035223228505\n",
      "Epoch 8370, train loss on all blocks 2.551784456772916\n",
      "Epoch 8380, train loss on all blocks 2.434093014159941\n",
      "Epoch 8390, train loss on all blocks 2.376916244852314\n",
      "Epoch 8400, train loss on all blocks 2.3282026037272825\n",
      "Epoch 8410, train loss on all blocks 2.321025398362945\n",
      "Epoch 8420, train loss on all blocks 2.3387178451013466\n",
      "Epoch 8430, train loss on all blocks 3.3175353973415342\n",
      "Epoch 8440, train loss on all blocks 2.94473205218104\n",
      "Epoch 8450, train loss on all blocks 2.449261243311467\n",
      "Epoch 8460, train loss on all blocks 2.3999420738852173\n",
      "Epoch 8470, train loss on all blocks 2.3387417808845807\n",
      "Epoch 8480, train loss on all blocks 2.3334432803734853\n",
      "Epoch 8490, train loss on all blocks 2.434054134454132\n",
      "Epoch 8500, train loss on all blocks 2.325835938777854\n",
      "Epoch 8510, train loss on all blocks 3.022997869416214\n",
      "Epoch 8520, train loss on all blocks 2.622642170882965\n",
      "Epoch 8530, train loss on all blocks 2.4810937645969857\n",
      "Epoch 8540, train loss on all blocks 2.3592638087625706\n",
      "Epoch 8550, train loss on all blocks 2.3362027853671625\n",
      "Epoch 8560, train loss on all blocks 2.313321076084932\n",
      "Epoch 8570, train loss on all blocks 2.3016544153363956\n",
      "Epoch 8580, train loss on all blocks 3.780557010166212\n",
      "Epoch 8590, train loss on all blocks 2.7172278172813114\n",
      "Epoch 8600, train loss on all blocks 3.1016420975100947\n",
      "Epoch 8610, train loss on all blocks 2.594132760954903\n",
      "Epoch 8620, train loss on all blocks 2.430549437657244\n",
      "Epoch 8630, train loss on all blocks 2.384465977522704\n",
      "Epoch 8640, train loss on all blocks 2.37278558690913\n",
      "Epoch 8650, train loss on all blocks 2.3361478199557584\n",
      "Epoch 8660, train loss on all blocks 2.3646489299856452\n",
      "Epoch 8670, train loss on all blocks 2.3551094201590432\n",
      "Epoch 8680, train loss on all blocks 2.342613841690331\n",
      "Epoch 8690, train loss on all blocks 4.721157067146705\n",
      "Epoch 8700, train loss on all blocks 2.96106050540597\n",
      "Epoch 8710, train loss on all blocks 2.5945419900645916\n",
      "Epoch 8720, train loss on all blocks 2.4845162480346623\n",
      "Epoch 8730, train loss on all blocks 2.412707007303151\n",
      "Epoch 8740, train loss on all blocks 2.523397686846898\n",
      "Epoch 8750, train loss on all blocks 2.3547190351912994\n",
      "Epoch 8760, train loss on all blocks 2.3073317340115684\n",
      "Epoch 8770, train loss on all blocks 2.2961651149649267\n",
      "Epoch 8780, train loss on all blocks 2.38620174222874\n",
      "Epoch 8790, train loss on all blocks 2.5711623746039702\n",
      "Epoch 8800, train loss on all blocks 2.62845007320772\n",
      "Epoch 8810, train loss on all blocks 2.7995124902651796\n",
      "Epoch 8820, train loss on all blocks 2.5021536685320043\n",
      "Epoch 8830, train loss on all blocks 2.3588436787675287\n",
      "Epoch 8840, train loss on all blocks 2.31756524396724\n",
      "Epoch 8850, train loss on all blocks 2.306091370728697\n",
      "Epoch 8860, train loss on all blocks 2.343703463905312\n",
      "Epoch 8870, train loss on all blocks 4.2125041689460865\n",
      "Epoch 8880, train loss on all blocks 3.1385360876878576\n",
      "Epoch 8890, train loss on all blocks 2.656904074644686\n",
      "Epoch 8900, train loss on all blocks 2.57082948707532\n",
      "Epoch 8910, train loss on all blocks 2.4581719787142964\n",
      "Epoch 8920, train loss on all blocks 2.3870710436205904\n",
      "Epoch 8930, train loss on all blocks 2.318918434387802\n",
      "Epoch 8940, train loss on all blocks 2.302354719396984\n",
      "Epoch 8950, train loss on all blocks 2.2790495601749443\n",
      "Epoch 8960, train loss on all blocks 2.9107699142162007\n",
      "Epoch 8970, train loss on all blocks 2.6384025090399232\n",
      "Epoch 8980, train loss on all blocks 2.4570226805550672\n",
      "Epoch 8990, train loss on all blocks 2.378144980384488\n",
      "Epoch 9000, train loss on all blocks 2.3405657388766876\n",
      "Epoch 9010, train loss on all blocks 2.357568055424344\n",
      "Epoch 9020, train loss on all blocks 2.2993357520539393\n",
      "Epoch 9030, train loss on all blocks 2.28527769685919\n",
      "Epoch 9040, train loss on all blocks 2.8364678218925587\n",
      "Epoch 9050, train loss on all blocks 2.725221231649405\n",
      "Epoch 9060, train loss on all blocks 2.3944270707826556\n",
      "Epoch 9070, train loss on all blocks 2.343153608283497\n",
      "Epoch 9080, train loss on all blocks 2.35005024476695\n",
      "Epoch 9090, train loss on all blocks 2.307120117927937\n",
      "Epoch 9100, train loss on all blocks 2.275880909247329\n",
      "Epoch 9110, train loss on all blocks 2.8180572779719872\n",
      "Epoch 9120, train loss on all blocks 2.4796911091179235\n",
      "Epoch 9130, train loss on all blocks 2.5971705598041277\n",
      "Epoch 9140, train loss on all blocks 2.6399555223456024\n",
      "Epoch 9150, train loss on all blocks 2.475611164145569\n",
      "Epoch 9160, train loss on all blocks 2.4077571458964027\n",
      "Epoch 9170, train loss on all blocks 2.344512116615212\n",
      "Epoch 9180, train loss on all blocks 2.4139252904522115\n",
      "Epoch 9190, train loss on all blocks 2.3028740947601367\n",
      "Epoch 9200, train loss on all blocks 2.3680454381710985\n",
      "Epoch 9210, train loss on all blocks 2.595042417411423\n",
      "Epoch 9220, train loss on all blocks 2.3936384050476294\n",
      "Epoch 9230, train loss on all blocks 2.331379004670849\n",
      "Epoch 9240, train loss on all blocks 2.765842142600108\n",
      "Epoch 9250, train loss on all blocks 2.434420271175917\n",
      "Epoch 9260, train loss on all blocks 2.343290794040363\n",
      "Epoch 9270, train loss on all blocks 2.350976923837539\n",
      "Epoch 9280, train loss on all blocks 2.5849486630674665\n",
      "Epoch 9290, train loss on all blocks 2.414733541211234\n",
      "Epoch 9300, train loss on all blocks 2.332755448205546\n",
      "Epoch 9310, train loss on all blocks 2.2951131721429006\n",
      "Epoch 9320, train loss on all blocks 2.4140304641592296\n",
      "Epoch 9330, train loss on all blocks 2.737678149918727\n",
      "Epoch 9340, train loss on all blocks 2.3935953178393095\n",
      "Epoch 9350, train loss on all blocks 2.836929498399992\n",
      "Epoch 9360, train loss on all blocks 2.8781313117322336\n",
      "Epoch 9370, train loss on all blocks 2.437000212493433\n",
      "Epoch 9380, train loss on all blocks 2.3399118543802437\n",
      "Epoch 9390, train loss on all blocks 2.357015473180992\n",
      "Epoch 9400, train loss on all blocks 2.3247547630974372\n",
      "Epoch 9410, train loss on all blocks 2.270770531982964\n",
      "Epoch 9420, train loss on all blocks 2.752644054642451\n",
      "Epoch 9430, train loss on all blocks 3.2220386379234185\n",
      "Epoch 9440, train loss on all blocks 2.4952502184357446\n",
      "Epoch 9450, train loss on all blocks 2.6304794466259462\n",
      "Epoch 9460, train loss on all blocks 2.3621582671185513\n",
      "Epoch 9470, train loss on all blocks 2.333543770421609\n",
      "Epoch 9480, train loss on all blocks 2.2867239073244434\n",
      "Epoch 9490, train loss on all blocks 2.307869478126909\n",
      "Epoch 9500, train loss on all blocks 2.2880494305709664\n",
      "Epoch 9510, train loss on all blocks 2.662420006267619\n",
      "Epoch 9520, train loss on all blocks 2.5524887907018043\n",
      "Epoch 9530, train loss on all blocks 2.6606714728018073\n",
      "Epoch 9540, train loss on all blocks 2.5277413699890094\n",
      "Epoch 9550, train loss on all blocks 2.4631608967727487\n",
      "Epoch 9560, train loss on all blocks 2.3848080053750937\n",
      "Epoch 9570, train loss on all blocks 2.3337934037358217\n",
      "Epoch 9580, train loss on all blocks 2.298718365900311\n",
      "Epoch 9590, train loss on all blocks 2.2656677262651526\n",
      "Epoch 9600, train loss on all blocks 2.2565231232388996\n",
      "Epoch 9610, train loss on all blocks 2.464827053671377\n",
      "Epoch 9620, train loss on all blocks 3.0940538107800277\n",
      "Epoch 9630, train loss on all blocks 3.4153668372137327\n",
      "Epoch 9640, train loss on all blocks 2.4888787698421044\n",
      "Epoch 9650, train loss on all blocks 2.4502753615995774\n",
      "Epoch 9660, train loss on all blocks 2.364795786367238\n",
      "Epoch 9670, train loss on all blocks 2.3125399391612924\n",
      "Epoch 9680, train loss on all blocks 2.2727530992001332\n",
      "Epoch 9690, train loss on all blocks 2.284646739750228\n",
      "Epoch 9700, train loss on all blocks 2.263668686134763\n",
      "Epoch 9710, train loss on all blocks 2.277011899571662\n",
      "Epoch 9720, train loss on all blocks 3.5165289709709358\n",
      "Epoch 9730, train loss on all blocks 2.663125833467972\n",
      "Epoch 9740, train loss on all blocks 2.437052158339097\n",
      "Epoch 9750, train loss on all blocks 2.372940631380457\n",
      "Epoch 9760, train loss on all blocks 2.3355615683488304\n",
      "Epoch 9770, train loss on all blocks 2.3440551209864924\n",
      "Epoch 9780, train loss on all blocks 2.3127003709061063\n",
      "Epoch 9790, train loss on all blocks 2.2624953831433157\n",
      "Epoch 9800, train loss on all blocks 2.3383509947583345\n",
      "Epoch 9810, train loss on all blocks 3.007335450668708\n",
      "Epoch 9820, train loss on all blocks 2.555878038881871\n",
      "Epoch 9830, train loss on all blocks 2.364207514394489\n",
      "Epoch 9840, train loss on all blocks 2.315044795577686\n",
      "Epoch 9850, train loss on all blocks 2.295890319159241\n",
      "Epoch 9860, train loss on all blocks 2.318512682611132\n",
      "Epoch 9870, train loss on all blocks 2.4505627530626377\n",
      "Epoch 9880, train loss on all blocks 2.806900132060537\n",
      "Epoch 9890, train loss on all blocks 2.4447976480612783\n",
      "Epoch 9900, train loss on all blocks 2.6315111786783945\n",
      "Epoch 9910, train loss on all blocks 2.7689774508085527\n",
      "Epoch 9920, train loss on all blocks 2.4475175126917295\n",
      "Epoch 9930, train loss on all blocks 2.3531056016285348\n",
      "Epoch 9940, train loss on all blocks 2.321540528414271\n",
      "Epoch 9950, train loss on all blocks 2.2888979762425192\n",
      "Epoch 9960, train loss on all blocks 2.285818112168954\n",
      "Epoch 9970, train loss on all blocks 2.4148317040799743\n",
      "Epoch 9980, train loss on all blocks 2.4549219360347827\n",
      "Epoch 9990, train loss on all blocks 2.414875517782429\n",
      "Epoch 10000, train loss on all blocks 2.3024017117561533\n",
      "Epoch 10010, train loss on all blocks 2.297430785398627\n",
      "Epoch 10020, train loss on all blocks 3.4086157315803574\n",
      "Epoch 10030, train loss on all blocks 2.6176293458708595\n",
      "Epoch 10040, train loss on all blocks 2.4292000728483423\n",
      "Epoch 10050, train loss on all blocks 2.4050412406067956\n",
      "Epoch 10060, train loss on all blocks 2.714778457938581\n",
      "Epoch 10070, train loss on all blocks 2.423836833020232\n",
      "Epoch 10080, train loss on all blocks 2.327260375841358\n",
      "Epoch 10090, train loss on all blocks 2.284865745636437\n",
      "Epoch 10100, train loss on all blocks 2.471650826230254\n",
      "Epoch 10110, train loss on all blocks 2.3157372972080674\n",
      "Epoch 10120, train loss on all blocks 2.2595769772500187\n",
      "Epoch 10130, train loss on all blocks 3.0292080944273834\n",
      "Epoch 10140, train loss on all blocks 2.5094670834087953\n",
      "Epoch 10150, train loss on all blocks 2.4903180871067514\n",
      "Epoch 10160, train loss on all blocks 2.4521770938478245\n",
      "Epoch 10170, train loss on all blocks 2.3966191524829337\n",
      "Epoch 10180, train loss on all blocks 2.536877204594102\n",
      "Epoch 10190, train loss on all blocks 2.339197750471066\n",
      "Epoch 10200, train loss on all blocks 2.2762559815269783\n",
      "Epoch 10210, train loss on all blocks 2.254350119680377\n",
      "Epoch 10220, train loss on all blocks 2.3567982822704066\n",
      "Epoch 10230, train loss on all blocks 3.0984456916484455\n",
      "Epoch 10240, train loss on all blocks 2.3838637376809118\n",
      "Epoch 10250, train loss on all blocks 2.866420849258469\n",
      "Epoch 10260, train loss on all blocks 2.5320923883185547\n",
      "Epoch 10270, train loss on all blocks 2.3847410184702182\n",
      "Epoch 10280, train loss on all blocks 2.290004901861277\n",
      "Epoch 10290, train loss on all blocks 2.2653922512514795\n",
      "Epoch 10300, train loss on all blocks 2.364911860163757\n",
      "Epoch 10310, train loss on all blocks 2.2684237907373968\n",
      "Epoch 10320, train loss on all blocks 2.2395376213175022\n",
      "Epoch 10330, train loss on all blocks 2.280310074477663\n",
      "Epoch 10340, train loss on all blocks 2.5199443039050156\n",
      "Epoch 10350, train loss on all blocks 2.7297133949568053\n",
      "Epoch 10360, train loss on all blocks 2.4510704025839125\n",
      "Epoch 10370, train loss on all blocks 2.3567397663977885\n",
      "Epoch 10380, train loss on all blocks 2.302480131989947\n",
      "Epoch 10390, train loss on all blocks 2.2635125789504054\n",
      "Epoch 10400, train loss on all blocks 2.2347004378159463\n",
      "Epoch 10410, train loss on all blocks 2.221184376166155\n",
      "Epoch 10420, train loss on all blocks 2.4600040800625784\n",
      "Epoch 10430, train loss on all blocks 2.8089526455257805\n",
      "Epoch 10440, train loss on all blocks 4.840385105010097\n",
      "Epoch 10450, train loss on all blocks 2.639270877270262\n",
      "Epoch 10460, train loss on all blocks 2.516222764940726\n",
      "Epoch 10470, train loss on all blocks 2.4189286888998334\n",
      "Epoch 10480, train loss on all blocks 2.3184261256498657\n",
      "Epoch 10490, train loss on all blocks 2.2705646051074924\n",
      "Epoch 10500, train loss on all blocks 2.242750336599613\n",
      "Epoch 10510, train loss on all blocks 2.472649169489367\n",
      "Epoch 10520, train loss on all blocks 2.318392982058171\n",
      "Epoch 10530, train loss on all blocks 2.5039187089694064\n",
      "Epoch 10540, train loss on all blocks 2.341388018380173\n",
      "Epoch 10550, train loss on all blocks 2.9768611117479624\n",
      "Epoch 10560, train loss on all blocks 2.3451392969933735\n",
      "Epoch 10570, train loss on all blocks 2.3070579497613144\n",
      "Epoch 10580, train loss on all blocks 2.248925775732843\n",
      "Epoch 10590, train loss on all blocks 2.234134018748572\n",
      "Epoch 10600, train loss on all blocks 2.2312277873090256\n",
      "Epoch 10610, train loss on all blocks 2.2750362790221006\n",
      "Epoch 10620, train loss on all blocks 3.0543749878702426\n",
      "Epoch 10630, train loss on all blocks 2.451215200956023\n",
      "Epoch 10640, train loss on all blocks 2.3287155444214465\n",
      "Epoch 10650, train loss on all blocks 2.3178445541976673\n",
      "Epoch 10660, train loss on all blocks 2.2523039903995725\n",
      "Epoch 10670, train loss on all blocks 2.2665499203697568\n",
      "Epoch 10680, train loss on all blocks 2.239259888724586\n",
      "Epoch 10690, train loss on all blocks 3.1494133881552537\n",
      "Epoch 10700, train loss on all blocks 2.9593114055346916\n",
      "Epoch 10710, train loss on all blocks 2.48874945161834\n",
      "Epoch 10720, train loss on all blocks 2.40089162854046\n",
      "Epoch 10730, train loss on all blocks 2.378043696480474\n",
      "Epoch 10740, train loss on all blocks 2.2805416302511547\n",
      "Epoch 10750, train loss on all blocks 2.2421435379183503\n",
      "Epoch 10760, train loss on all blocks 3.0730814154831814\n",
      "Epoch 10770, train loss on all blocks 2.8029593854409445\n",
      "Epoch 10780, train loss on all blocks 2.4899594343562246\n",
      "Epoch 10790, train loss on all blocks 2.4428220549416997\n",
      "Epoch 10800, train loss on all blocks 2.3206153943256354\n",
      "Epoch 10810, train loss on all blocks 2.4114747634455305\n",
      "Epoch 10820, train loss on all blocks 2.4177432219546175\n",
      "Epoch 10830, train loss on all blocks 2.3179677503784863\n",
      "Epoch 10840, train loss on all blocks 2.286559405083708\n",
      "Epoch 10850, train loss on all blocks 2.234418603147618\n",
      "Epoch 10860, train loss on all blocks 2.3078407179466494\n",
      "Epoch 10870, train loss on all blocks 2.211954128305661\n",
      "Epoch 10880, train loss on all blocks 2.2172508266941704\n",
      "Epoch 10890, train loss on all blocks 4.142176782080185\n",
      "Epoch 10900, train loss on all blocks 2.722061323632749\n",
      "Epoch 10910, train loss on all blocks 2.5070258278983517\n",
      "Epoch 10920, train loss on all blocks 2.3486633855513785\n",
      "Epoch 10930, train loss on all blocks 2.37470004801334\n",
      "Epoch 10940, train loss on all blocks 2.268464872119802\n",
      "Epoch 10950, train loss on all blocks 2.235006586910982\n",
      "Epoch 10960, train loss on all blocks 2.2163475990969896\n",
      "Epoch 10970, train loss on all blocks 2.200840023197837\n",
      "Epoch 10980, train loss on all blocks 3.4046309414431475\n",
      "Epoch 10990, train loss on all blocks 3.22223121044865\n",
      "Epoch 11000, train loss on all blocks 2.781516123070819\n",
      "Epoch 11010, train loss on all blocks 2.444533433949437\n",
      "Epoch 11020, train loss on all blocks 2.3304842508421535\n",
      "Epoch 11030, train loss on all blocks 2.285956114801582\n",
      "Epoch 11040, train loss on all blocks 2.2351151002047187\n",
      "Epoch 11050, train loss on all blocks 2.2132902068873324\n",
      "Epoch 11060, train loss on all blocks 2.217490988916781\n",
      "Epoch 11070, train loss on all blocks 2.2335042943604893\n",
      "Epoch 11080, train loss on all blocks 2.566625094513179\n",
      "Epoch 11090, train loss on all blocks 2.446278617809321\n",
      "Epoch 11100, train loss on all blocks 2.431136351544372\n",
      "Epoch 11110, train loss on all blocks 2.3728181641962185\n",
      "Epoch 11120, train loss on all blocks 2.2754892407575937\n",
      "Epoch 11130, train loss on all blocks 2.2249904900201667\n",
      "Epoch 11140, train loss on all blocks 2.2155239029314324\n",
      "Epoch 11150, train loss on all blocks 2.2761864401854632\n",
      "Epoch 11160, train loss on all blocks 2.227218407388033\n",
      "Epoch 11170, train loss on all blocks 2.850560221629359\n",
      "Epoch 11180, train loss on all blocks 2.390302513724224\n",
      "Epoch 11190, train loss on all blocks 2.3482215512203544\n",
      "Epoch 11200, train loss on all blocks 2.2967470360611224\n",
      "Epoch 11210, train loss on all blocks 2.3150936584836863\n",
      "Epoch 11220, train loss on all blocks 2.2313673975924893\n",
      "Epoch 11230, train loss on all blocks 2.203761245464376\n",
      "Epoch 11240, train loss on all blocks 2.762657130653018\n",
      "Epoch 11250, train loss on all blocks 2.629049944305741\n",
      "Epoch 11260, train loss on all blocks 2.5799576584659194\n",
      "Epoch 11270, train loss on all blocks 2.4668915958984243\n",
      "Epoch 11280, train loss on all blocks 2.391812267280073\n",
      "Epoch 11290, train loss on all blocks 2.4116405176990448\n",
      "Epoch 11300, train loss on all blocks 2.2896749811051746\n",
      "Epoch 11310, train loss on all blocks 2.239742458653865\n",
      "Epoch 11320, train loss on all blocks 2.2687114779719977\n",
      "Epoch 11330, train loss on all blocks 2.206775042258343\n",
      "Epoch 11340, train loss on all blocks 2.197096709675198\n",
      "Epoch 11350, train loss on all blocks 3.2034748099192694\n",
      "Epoch 11360, train loss on all blocks 3.112785211350801\n",
      "Epoch 11370, train loss on all blocks 2.484875749405461\n",
      "Epoch 11380, train loss on all blocks 2.388954674956281\n",
      "Epoch 11390, train loss on all blocks 2.273505974526343\n",
      "Epoch 11400, train loss on all blocks 2.249878787971495\n",
      "Epoch 11410, train loss on all blocks 2.2118577356795575\n",
      "Epoch 11420, train loss on all blocks 2.207616484211443\n",
      "Epoch 11430, train loss on all blocks 2.203707079242286\n",
      "Epoch 11440, train loss on all blocks 2.2015582276447647\n",
      "Epoch 11450, train loss on all blocks 2.4218775820195484\n",
      "Epoch 11460, train loss on all blocks 2.622326002477022\n",
      "Epoch 11470, train loss on all blocks 2.488379714879133\n",
      "Epoch 11480, train loss on all blocks 2.371323968629219\n",
      "Epoch 11490, train loss on all blocks 2.2949983850406657\n",
      "Epoch 11500, train loss on all blocks 2.242577284089989\n",
      "Epoch 11510, train loss on all blocks 2.226991459515493\n",
      "Epoch 11520, train loss on all blocks 2.2473520896564256\n",
      "Epoch 11530, train loss on all blocks 2.2340088955257382\n",
      "Epoch 11540, train loss on all blocks 3.6462465194619913\n",
      "Epoch 11550, train loss on all blocks 2.422523163056473\n",
      "Epoch 11560, train loss on all blocks 2.5860421637681283\n",
      "Epoch 11570, train loss on all blocks 2.4925610463527157\n",
      "Epoch 11580, train loss on all blocks 2.303655456462751\n",
      "Epoch 11590, train loss on all blocks 2.3668969550161694\n",
      "Epoch 11600, train loss on all blocks 2.2499790965215585\n",
      "Epoch 11610, train loss on all blocks 2.2031788374542374\n",
      "Epoch 11620, train loss on all blocks 2.260264559114063\n",
      "Epoch 11630, train loss on all blocks 2.679216495440035\n",
      "Epoch 11640, train loss on all blocks 2.3939041423423895\n",
      "Epoch 11650, train loss on all blocks 2.3027423829332596\n",
      "Epoch 11660, train loss on all blocks 2.4068912192326115\n",
      "Epoch 11670, train loss on all blocks 2.336603995799734\n",
      "Epoch 11680, train loss on all blocks 2.4585777742280417\n",
      "Epoch 11690, train loss on all blocks 2.2982709600216564\n",
      "Epoch 11700, train loss on all blocks 2.222697884912007\n",
      "Epoch 11710, train loss on all blocks 2.2046438962798227\n",
      "Epoch 11720, train loss on all blocks 2.2015321723864414\n",
      "Epoch 11730, train loss on all blocks 2.4547992145758677\n",
      "Epoch 11740, train loss on all blocks 2.4015678888560186\n",
      "Epoch 11750, train loss on all blocks 2.463548545010734\n",
      "Epoch 11760, train loss on all blocks 2.7051280890575256\n",
      "Epoch 11770, train loss on all blocks 2.477368944286841\n",
      "Epoch 11780, train loss on all blocks 2.415629028228996\n",
      "Epoch 11790, train loss on all blocks 2.3376632838588707\n",
      "Epoch 11800, train loss on all blocks 2.3062957223342107\n",
      "Epoch 11810, train loss on all blocks 2.243344192642276\n",
      "Epoch 11820, train loss on all blocks 2.2092861984852075\n",
      "Epoch 11830, train loss on all blocks 3.1547963139424935\n",
      "Epoch 11840, train loss on all blocks 2.3229715301547618\n",
      "Epoch 11850, train loss on all blocks 2.266424855178795\n",
      "Epoch 11860, train loss on all blocks 2.2711848288552208\n",
      "Epoch 11870, train loss on all blocks 2.426902721014102\n",
      "Epoch 11880, train loss on all blocks 2.345387965851753\n",
      "Epoch 11890, train loss on all blocks 2.2228890826115366\n",
      "Epoch 11900, train loss on all blocks 2.2027697347461803\n",
      "Epoch 11910, train loss on all blocks 2.385466970951957\n",
      "Epoch 11920, train loss on all blocks 2.4317140041864285\n",
      "Epoch 11930, train loss on all blocks 2.329762106718804\n",
      "Epoch 11940, train loss on all blocks 2.4582956105400435\n",
      "Epoch 11950, train loss on all blocks 2.405805477369369\n",
      "Epoch 11960, train loss on all blocks 2.3107580524092617\n",
      "Epoch 11970, train loss on all blocks 2.3345922357614954\n",
      "Epoch 11980, train loss on all blocks 2.21067608538367\n",
      "Epoch 11990, train loss on all blocks 2.319994690871339\n",
      "Epoch 12000, train loss on all blocks 2.2028331753637547\n",
      "Epoch 12010, train loss on all blocks 5.1692632610992035\n",
      "Epoch 12020, train loss on all blocks 2.565227014243617\n",
      "Epoch 12030, train loss on all blocks 2.638961114492964\n",
      "Epoch 12040, train loss on all blocks 2.9361857907720736\n",
      "Epoch 12050, train loss on all blocks 2.435499609880028\n",
      "Epoch 12060, train loss on all blocks 2.3789224836969023\n",
      "Epoch 12070, train loss on all blocks 2.3545791204882827\n",
      "Epoch 12080, train loss on all blocks 2.4768599495120522\n",
      "Epoch 12090, train loss on all blocks 2.2935176782801627\n",
      "Epoch 12100, train loss on all blocks 2.219476449297246\n",
      "Epoch 12110, train loss on all blocks 2.279946250190034\n",
      "Epoch 12120, train loss on all blocks 2.1991594714309244\n",
      "Epoch 12130, train loss on all blocks 2.1862410964443235\n",
      "Epoch 12140, train loss on all blocks 3.1769588664609434\n",
      "Epoch 12150, train loss on all blocks 4.152948861590855\n",
      "Epoch 12160, train loss on all blocks 2.532787887633557\n",
      "Epoch 12170, train loss on all blocks 2.3072315346666556\n",
      "Epoch 12180, train loss on all blocks 2.2680622968295046\n",
      "Epoch 12190, train loss on all blocks 2.2136912621799274\n",
      "Epoch 12200, train loss on all blocks 2.2105133561753294\n",
      "Epoch 12210, train loss on all blocks 2.1815300598576783\n",
      "Epoch 12220, train loss on all blocks 2.26210399935837\n",
      "Epoch 12230, train loss on all blocks 2.6713010455643627\n",
      "Epoch 12240, train loss on all blocks 2.337537992194785\n",
      "Epoch 12250, train loss on all blocks 2.7905496170704778\n",
      "Epoch 12260, train loss on all blocks 2.4158932738850813\n",
      "Epoch 12270, train loss on all blocks 2.294685577566953\n",
      "Epoch 12280, train loss on all blocks 2.325493690421607\n",
      "Epoch 12290, train loss on all blocks 2.234348428178766\n",
      "Epoch 12300, train loss on all blocks 2.198393646534436\n",
      "Epoch 12310, train loss on all blocks 2.184963244325753\n",
      "Epoch 12320, train loss on all blocks 2.6276864255232293\n",
      "Epoch 12330, train loss on all blocks 2.5828470078616945\n",
      "Epoch 12340, train loss on all blocks 2.455386859064352\n",
      "Epoch 12350, train loss on all blocks 2.3474658819879206\n",
      "Epoch 12360, train loss on all blocks 2.440981431931276\n",
      "Epoch 12370, train loss on all blocks 2.7335283890460325\n",
      "Epoch 12380, train loss on all blocks 2.4067241081875164\n",
      "Epoch 12390, train loss on all blocks 2.254873237992035\n",
      "Epoch 12400, train loss on all blocks 2.2179342689507493\n",
      "Epoch 12410, train loss on all blocks 2.1857933506941682\n",
      "Epoch 12420, train loss on all blocks 2.163661144731953\n",
      "Epoch 12430, train loss on all blocks 2.1695892952676696\n",
      "Epoch 12440, train loss on all blocks 2.5969488392285576\n",
      "Epoch 12450, train loss on all blocks 2.4447221111842725\n",
      "Epoch 12460, train loss on all blocks 5.449276293299144\n",
      "Epoch 12470, train loss on all blocks 2.7846042180855752\n",
      "Epoch 12480, train loss on all blocks 2.459947379664087\n",
      "Epoch 12490, train loss on all blocks 2.3346006203248786\n",
      "Epoch 12500, train loss on all blocks 2.2627852234510333\n",
      "Epoch 12510, train loss on all blocks 2.247745847146497\n",
      "Epoch 12520, train loss on all blocks 2.2168717203663846\n",
      "Epoch 12530, train loss on all blocks 2.3050709489974492\n",
      "Epoch 12540, train loss on all blocks 2.335672525189241\n",
      "Epoch 12550, train loss on all blocks 2.2574983735178322\n",
      "Epoch 12560, train loss on all blocks 2.252570280591101\n",
      "Epoch 12570, train loss on all blocks 2.2285847535199017\n",
      "Epoch 12580, train loss on all blocks 2.3529874518231315\n",
      "Epoch 12590, train loss on all blocks 2.4244533026225774\n",
      "Epoch 12600, train loss on all blocks 2.3703777666416195\n",
      "Epoch 12610, train loss on all blocks 2.28219578469504\n",
      "Epoch 12620, train loss on all blocks 2.21499664053277\n",
      "Epoch 12630, train loss on all blocks 2.329028205814834\n",
      "Epoch 12640, train loss on all blocks 2.2739158179700594\n",
      "Epoch 12650, train loss on all blocks 2.829054143170195\n",
      "Epoch 12660, train loss on all blocks 2.4809026665990217\n",
      "Epoch 12670, train loss on all blocks 2.286555061545002\n",
      "Epoch 12680, train loss on all blocks 2.6213082514884363\n",
      "Epoch 12690, train loss on all blocks 2.5615970965788106\n",
      "Epoch 12700, train loss on all blocks 2.455583674732113\n",
      "Epoch 12710, train loss on all blocks 2.370022281251819\n",
      "Epoch 12720, train loss on all blocks 2.261233539518434\n",
      "Epoch 12730, train loss on all blocks 2.2040637816250372\n",
      "Epoch 12740, train loss on all blocks 2.183878746499558\n",
      "Epoch 12750, train loss on all blocks 2.157310858404563\n",
      "Epoch 12760, train loss on all blocks 3.4604473018212305\n",
      "Epoch 12770, train loss on all blocks 3.5400952003000814\n",
      "Epoch 12780, train loss on all blocks 2.5762366507244367\n",
      "Epoch 12790, train loss on all blocks 2.5395760093365887\n",
      "Epoch 12800, train loss on all blocks 2.3767745314718924\n",
      "Epoch 12810, train loss on all blocks 2.3520991110755594\n",
      "Epoch 12820, train loss on all blocks 2.2389459845345465\n",
      "Epoch 12830, train loss on all blocks 2.1922884861666825\n",
      "Epoch 12840, train loss on all blocks 2.1831788331614055\n",
      "Epoch 12850, train loss on all blocks 2.383824132395275\n",
      "Epoch 12860, train loss on all blocks 2.3197785212059943\n",
      "Epoch 12870, train loss on all blocks 2.3701297841822773\n",
      "Epoch 12880, train loss on all blocks 4.5208873745206954\n",
      "Epoch 12890, train loss on all blocks 2.6815330446122188\n",
      "Epoch 12900, train loss on all blocks 2.457567929322646\n",
      "Epoch 12910, train loss on all blocks 2.310209702936379\n",
      "Epoch 12920, train loss on all blocks 2.2501409668389716\n",
      "Epoch 12930, train loss on all blocks 2.204366196944607\n",
      "Epoch 12940, train loss on all blocks 2.219055575821349\n",
      "Epoch 12950, train loss on all blocks 2.1557711330402984\n",
      "Epoch 12960, train loss on all blocks 2.1523592344198534\n",
      "Epoch 12970, train loss on all blocks 2.148344467072911\n",
      "Epoch 12980, train loss on all blocks 2.550630553300726\n",
      "Epoch 12990, train loss on all blocks 2.1923955504482033\n",
      "Epoch 13000, train loss on all blocks 2.171776794442088\n",
      "Epoch 13010, train loss on all blocks 2.1820173856552634\n",
      "Epoch 13020, train loss on all blocks 2.5302343384449286\n",
      "Epoch 13030, train loss on all blocks 2.309876299368478\n",
      "Epoch 13040, train loss on all blocks 2.241936497685574\n",
      "Epoch 13050, train loss on all blocks 2.2281425340693417\n",
      "Epoch 13060, train loss on all blocks 2.2093648328127466\n",
      "Epoch 13070, train loss on all blocks 2.61854156731195\n",
      "Epoch 13080, train loss on all blocks 5.065717010120593\n",
      "Epoch 13090, train loss on all blocks 3.003243960180435\n",
      "Epoch 13100, train loss on all blocks 5.484818415673086\n",
      "Epoch 13110, train loss on all blocks 2.3545838713589973\n",
      "Epoch 13120, train loss on all blocks 3.1002476237515397\n",
      "Epoch 13130, train loss on all blocks 2.4206055161953737\n",
      "Epoch 13140, train loss on all blocks 2.3253390446738997\n",
      "Epoch 13150, train loss on all blocks 2.2486289841007014\n",
      "Epoch 13160, train loss on all blocks 2.1778966250534157\n",
      "Epoch 13170, train loss on all blocks 2.150311455115178\n",
      "Epoch 13180, train loss on all blocks 2.2518398407870803\n",
      "Epoch 13190, train loss on all blocks 2.828988563910153\n",
      "Epoch 13200, train loss on all blocks 2.894501821470574\n",
      "Epoch 13210, train loss on all blocks 2.6036417578711557\n",
      "Epoch 13220, train loss on all blocks 2.292129636840672\n",
      "Epoch 13230, train loss on all blocks 2.261253649476899\n",
      "Epoch 13240, train loss on all blocks 2.1944707128443905\n",
      "Epoch 13250, train loss on all blocks 2.166442377308817\n",
      "Epoch 13260, train loss on all blocks 2.1391749700229905\n",
      "Epoch 13270, train loss on all blocks 2.6008067083271236\n",
      "Epoch 13280, train loss on all blocks 2.1914721974582556\n",
      "Epoch 13290, train loss on all blocks 2.473818905738943\n",
      "Epoch 13300, train loss on all blocks 2.3633001601509918\n",
      "Epoch 13310, train loss on all blocks 3.131168571995503\n",
      "Epoch 13320, train loss on all blocks 2.6411610926624878\n",
      "Epoch 13330, train loss on all blocks 2.4534431572256414\n",
      "Epoch 13340, train loss on all blocks 2.3170378797187503\n",
      "Epoch 13350, train loss on all blocks 2.2956306408191867\n",
      "Epoch 13360, train loss on all blocks 2.240071975614527\n",
      "Epoch 13370, train loss on all blocks 2.231506905732496\n",
      "Epoch 13380, train loss on all blocks 3.60725422295419\n",
      "Epoch 13390, train loss on all blocks 2.386002176864303\n",
      "Epoch 13400, train loss on all blocks 2.3079785064185376\n",
      "Epoch 13410, train loss on all blocks 2.2185898431746502\n",
      "Epoch 13420, train loss on all blocks 2.1753400112716132\n",
      "Epoch 13430, train loss on all blocks 2.1509895507137204\n",
      "Epoch 13440, train loss on all blocks 2.268128186186463\n",
      "Epoch 13450, train loss on all blocks 2.177152332714636\n",
      "Epoch 13460, train loss on all blocks 2.1393459275565014\n",
      "Epoch 13470, train loss on all blocks 2.4656002483512127\n",
      "Epoch 13480, train loss on all blocks 3.0376790196380865\n",
      "Epoch 13490, train loss on all blocks 2.9443215919231216\n",
      "Epoch 13500, train loss on all blocks 2.5021766428905696\n",
      "Epoch 13510, train loss on all blocks 2.39839348435513\n",
      "Epoch 13520, train loss on all blocks 2.2938299732952823\n",
      "Epoch 13530, train loss on all blocks 2.430231336518533\n",
      "Epoch 13540, train loss on all blocks 2.2311505871727038\n",
      "Epoch 13550, train loss on all blocks 2.196230844756104\n",
      "Epoch 13560, train loss on all blocks 2.1637130040390096\n",
      "Epoch 13570, train loss on all blocks 2.1469842813726006\n",
      "Epoch 13580, train loss on all blocks 2.141254462985664\n",
      "Epoch 13590, train loss on all blocks 2.1269819429490475\n",
      "Epoch 13600, train loss on all blocks 2.1336625836020793\n",
      "Epoch 13610, train loss on all blocks 2.3101820150943446\n",
      "Epoch 13620, train loss on all blocks 4.420420710221002\n",
      "Epoch 13630, train loss on all blocks 2.8775872633766997\n",
      "Epoch 13640, train loss on all blocks 2.5805662811997676\n",
      "Epoch 13650, train loss on all blocks 2.500174864847595\n",
      "Epoch 13660, train loss on all blocks 2.348546544805198\n",
      "Epoch 13670, train loss on all blocks 2.2750589909121928\n",
      "Epoch 13680, train loss on all blocks 2.2196541308911053\n",
      "Epoch 13690, train loss on all blocks 2.502085496906865\n",
      "Epoch 13700, train loss on all blocks 2.2338244324728245\n",
      "Epoch 13710, train loss on all blocks 2.202636930514535\n",
      "Epoch 13720, train loss on all blocks 2.15470643543013\n",
      "Epoch 13730, train loss on all blocks 2.1289829305349297\n",
      "Epoch 13740, train loss on all blocks 2.1453924137863805\n",
      "Epoch 13750, train loss on all blocks 2.457739128886387\n",
      "Epoch 13760, train loss on all blocks 2.413941847691002\n",
      "Epoch 13770, train loss on all blocks 2.800681007921896\n",
      "Epoch 13780, train loss on all blocks 2.2948871491251133\n",
      "Epoch 13790, train loss on all blocks 2.2892703539363506\n",
      "Epoch 13800, train loss on all blocks 2.2229183461162974\n",
      "Epoch 13810, train loss on all blocks 2.1802338912537125\n",
      "Epoch 13820, train loss on all blocks 2.1523498074908325\n",
      "Epoch 13830, train loss on all blocks 2.138514955689572\n",
      "Epoch 13840, train loss on all blocks 2.2935978436654487\n",
      "Epoch 13850, train loss on all blocks 2.6293426795181007\n",
      "Epoch 13860, train loss on all blocks 2.2896329168794454\n",
      "Epoch 13870, train loss on all blocks 2.207098498858279\n",
      "Epoch 13880, train loss on all blocks 2.1481025078356684\n",
      "Epoch 13890, train loss on all blocks 2.2363350166955014\n",
      "Epoch 13900, train loss on all blocks 2.152198377111568\n",
      "Epoch 13910, train loss on all blocks 3.4465538647844856\n",
      "Epoch 13920, train loss on all blocks 2.3434102606316105\n",
      "Epoch 13930, train loss on all blocks 2.6125377219956434\n",
      "Epoch 13940, train loss on all blocks 2.2841869220586775\n",
      "Epoch 13950, train loss on all blocks 2.90992375943018\n",
      "Epoch 13960, train loss on all blocks 2.750349576093728\n",
      "Epoch 13970, train loss on all blocks 2.5180272492254137\n",
      "Epoch 13980, train loss on all blocks 2.3492699445637095\n",
      "Epoch 13990, train loss on all blocks 2.2860039904015164\n",
      "Epoch 14000, train loss on all blocks 2.233442553456375\n",
      "Epoch 14010, train loss on all blocks 2.192681728104102\n",
      "Epoch 14020, train loss on all blocks 2.1631918660393175\n",
      "Epoch 14030, train loss on all blocks 2.255844479961465\n",
      "Epoch 14040, train loss on all blocks 2.3248968552620717\n",
      "Epoch 14050, train loss on all blocks 2.2050042168074526\n",
      "Epoch 14060, train loss on all blocks 2.2355045712671435\n",
      "Epoch 14070, train loss on all blocks 4.730025199762254\n",
      "Epoch 14080, train loss on all blocks 2.6866460192016564\n",
      "Epoch 14090, train loss on all blocks 2.3479872876036985\n",
      "Epoch 14100, train loss on all blocks 2.2562693641846665\n",
      "Epoch 14110, train loss on all blocks 2.265978351669374\n",
      "Epoch 14120, train loss on all blocks 2.2567090184227245\n",
      "Epoch 14130, train loss on all blocks 2.16327180895201\n",
      "Epoch 14140, train loss on all blocks 2.1837520532144543\n",
      "Epoch 14150, train loss on all blocks 2.1207256217024115\n",
      "Epoch 14160, train loss on all blocks 2.4579254452186987\n",
      "Epoch 14170, train loss on all blocks 2.3301429555710307\n",
      "Epoch 14180, train loss on all blocks 2.4545007063381923\n",
      "Epoch 14190, train loss on all blocks 2.3113158081466123\n",
      "Epoch 14200, train loss on all blocks 2.2161773313968736\n",
      "Epoch 14210, train loss on all blocks 2.8787776001288563\n",
      "Epoch 14220, train loss on all blocks 2.3532301470633663\n",
      "Epoch 14230, train loss on all blocks 2.3172588894215322\n",
      "Epoch 14240, train loss on all blocks 2.290585284048521\n",
      "Epoch 14250, train loss on all blocks 2.4794360412829537\n",
      "Epoch 14260, train loss on all blocks 2.222459699612612\n",
      "Epoch 14270, train loss on all blocks 2.1806606055362443\n",
      "Epoch 14280, train loss on all blocks 3.83181961243122\n",
      "Epoch 14290, train loss on all blocks 2.3781101058304044\n",
      "Epoch 14300, train loss on all blocks 2.4004043585962345\n",
      "Epoch 14310, train loss on all blocks 2.251536919960622\n",
      "Epoch 14320, train loss on all blocks 2.191345668882669\n",
      "Epoch 14330, train loss on all blocks 2.158726136894511\n",
      "Epoch 14340, train loss on all blocks 2.252030856366053\n",
      "Epoch 14350, train loss on all blocks 2.143342816585508\n",
      "Epoch 14360, train loss on all blocks 2.1073054972318497\n",
      "Epoch 14370, train loss on all blocks 3.9880257984793213\n",
      "Epoch 14380, train loss on all blocks 2.5403858902193033\n",
      "Epoch 14390, train loss on all blocks 2.6122726497175415\n",
      "Epoch 14400, train loss on all blocks 2.326268675512906\n",
      "Epoch 14410, train loss on all blocks 2.2523309328943526\n",
      "Epoch 14420, train loss on all blocks 2.210314459560867\n",
      "Epoch 14430, train loss on all blocks 2.291352889101824\n",
      "Epoch 14440, train loss on all blocks 2.1749923209616018\n",
      "Epoch 14450, train loss on all blocks 2.134125968108326\n",
      "Epoch 14460, train loss on all blocks 2.117106748037483\n",
      "Epoch 14470, train loss on all blocks 2.1092692831045676\n",
      "Epoch 14480, train loss on all blocks 2.60136982366524\n",
      "Epoch 14490, train loss on all blocks 2.2572312754941377\n",
      "Epoch 14500, train loss on all blocks 2.184874968608008\n",
      "Epoch 14510, train loss on all blocks 2.461584678565476\n",
      "Epoch 14520, train loss on all blocks 2.4878321268694226\n",
      "Epoch 14530, train loss on all blocks 2.477016139707878\n",
      "Epoch 14540, train loss on all blocks 2.258613120059759\n",
      "Epoch 14550, train loss on all blocks 2.2383748939922388\n",
      "Epoch 14560, train loss on all blocks 2.18843072757477\n",
      "Epoch 14570, train loss on all blocks 2.534770460243789\n",
      "Epoch 14580, train loss on all blocks 2.5602056642985946\n",
      "Epoch 14590, train loss on all blocks 2.2894732025643094\n",
      "Epoch 14600, train loss on all blocks 2.439781571389945\n",
      "Epoch 14610, train loss on all blocks 2.2310070361747334\n",
      "Epoch 14620, train loss on all blocks 2.16792162947051\n",
      "Epoch 14630, train loss on all blocks 2.137812132866392\n",
      "Epoch 14640, train loss on all blocks 2.1321674893573297\n",
      "Epoch 14650, train loss on all blocks 2.194491175035385\n",
      "Epoch 14660, train loss on all blocks 4.206980468627893\n",
      "Epoch 14670, train loss on all blocks 2.57420469907635\n",
      "Epoch 14680, train loss on all blocks 2.2890057255675242\n",
      "Epoch 14690, train loss on all blocks 2.2210308219909023\n",
      "Epoch 14700, train loss on all blocks 2.244842011211923\n",
      "Epoch 14710, train loss on all blocks 2.816562977234512\n",
      "Epoch 14720, train loss on all blocks 2.3315763824577784\n",
      "Epoch 14730, train loss on all blocks 2.25963226597479\n",
      "Epoch 14740, train loss on all blocks 2.2214386429813686\n",
      "Epoch 14750, train loss on all blocks 2.212193923767999\n",
      "Epoch 14760, train loss on all blocks 2.165278038042203\n",
      "Epoch 14770, train loss on all blocks 2.127496284606247\n",
      "Epoch 14780, train loss on all blocks 2.1025385710683087\n",
      "Epoch 14790, train loss on all blocks 2.422574618405145\n",
      "Epoch 14800, train loss on all blocks 2.121594678545632\n",
      "Epoch 14810, train loss on all blocks 2.119373440410768\n",
      "Epoch 14820, train loss on all blocks 2.1886804733376444\n",
      "Epoch 14830, train loss on all blocks 3.9635514418941615\n",
      "Epoch 14840, train loss on all blocks 2.7241082423819405\n",
      "Epoch 14850, train loss on all blocks 2.455217767871705\n",
      "Epoch 14860, train loss on all blocks 2.347789022739547\n",
      "Epoch 14870, train loss on all blocks 2.340258695892185\n",
      "Epoch 14880, train loss on all blocks 2.2567374037584473\n",
      "Epoch 14890, train loss on all blocks 2.199286489209391\n",
      "Epoch 14900, train loss on all blocks 2.148456674129239\n",
      "Epoch 14910, train loss on all blocks 2.127718699031969\n",
      "Epoch 14920, train loss on all blocks 2.1007024564019123\n",
      "Epoch 14930, train loss on all blocks 2.0907037589928157\n",
      "Epoch 14940, train loss on all blocks 2.080082010941723\n",
      "Epoch 14950, train loss on all blocks 2.2505546885686183\n",
      "Epoch 14960, train loss on all blocks 2.515592355803771\n",
      "Epoch 14970, train loss on all blocks 3.0645423570273307\n",
      "Epoch 14980, train loss on all blocks 2.5395025514511884\n",
      "Epoch 14990, train loss on all blocks 2.3005414229016186\n",
      "Epoch 15000, train loss on all blocks 2.2545358302133423\n",
      "Epoch 15010, train loss on all blocks 2.1943838092447328\n",
      "Epoch 15020, train loss on all blocks 6.070986883012116\n",
      "Epoch 15030, train loss on all blocks 4.242701704174835\n",
      "Epoch 15040, train loss on all blocks 2.322735804702405\n",
      "Epoch 15050, train loss on all blocks 2.2332762762344265\n",
      "Epoch 15060, train loss on all blocks 3.0104314941406605\n",
      "Epoch 15070, train loss on all blocks 2.3116437749111274\n",
      "Epoch 15080, train loss on all blocks 2.2589950248601873\n",
      "Epoch 15090, train loss on all blocks 2.2037733671696444\n",
      "Epoch 15100, train loss on all blocks 2.1576076673576194\n",
      "Epoch 15110, train loss on all blocks 2.1277051935116207\n",
      "Epoch 15120, train loss on all blocks 3.402027802177817\n",
      "Epoch 15130, train loss on all blocks 2.5293325750679174\n",
      "Epoch 15140, train loss on all blocks 2.3492478595405224\n",
      "Epoch 15150, train loss on all blocks 2.223750575798608\n",
      "Epoch 15160, train loss on all blocks 2.1682426200908402\n",
      "Epoch 15170, train loss on all blocks 2.182473888657957\n",
      "Epoch 15180, train loss on all blocks 2.11927981987708\n",
      "Epoch 15190, train loss on all blocks 2.493743186811064\n",
      "Epoch 15200, train loss on all blocks 2.3978251254289966\n",
      "Epoch 15210, train loss on all blocks 2.2354768910586515\n",
      "Epoch 15220, train loss on all blocks 2.310920681507323\n",
      "Epoch 15230, train loss on all blocks 2.2110463981283504\n",
      "Epoch 15240, train loss on all blocks 2.154293883549337\n",
      "Epoch 15250, train loss on all blocks 2.981763600928061\n",
      "Epoch 15260, train loss on all blocks 2.4210190375397715\n",
      "Epoch 15270, train loss on all blocks 2.2072943119430253\n",
      "Epoch 15280, train loss on all blocks 2.2579944436136916\n",
      "Epoch 15290, train loss on all blocks 2.1462090558995808\n",
      "Epoch 15300, train loss on all blocks 2.4097867232016235\n",
      "Epoch 15310, train loss on all blocks 2.18427647933175\n",
      "Epoch 15320, train loss on all blocks 2.1187598696736716\n",
      "Epoch 15330, train loss on all blocks 3.953303043608905\n",
      "Epoch 15340, train loss on all blocks 2.537819951715564\n",
      "Epoch 15350, train loss on all blocks 2.3194670892542444\n",
      "Epoch 15360, train loss on all blocks 2.2190005320083603\n",
      "Epoch 15370, train loss on all blocks 2.2103234257664113\n",
      "Epoch 15380, train loss on all blocks 2.228693728115765\n",
      "Epoch 15390, train loss on all blocks 2.1362100500235415\n",
      "Epoch 15400, train loss on all blocks 5.861281921237682\n",
      "Epoch 15410, train loss on all blocks 2.5005243983535754\n",
      "Epoch 15420, train loss on all blocks 2.375928597745702\n",
      "Epoch 15430, train loss on all blocks 2.203737801778707\n",
      "Epoch 15440, train loss on all blocks 2.188617938877422\n",
      "Epoch 15450, train loss on all blocks 2.149696077272704\n",
      "Epoch 15460, train loss on all blocks 4.327502171194798\n",
      "Epoch 15470, train loss on all blocks 2.4972664774380924\n",
      "Epoch 15480, train loss on all blocks 2.2905763646060167\n",
      "Epoch 15490, train loss on all blocks 2.2160614491781647\n",
      "Epoch 15500, train loss on all blocks 2.145243834607885\n",
      "Epoch 15510, train loss on all blocks 2.1349829756358165\n",
      "Epoch 15520, train loss on all blocks 2.1174448800810883\n",
      "Epoch 15530, train loss on all blocks 2.076384940934177\n",
      "Epoch 15540, train loss on all blocks 3.7795659927396175\n",
      "Epoch 15550, train loss on all blocks 2.4706668744469225\n",
      "Epoch 15560, train loss on all blocks 2.508746385776251\n",
      "Epoch 15570, train loss on all blocks 2.2759863673476124\n",
      "Epoch 15580, train loss on all blocks 2.200853013918207\n",
      "Epoch 15590, train loss on all blocks 3.6727717979025614\n",
      "Epoch 15600, train loss on all blocks 2.863395564867127\n",
      "Epoch 15610, train loss on all blocks 2.393395119859746\n",
      "Epoch 15620, train loss on all blocks 2.518277739680361\n",
      "Epoch 15630, train loss on all blocks 2.2580580406951443\n",
      "Epoch 15640, train loss on all blocks 2.2265489818251902\n",
      "Epoch 15650, train loss on all blocks 2.1795859136864086\n",
      "Epoch 15660, train loss on all blocks 2.1567472593569863\n",
      "Epoch 15670, train loss on all blocks 2.121422609342008\n",
      "Epoch 15680, train loss on all blocks 2.1980231702213437\n",
      "Epoch 15690, train loss on all blocks 2.2173372026335545\n",
      "Epoch 15700, train loss on all blocks 2.5689289723384623\n",
      "Epoch 15710, train loss on all blocks 2.2418355309881965\n",
      "Epoch 15720, train loss on all blocks 2.163062733987503\n",
      "Epoch 15730, train loss on all blocks 2.1355599474595\n",
      "Epoch 15740, train loss on all blocks 2.1451550269161204\n",
      "Epoch 15750, train loss on all blocks 2.3994427458032193\n",
      "Epoch 15760, train loss on all blocks 2.344487112142092\n",
      "Epoch 15770, train loss on all blocks 2.2077637624829363\n",
      "Epoch 15780, train loss on all blocks 2.2326092447499852\n",
      "Epoch 15790, train loss on all blocks 2.139208961489021\n",
      "Epoch 15800, train loss on all blocks 2.570246089402308\n",
      "Epoch 15810, train loss on all blocks 2.136198605223237\n",
      "Epoch 15820, train loss on all blocks 2.099155757586003\n",
      "Epoch 15830, train loss on all blocks 2.071488761314053\n",
      "Epoch 15840, train loss on all blocks 5.651449790722326\n",
      "Epoch 15850, train loss on all blocks 2.3787549268437216\n",
      "Epoch 15860, train loss on all blocks 2.283951207879042\n",
      "Epoch 15870, train loss on all blocks 2.21490459289219\n",
      "Epoch 15880, train loss on all blocks 2.2000698893478887\n",
      "Epoch 15890, train loss on all blocks 2.4679799250393866\n",
      "Epoch 15900, train loss on all blocks 2.308654453650118\n",
      "Epoch 15910, train loss on all blocks 2.2889278191272555\n",
      "Epoch 15920, train loss on all blocks 2.2319409143057696\n",
      "Epoch 15930, train loss on all blocks 2.1715344599917623\n",
      "Epoch 15940, train loss on all blocks 2.150508539263452\n",
      "Epoch 15950, train loss on all blocks 2.135044264532685\n",
      "Epoch 15960, train loss on all blocks 2.3847761350744507\n",
      "Epoch 15970, train loss on all blocks 2.093777692176248\n",
      "Epoch 15980, train loss on all blocks 2.124406615937299\n",
      "Epoch 15990, train loss on all blocks 2.0791683550068982\n",
      "Epoch 16000, train loss on all blocks 2.0944869817545824\n",
      "Epoch 16010, train loss on all blocks 2.0824559674683494\n",
      "Epoch 16020, train loss on all blocks 2.130169477827857\n",
      "Epoch 16030, train loss on all blocks 2.266627006815339\n",
      "Epoch 16040, train loss on all blocks 2.2730725423376095\n",
      "Epoch 16050, train loss on all blocks 2.2740174987088935\n",
      "Epoch 16060, train loss on all blocks 2.1628462562060657\n",
      "Epoch 16070, train loss on all blocks 2.120990200141322\n",
      "Epoch 16080, train loss on all blocks 2.1085018095005803\n",
      "Epoch 16090, train loss on all blocks 2.4770026333466495\n",
      "Epoch 16100, train loss on all blocks 2.146688626088898\n",
      "Epoch 16110, train loss on all blocks 2.86349565374395\n",
      "Epoch 16120, train loss on all blocks 2.1940698311350832\n",
      "Epoch 16130, train loss on all blocks 2.184127445405303\n",
      "Epoch 16140, train loss on all blocks 2.1471027163446\n",
      "Epoch 16150, train loss on all blocks 2.1268005442407656\n",
      "Epoch 16160, train loss on all blocks 2.1874448476419563\n",
      "Epoch 16170, train loss on all blocks 3.1018821770417766\n",
      "Epoch 16180, train loss on all blocks 2.5267545550019053\n",
      "Epoch 16190, train loss on all blocks 2.3026103985659017\n",
      "Epoch 16200, train loss on all blocks 2.2273423669887866\n",
      "Epoch 16210, train loss on all blocks 2.1658307459335866\n",
      "Epoch 16220, train loss on all blocks 2.1281109176626565\n",
      "Epoch 16230, train loss on all blocks 2.5262484910050302\n",
      "Epoch 16240, train loss on all blocks 2.158697486374591\n",
      "Epoch 16250, train loss on all blocks 3.660080320242499\n",
      "Epoch 16260, train loss on all blocks 2.3422583276216695\n",
      "Epoch 16270, train loss on all blocks 2.2893571176721013\n",
      "Epoch 16280, train loss on all blocks 2.169664164090242\n",
      "Epoch 16290, train loss on all blocks 2.1892322144819234\n",
      "Epoch 16300, train loss on all blocks 2.1428834884632724\n",
      "Epoch 16310, train loss on all blocks 2.140692204626578\n",
      "Epoch 16320, train loss on all blocks 3.635664750555664\n",
      "Epoch 16330, train loss on all blocks 2.4492067653224234\n",
      "Epoch 16340, train loss on all blocks 2.317469028851084\n",
      "Epoch 16350, train loss on all blocks 2.248555298112813\n",
      "Epoch 16360, train loss on all blocks 2.1774658000773695\n",
      "Epoch 16370, train loss on all blocks 2.1188816964226285\n",
      "Epoch 16380, train loss on all blocks 2.1041770552130226\n",
      "Epoch 16390, train loss on all blocks 3.2071982664471355\n",
      "Epoch 16400, train loss on all blocks 2.414101346484431\n",
      "Epoch 16410, train loss on all blocks 2.216365820209179\n",
      "Epoch 16420, train loss on all blocks 2.138618502655863\n",
      "Epoch 16430, train loss on all blocks 2.111253457083111\n",
      "Epoch 16440, train loss on all blocks 2.1056718738312226\n",
      "Epoch 16450, train loss on all blocks 2.1569464129859863\n",
      "Epoch 16460, train loss on all blocks 2.6539935900200904\n",
      "Epoch 16470, train loss on all blocks 2.2485948593349834\n",
      "Epoch 16480, train loss on all blocks 2.2134613703590222\n",
      "Epoch 16490, train loss on all blocks 2.1235520206126486\n",
      "Epoch 16500, train loss on all blocks 2.177396079431591\n",
      "Epoch 16510, train loss on all blocks 2.1868420578605514\n",
      "Epoch 16520, train loss on all blocks 2.107469041146716\n",
      "Epoch 16530, train loss on all blocks 2.750527858574835\n",
      "Epoch 16540, train loss on all blocks 2.1783816379455203\n",
      "Epoch 16550, train loss on all blocks 2.2300709665742104\n",
      "Epoch 16560, train loss on all blocks 2.187779256294472\n",
      "Epoch 16570, train loss on all blocks 2.1150692477629294\n",
      "Epoch 16580, train loss on all blocks 2.0796158900953565\n",
      "Epoch 16590, train loss on all blocks 4.577304733810361\n",
      "Epoch 16600, train loss on all blocks 2.468642150786822\n",
      "Epoch 16610, train loss on all blocks 2.2200866058990574\n",
      "Epoch 16620, train loss on all blocks 2.167201876681036\n",
      "Epoch 16630, train loss on all blocks 2.1843624645574686\n",
      "Epoch 16640, train loss on all blocks 2.107295556634881\n",
      "Epoch 16650, train loss on all blocks 2.1957762435307795\n",
      "Epoch 16660, train loss on all blocks 2.1675282784763557\n",
      "Epoch 16670, train loss on all blocks 2.3097098807035694\n",
      "Epoch 16680, train loss on all blocks 2.1989962271011407\n",
      "Epoch 16690, train loss on all blocks 2.1608796935269114\n",
      "Epoch 16700, train loss on all blocks 2.1303882776289376\n",
      "Epoch 16710, train loss on all blocks 2.092183495613299\n",
      "Epoch 16720, train loss on all blocks 5.009213116506463\n",
      "Epoch 16730, train loss on all blocks 2.421135510112034\n",
      "Epoch 16740, train loss on all blocks 2.2577625149429705\n",
      "Epoch 16750, train loss on all blocks 2.17099803156125\n",
      "Epoch 16760, train loss on all blocks 2.2151828379022405\n",
      "Epoch 16770, train loss on all blocks 2.182992350813203\n",
      "Epoch 16780, train loss on all blocks 2.0965944350016876\n",
      "Epoch 16790, train loss on all blocks 3.874410540294823\n",
      "Epoch 16800, train loss on all blocks 2.271407435166452\n",
      "Epoch 16810, train loss on all blocks 2.170356998288331\n",
      "Epoch 16820, train loss on all blocks 2.382410140018438\n",
      "Epoch 16830, train loss on all blocks 2.1194448260229555\n",
      "Epoch 16840, train loss on all blocks 2.104991866078235\n",
      "Epoch 16850, train loss on all blocks 2.075353225069667\n",
      "Epoch 16860, train loss on all blocks 3.9568005679817606\n",
      "Epoch 16870, train loss on all blocks 2.3825089435227227\n",
      "Epoch 16880, train loss on all blocks 2.3160932581567693\n",
      "Epoch 16890, train loss on all blocks 2.163493426434694\n",
      "Epoch 16900, train loss on all blocks 2.099495505482236\n",
      "Epoch 16910, train loss on all blocks 2.0760613551590787\n",
      "Epoch 16920, train loss on all blocks 2.06586610665617\n",
      "Epoch 16930, train loss on all blocks 3.8969128732642666\n",
      "Epoch 16940, train loss on all blocks 2.5318740471548287\n",
      "Epoch 16950, train loss on all blocks 2.2844163283670578\n",
      "Epoch 16960, train loss on all blocks 2.2322153676120124\n",
      "Epoch 16970, train loss on all blocks 2.150361740207562\n",
      "Epoch 16980, train loss on all blocks 2.1529376645120175\n",
      "Epoch 16990, train loss on all blocks 2.1107477626432174\n",
      "Epoch 17000, train loss on all blocks 5.28581946205382\n",
      "Epoch 17010, train loss on all blocks 2.621436928738161\n",
      "Epoch 17020, train loss on all blocks 2.340770783454577\n",
      "Epoch 17030, train loss on all blocks 2.4424142332620447\n",
      "Epoch 17040, train loss on all blocks 2.7002436928319464\n",
      "Epoch 17050, train loss on all blocks 2.401794429216703\n",
      "Epoch 17060, train loss on all blocks 2.271715652840267\n",
      "Epoch 17070, train loss on all blocks 2.199458338460876\n",
      "Epoch 17080, train loss on all blocks 2.138636078693101\n",
      "Epoch 17090, train loss on all blocks 2.137947477325862\n",
      "Epoch 17100, train loss on all blocks 2.1601782443145243\n",
      "Epoch 17110, train loss on all blocks 2.0768245158997853\n",
      "Epoch 17120, train loss on all blocks 2.4108634667758717\n",
      "Epoch 17130, train loss on all blocks 2.406420253204023\n",
      "Epoch 17140, train loss on all blocks 2.2563727854715943\n",
      "Epoch 17150, train loss on all blocks 2.1786157994575204\n",
      "Epoch 17160, train loss on all blocks 2.1396097212953107\n",
      "Epoch 17170, train loss on all blocks 2.101545124492138\n",
      "Epoch 17180, train loss on all blocks 2.087111644396348\n",
      "Epoch 17190, train loss on all blocks 2.0941529537310224\n",
      "Epoch 17200, train loss on all blocks 2.142563116964367\n",
      "Epoch 17210, train loss on all blocks 2.1908920090140285\n",
      "Epoch 17220, train loss on all blocks 2.1717818560763513\n",
      "Epoch 17230, train loss on all blocks 2.144512940654817\n",
      "Epoch 17240, train loss on all blocks 2.216730891468745\n",
      "Epoch 17250, train loss on all blocks 2.1081897208037317\n",
      "Epoch 17260, train loss on all blocks 2.065255746793575\n",
      "Epoch 17270, train loss on all blocks 2.5660657098380586\n",
      "Epoch 17280, train loss on all blocks 2.416259319744423\n",
      "Epoch 17290, train loss on all blocks 2.544515490899715\n",
      "Epoch 17300, train loss on all blocks 2.2235025522228886\n",
      "Epoch 17310, train loss on all blocks 2.1469695459729254\n",
      "Epoch 17320, train loss on all blocks 2.087066332047848\n",
      "Epoch 17330, train loss on all blocks 2.0666419896044426\n",
      "Epoch 17340, train loss on all blocks 2.0397592283638577\n",
      "Epoch 17350, train loss on all blocks 2.022827248802622\n",
      "Epoch 17360, train loss on all blocks 4.157941908176577\n",
      "Epoch 17370, train loss on all blocks 2.480184568029715\n",
      "Epoch 17380, train loss on all blocks 2.657543790488626\n",
      "Epoch 17390, train loss on all blocks 2.2372262681484045\n",
      "Epoch 17400, train loss on all blocks 2.169050583971236\n",
      "Epoch 17410, train loss on all blocks 2.536622482821186\n",
      "Epoch 17420, train loss on all blocks 2.409676327846263\n",
      "Epoch 17430, train loss on all blocks 2.253695154543585\n",
      "Epoch 17440, train loss on all blocks 2.197611783035631\n",
      "Epoch 17450, train loss on all blocks 2.146350132154301\n",
      "Epoch 17460, train loss on all blocks 2.120443403977922\n",
      "Epoch 17470, train loss on all blocks 2.15232084271761\n",
      "Epoch 17480, train loss on all blocks 2.0886198929294695\n",
      "Epoch 17490, train loss on all blocks 2.071436250721458\n",
      "Epoch 17500, train loss on all blocks 2.039962509033289\n",
      "Epoch 17510, train loss on all blocks 2.029868316485365\n",
      "Epoch 17520, train loss on all blocks 2.3694928776950084\n",
      "Epoch 17530, train loss on all blocks 2.125080291935711\n",
      "Epoch 17540, train loss on all blocks 2.266964322225516\n",
      "Epoch 17550, train loss on all blocks 2.1665029951469745\n",
      "Epoch 17560, train loss on all blocks 2.4055471836237063\n",
      "Epoch 17570, train loss on all blocks 3.428525293734891\n",
      "Epoch 17580, train loss on all blocks 2.2662738046615303\n",
      "Epoch 17590, train loss on all blocks 2.238250766357886\n",
      "Epoch 17600, train loss on all blocks 2.257693478756435\n",
      "Epoch 17610, train loss on all blocks 2.1579199963903744\n",
      "Epoch 17620, train loss on all blocks 2.2103529577002243\n",
      "Epoch 17630, train loss on all blocks 2.151250459178467\n",
      "Epoch 17640, train loss on all blocks 2.0744309670951897\n",
      "Epoch 17650, train loss on all blocks 2.0417861140378126\n",
      "Epoch 17660, train loss on all blocks 2.0497132915849914\n",
      "Epoch 17670, train loss on all blocks 2.0267063286780678\n",
      "Epoch 17680, train loss on all blocks 2.0106540691140102\n",
      "Epoch 17690, train loss on all blocks 2.2388584035550747\n",
      "Epoch 17700, train loss on all blocks 2.942352529400681\n",
      "Epoch 17710, train loss on all blocks 3.037687091193341\n",
      "Epoch 17720, train loss on all blocks 2.4612314467957126\n",
      "Epoch 17730, train loss on all blocks 2.334899497545644\n",
      "Epoch 17740, train loss on all blocks 2.302413316095938\n",
      "Epoch 17750, train loss on all blocks 2.192444841634791\n",
      "Epoch 17760, train loss on all blocks 2.139375745445327\n",
      "Epoch 17770, train loss on all blocks 2.146968431395647\n",
      "Epoch 17780, train loss on all blocks 2.1403896329318406\n",
      "Epoch 17790, train loss on all blocks 2.085669638972358\n",
      "Epoch 17800, train loss on all blocks 2.040959044127727\n",
      "Epoch 17810, train loss on all blocks 2.0160042733935946\n",
      "Epoch 17820, train loss on all blocks 2.297915079069724\n",
      "Epoch 17830, train loss on all blocks 2.459839144268032\n",
      "Epoch 17840, train loss on all blocks 2.6020074812164107\n",
      "Epoch 17850, train loss on all blocks 2.5401600096734223\n",
      "Epoch 17860, train loss on all blocks 2.270286792643142\n",
      "Epoch 17870, train loss on all blocks 2.259035960338335\n",
      "Epoch 17880, train loss on all blocks 2.2029400623964515\n",
      "Epoch 17890, train loss on all blocks 2.124305467885213\n",
      "Epoch 17900, train loss on all blocks 2.0681055079098574\n",
      "Epoch 17910, train loss on all blocks 2.04628058210971\n",
      "Epoch 17920, train loss on all blocks 2.022126557517572\n",
      "Epoch 17930, train loss on all blocks 2.052007847396477\n",
      "Epoch 17940, train loss on all blocks 2.8893800814086266\n",
      "Epoch 17950, train loss on all blocks 2.4122123571839973\n",
      "Epoch 17960, train loss on all blocks 3.8045530667506564\n",
      "Epoch 17970, train loss on all blocks 2.391519310207623\n",
      "Epoch 17980, train loss on all blocks 2.292675495596588\n",
      "Epoch 17990, train loss on all blocks 2.2477636148067512\n",
      "Epoch 18000, train loss on all blocks 2.2783480285522515\n",
      "Epoch 18010, train loss on all blocks 2.1446486608352373\n",
      "Epoch 18020, train loss on all blocks 2.0989226345500023\n",
      "Epoch 18030, train loss on all blocks 2.0607797861838573\n",
      "Epoch 18040, train loss on all blocks 2.044406273514957\n",
      "Epoch 18050, train loss on all blocks 2.06980988121201\n",
      "Epoch 18060, train loss on all blocks 2.013628332766486\n",
      "Epoch 18070, train loss on all blocks 4.503416559046718\n",
      "Epoch 18080, train loss on all blocks 2.4407439192843188\n",
      "Epoch 18090, train loss on all blocks 2.21581423155365\n",
      "Epoch 18100, train loss on all blocks 2.1591095215363283\n",
      "Epoch 18110, train loss on all blocks 2.166911357710417\n",
      "Epoch 18120, train loss on all blocks 3.106388569858958\n",
      "Epoch 18130, train loss on all blocks 2.4732760966975897\n",
      "Epoch 18140, train loss on all blocks 2.172407197724816\n",
      "Epoch 18150, train loss on all blocks 2.1866811240109505\n",
      "Epoch 18160, train loss on all blocks 2.110964834370357\n",
      "Epoch 18170, train loss on all blocks 2.0699486588112697\n",
      "Epoch 18180, train loss on all blocks 2.4644310508655916\n",
      "Epoch 18190, train loss on all blocks 2.090333451686195\n",
      "Epoch 18200, train loss on all blocks 2.041284469208395\n",
      "Epoch 18210, train loss on all blocks 2.2703090722986814\n",
      "Epoch 18220, train loss on all blocks 2.3358237773232444\n",
      "Epoch 18230, train loss on all blocks 2.1878449752638907\n",
      "Epoch 18240, train loss on all blocks 2.2473241747673685\n",
      "Epoch 18250, train loss on all blocks 2.1380331805853205\n",
      "Epoch 18260, train loss on all blocks 2.139165232136473\n",
      "Epoch 18270, train loss on all blocks 2.1474204549360474\n",
      "Epoch 18280, train loss on all blocks 4.033371272262966\n",
      "Epoch 18290, train loss on all blocks 2.2857198828441976\n",
      "Epoch 18300, train loss on all blocks 2.2871870928031885\n",
      "Epoch 18310, train loss on all blocks 2.1736432469457445\n",
      "Epoch 18320, train loss on all blocks 2.1295400236094943\n",
      "Epoch 18330, train loss on all blocks 2.199900004749801\n",
      "Epoch 18340, train loss on all blocks 2.1584845940453636\n",
      "Epoch 18350, train loss on all blocks 2.055622088756566\n",
      "Epoch 18360, train loss on all blocks 2.0320040535392074\n",
      "Epoch 18370, train loss on all blocks 2.0213678771121106\n",
      "Epoch 18380, train loss on all blocks 2.0871741429812234\n",
      "Epoch 18390, train loss on all blocks 2.019039876907226\n",
      "Epoch 18400, train loss on all blocks 3.2674862611785276\n",
      "Epoch 18410, train loss on all blocks 2.5597225347572996\n",
      "Epoch 18420, train loss on all blocks 2.1659415880899244\n",
      "Epoch 18430, train loss on all blocks 2.156401549410912\n",
      "Epoch 18440, train loss on all blocks 2.2347349378480645\n",
      "Epoch 18450, train loss on all blocks 2.8815945683789956\n",
      "Epoch 18460, train loss on all blocks 2.2069069257068237\n",
      "Epoch 18470, train loss on all blocks 2.1680030788068905\n",
      "Epoch 18480, train loss on all blocks 2.1553397345270873\n",
      "Epoch 18490, train loss on all blocks 2.172121987047332\n",
      "Epoch 18500, train loss on all blocks 2.1320217521945097\n",
      "Epoch 18510, train loss on all blocks 2.0728503410837833\n",
      "Epoch 18520, train loss on all blocks 2.0376426183132668\n",
      "Epoch 18530, train loss on all blocks 2.0557196512247176\n",
      "Epoch 18540, train loss on all blocks 2.024626683157376\n",
      "Epoch 18550, train loss on all blocks 2.0410425373006795\n",
      "Epoch 18560, train loss on all blocks 1.989605103995437\n",
      "Epoch 18570, train loss on all blocks 1.9895070400637476\n",
      "Epoch 18580, train loss on all blocks 2.046607629457228\n",
      "Epoch 18590, train loss on all blocks 4.134471350583912\n",
      "Epoch 18600, train loss on all blocks 2.3177168863799706\n",
      "Epoch 18610, train loss on all blocks 3.7356328950670137\n",
      "Epoch 18620, train loss on all blocks 2.6312504765084292\n",
      "Epoch 18630, train loss on all blocks 2.4440437274519864\n",
      "Epoch 18640, train loss on all blocks 2.330228540745936\n",
      "Epoch 18650, train loss on all blocks 2.2548564900353223\n",
      "Epoch 18660, train loss on all blocks 2.3022107405945036\n",
      "Epoch 18670, train loss on all blocks 2.1519273103965526\n",
      "Epoch 18680, train loss on all blocks 2.106838500035502\n",
      "Epoch 18690, train loss on all blocks 2.0688485241223074\n",
      "Epoch 18700, train loss on all blocks 2.3739636444764507\n",
      "Epoch 18710, train loss on all blocks 2.1011727273137626\n",
      "Epoch 18720, train loss on all blocks 2.0508520123638414\n",
      "Epoch 18730, train loss on all blocks 2.0111449518474425\n",
      "Epoch 18740, train loss on all blocks 2.0612135821752764\n",
      "Epoch 18750, train loss on all blocks 2.0152238771763287\n",
      "Epoch 18760, train loss on all blocks 2.0185644503161138\n",
      "Epoch 18770, train loss on all blocks 2.4374834642548877\n",
      "Epoch 18780, train loss on all blocks 3.06451356513408\n",
      "Epoch 18790, train loss on all blocks 2.358251496954275\n",
      "Epoch 18800, train loss on all blocks 2.2967603330528847\n",
      "Epoch 18810, train loss on all blocks 2.188438931857132\n",
      "Epoch 18820, train loss on all blocks 2.2387431866884393\n",
      "Epoch 18830, train loss on all blocks 2.133677415772518\n",
      "Epoch 18840, train loss on all blocks 2.1109834163091747\n",
      "Epoch 18850, train loss on all blocks 2.14307136567912\n",
      "Epoch 18860, train loss on all blocks 2.046297725225764\n",
      "Epoch 18870, train loss on all blocks 2.0232721124414805\n",
      "Epoch 18880, train loss on all blocks 2.141050280570031\n",
      "Epoch 18890, train loss on all blocks 2.8642084855984153\n",
      "Epoch 18900, train loss on all blocks 2.3288401463777855\n",
      "Epoch 18910, train loss on all blocks 2.1644620825191585\n",
      "Epoch 18920, train loss on all blocks 2.0754697498812478\n",
      "Epoch 18930, train loss on all blocks 2.027424193171031\n",
      "Epoch 18940, train loss on all blocks 2.0156116817602396\n",
      "Epoch 18950, train loss on all blocks 2.2532724562494253\n",
      "Epoch 18960, train loss on all blocks 2.8527944297719845\n",
      "Epoch 18970, train loss on all blocks 2.2072236212208995\n",
      "Epoch 18980, train loss on all blocks 2.1300739665468313\n",
      "Epoch 18990, train loss on all blocks 2.104940194428927\n",
      "Epoch 19000, train loss on all blocks 2.425272283162932\n",
      "Epoch 19010, train loss on all blocks 2.461134376564662\n",
      "Epoch 19020, train loss on all blocks 2.2618192056207356\n",
      "Epoch 19030, train loss on all blocks 2.1728599634560783\n",
      "Epoch 19040, train loss on all blocks 2.180667102304525\n",
      "Epoch 19050, train loss on all blocks 2.109036829353368\n",
      "Epoch 19060, train loss on all blocks 2.091490266795595\n",
      "Epoch 19070, train loss on all blocks 2.0380273275548344\n",
      "Epoch 19080, train loss on all blocks 2.0120526994595416\n",
      "Epoch 19090, train loss on all blocks 1.9959767976451368\n",
      "Epoch 19100, train loss on all blocks 2.179974115098431\n",
      "Epoch 19110, train loss on all blocks 2.022640666410453\n",
      "Epoch 19120, train loss on all blocks 2.004266183519695\n",
      "Epoch 19130, train loss on all blocks 3.503763692452731\n",
      "Epoch 19140, train loss on all blocks 2.3857901855007513\n",
      "Epoch 19150, train loss on all blocks 2.2821766822303875\n",
      "Epoch 19160, train loss on all blocks 2.851681603767959\n",
      "Epoch 19170, train loss on all blocks 2.389386355952297\n",
      "Epoch 19180, train loss on all blocks 2.2885186386674494\n",
      "Epoch 19190, train loss on all blocks 2.2749816711953104\n",
      "Epoch 19200, train loss on all blocks 2.159668488391212\n",
      "Epoch 19210, train loss on all blocks 2.0910106950071956\n",
      "Epoch 19220, train loss on all blocks 2.0612308079784656\n",
      "Epoch 19230, train loss on all blocks 2.0320085067923976\n",
      "Epoch 19240, train loss on all blocks 2.062501354364295\n",
      "Epoch 19250, train loss on all blocks 6.278621772829295\n",
      "Epoch 19260, train loss on all blocks 2.5609691765240528\n",
      "Epoch 19270, train loss on all blocks 2.35195231476874\n",
      "Epoch 19280, train loss on all blocks 2.1812533290125504\n",
      "Epoch 19290, train loss on all blocks 2.1843932129378345\n",
      "Epoch 19300, train loss on all blocks 2.3085178799485284\n",
      "Epoch 19310, train loss on all blocks 2.0943253978090084\n",
      "Epoch 19320, train loss on all blocks 2.0468347174143178\n",
      "Epoch 19330, train loss on all blocks 2.0443353829848254\n",
      "Epoch 19340, train loss on all blocks 2.8427474270288\n",
      "Epoch 19350, train loss on all blocks 2.2243254336568175\n",
      "Epoch 19360, train loss on all blocks 2.2201916254829426\n",
      "Epoch 19370, train loss on all blocks 2.1298751362216586\n",
      "Epoch 19380, train loss on all blocks 2.2849157669167397\n",
      "Epoch 19390, train loss on all blocks 2.531194502608648\n",
      "Epoch 19400, train loss on all blocks 2.3402456669232374\n",
      "Epoch 19410, train loss on all blocks 2.177528897786339\n",
      "Epoch 19420, train loss on all blocks 2.1094068335515193\n",
      "Epoch 19430, train loss on all blocks 2.103063520014079\n",
      "Epoch 19440, train loss on all blocks 2.0454627603983244\n",
      "Epoch 19450, train loss on all blocks 2.003247164611234\n",
      "Epoch 19460, train loss on all blocks 1.9864862696463104\n",
      "Epoch 19470, train loss on all blocks 2.006302854965609\n",
      "Epoch 19480, train loss on all blocks 2.0295642017499005\n",
      "Epoch 19490, train loss on all blocks 2.3917958330908053\n",
      "Epoch 19500, train loss on all blocks 2.1505196374328417\n",
      "Epoch 19510, train loss on all blocks 2.1395223337474834\n",
      "Epoch 19520, train loss on all blocks 3.138859645149375\n",
      "Epoch 19530, train loss on all blocks 2.4085332459897213\n",
      "Epoch 19540, train loss on all blocks 2.2405239543282844\n",
      "Epoch 19550, train loss on all blocks 2.1686155994705194\n",
      "Epoch 19560, train loss on all blocks 2.111331033893763\n",
      "Epoch 19570, train loss on all blocks 2.0640877468070675\n",
      "Epoch 19580, train loss on all blocks 2.032632617586165\n",
      "Epoch 19590, train loss on all blocks 2.006979541833375\n",
      "Epoch 19600, train loss on all blocks 1.9903020396114104\n",
      "Epoch 19610, train loss on all blocks 1.9938668240709252\n",
      "Epoch 19620, train loss on all blocks 2.059985166339092\n",
      "Epoch 19630, train loss on all blocks 2.01325177562129\n",
      "Epoch 19640, train loss on all blocks 1.9753325488985136\n",
      "Epoch 19650, train loss on all blocks 2.835488113364285\n",
      "Epoch 19660, train loss on all blocks 2.485316313592503\n",
      "Epoch 19670, train loss on all blocks 2.159042651184953\n",
      "Epoch 19680, train loss on all blocks 2.1754910307149964\n",
      "Epoch 19690, train loss on all blocks 2.1868123102616797\n",
      "Epoch 19700, train loss on all blocks 2.1135897334822435\n",
      "Epoch 19710, train loss on all blocks 2.9982841223496317\n",
      "Epoch 19720, train loss on all blocks 2.2581580673510726\n",
      "Epoch 19730, train loss on all blocks 2.676778451770649\n",
      "Epoch 19740, train loss on all blocks 2.199279574392471\n",
      "Epoch 19750, train loss on all blocks 2.147831125721533\n",
      "Epoch 19760, train loss on all blocks 2.0866866441151832\n",
      "Epoch 19770, train loss on all blocks 2.051249838565468\n",
      "Epoch 19780, train loss on all blocks 2.0281249779068196\n",
      "Epoch 19790, train loss on all blocks 2.03494765562964\n",
      "Epoch 19800, train loss on all blocks 2.0051541643053836\n",
      "Epoch 19810, train loss on all blocks 2.0268116418715314\n",
      "Epoch 19820, train loss on all blocks 2.1420648562017894\n",
      "Epoch 19830, train loss on all blocks 2.275388072352454\n",
      "Epoch 19840, train loss on all blocks 2.3902823679393084\n",
      "Epoch 19850, train loss on all blocks 2.2436330397628854\n",
      "Epoch 19860, train loss on all blocks 2.157989324964256\n",
      "Epoch 19870, train loss on all blocks 2.111600272635629\n",
      "Epoch 19880, train loss on all blocks 2.088135073835154\n",
      "Epoch 19890, train loss on all blocks 2.1308168769660423\n",
      "Epoch 19900, train loss on all blocks 2.03505657131358\n",
      "Epoch 19910, train loss on all blocks 4.005830009261048\n",
      "Epoch 19920, train loss on all blocks 2.62018106570778\n",
      "Epoch 19930, train loss on all blocks 2.298644639239769\n",
      "Epoch 19940, train loss on all blocks 2.1295044487951706\n",
      "Epoch 19950, train loss on all blocks 2.080600036030753\n",
      "Epoch 19960, train loss on all blocks 2.0570717510736936\n",
      "Epoch 19970, train loss on all blocks 2.2193528077590106\n",
      "Epoch 19980, train loss on all blocks 2.036270550453992\n",
      "Epoch 19990, train loss on all blocks 2.0196957838165934\n"
     ]
    }
   ],
   "source": [
    "m = train_model(model, optimizer, nepoch = 20000, dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c44d80-7534-47a5-a87a-18be59be7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f train_model train_model(model, optimizer, nepoch = 1, dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "be030d23-f770-484b-9345-774eb8394a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.twocenter_utils import _to_uncoupled_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b8e4b886-a684-4d24-b611-52776807fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.symmetry import ClebschGordanReal, _complex_clebsch_gordan_matrix, _real_clebsch_gordan_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "545f2677-4bdc-41f2-81c7-39f7c582f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_cg(lmax):\n",
    "    return ClebschGordanReal(lmax, device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6f7874f3-23c0-4402-a8fa-9789bb57e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.000335143 s\n",
       "File: /home/pegolo/Software/my_mlelec/src/mlelec/utils/symmetry.py\n",
       "Function: _complex_clebsch_gordan_matrix at line 228\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   228                                           def _complex_clebsch_gordan_matrix(l1: int, l2: int, L: int, device: str = None):\n",
       "   229                                               \"\"\"\n",
       "   230                                               Computes the Clebsch-Gordan (CG) matrix for\n",
       "   231                                               transforming complex-valued spherical harmonics.\n",
       "   232                                               The CG matrix is computed as a 3D array of elements\n",
       "   233                                               < l1 m1 l2 m2 | L M >\n",
       "   234                                               where the first axis loops over m1, the second loops over m2,\n",
       "   235                                               and the third one loops over M. The matrix is real.\n",
       "   236                                           \n",
       "   237                                               For example, using the relation:\n",
       "   238                                           \n",
       "   239                                                   | l1 l2 L M > = \\sum_{m1, m2} <l1 m1 l2 m2 | L M > | l1 m1 > | l2 m2 >\n",
       "   240                                           \n",
       "   241                                               Args:\n",
       "   242                                                   l1: Order of the first set of spherical harmonics\n",
       "   243                                                   l2: Order of the second set of spherical harmonics\n",
       "   244                                                   L: Order of the coupled spherical harmonics\n",
       "   245                                               Returns:\n",
       "   246                                                   real_cg: CG matrix for transforming complex-valued spherical harmonics\n",
       "   247                                               \"\"\"\n",
       "   248         1       1563.0   1563.0      0.5      if abs(l1 - l2) > L or (l1 + l2) < L:\n",
       "   249                                                   return torch.zeros(\n",
       "   250                                                       (2 * l1 + 1, 2 * l2 + 1, 2 * L + 1), dtype=torch.double, device=device\n",
       "   251                                                   )\n",
       "   252                                               else:\n",
       "   253         1     333580.0 333580.0     99.5          return torch.from_numpy(wigners.clebsch_gordan_array(l1, l2, L)).to(device)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f _complex_clebsch_gordan_matrix _complex_clebsch_gordan_matrix(1, 1, 2, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4c14805d-a653-4eff-a242-bf71b6ccc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wigners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9c9ff9fb-0586-4c9d-8751-7f2d1ebb088c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.000228811 s\n",
       "File: /home/pegolo/micromamba/envs/sci/lib/python3.11/site-packages/wigners/__init__.py\n",
       "Function: clebsch_gordan_array at line 66\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    66                                           def clebsch_gordan_array(j1: int, j2: int, j3: int) -> np.ndarray:\n",
       "    67                                               \"\"\"\n",
       "    68                                               Compute a full array of Clebsch-Gordan coefficient for the three given\n",
       "    69                                               ``j``.\n",
       "    70                                           \n",
       "    71                                               The result is a 3-dimensional array with shape ``(2 * j1 + 1, 2 * j2 + 1, 2\n",
       "    72                                               * j3 + 1)``.\n",
       "    73                                               \"\"\"\n",
       "    74         1      10079.0  10079.0      4.4      array = np.zeros((2 * j1 + 1, 2 * j2 + 1, 2 * j3 + 1), dtype=np.float64)\n",
       "    75         1      22993.0  22993.0     10.0      ptr = array.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
       "    76         1     195529.0 195529.0     85.5      __lib.clebsch_gordan_array_c(j1, j2, j3, ptr, array.size)\n",
       "    77         1        210.0    210.0      0.1      return array"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f wigners.clebsch_gordan_array wigners.clebsch_gordan_array(1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0d7f0e89-b0d9-4c37-a80c-deafc2d0bae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0424829 s\n",
       "File: /home/pegolo/Software/my_mlelec/src/mlelec/utils/symmetry.py\n",
       "Function: __init__ at line 288\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   288                                               def __init__(self, lmax: int, device: str = None):\n",
       "   289         1        681.0    681.0      0.0          self.lmax = lmax\n",
       "   290         1        271.0    271.0      0.0          self._cg = {}\n",
       "   291         1        150.0    150.0      0.0          if device is not None:\n",
       "   292         1        280.0    280.0      0.0              self.device = device\n",
       "   293                                                   else:\n",
       "   294                                                       self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
       "   295                                           \n",
       "   296         1        130.0    130.0      0.0          self.r2c = {}\n",
       "   297         1        200.0    200.0      0.0          self.c2r = {}\n",
       "   298         5       1703.0    340.6      0.0          for L in range(0, lmax + 1):\n",
       "   299         4     360219.0  90054.8      0.8              self.r2c[L] = _real2complex(L).to(self.device)\n",
       "   300         4      33704.0   8426.0      0.1              self.c2r[L] = torch.conj(self.r2c[L]).T\n",
       "   301                                           \n",
       "   302                                                   # real-to-complex and complex-to-real transformations as matrices\n",
       "   303         5       1513.0    302.6      0.0          for l1 in range(self.lmax + 1):\n",
       "   304        20       7784.0    389.2      0.0              for l2 in range(self.lmax + 1):\n",
       "   305        50      44950.0    899.0      0.1                  for L in range(abs(l1 - l2), min(self.lmax, (l1 + l2)) + 1):\n",
       "   306        68   30784927.0 452719.5     72.5                      rcg = _real_clebsch_gordan_matrix(\n",
       "   307        34       4467.0    131.4      0.0                          l1,\n",
       "   308        34       5312.0    156.2      0.0                          l2,\n",
       "   309        34       4413.0    129.8      0.0                          L,\n",
       "   310        34      13738.0    404.1      0.0                          r2c_l1=self.r2c[l1],\n",
       "   311        34       6777.0    199.3      0.0                          r2c_l2=self.r2c[l2],\n",
       "   312        34       7366.0    216.6      0.0                          c2r_L=self.c2r[L],\n",
       "   313        34       6060.0    178.2      0.0                          device=self.device,\n",
       "   314                                                               )\n",
       "   315                                           \n",
       "   316                                                               # sparsify: take only the non-zero entries (indices\n",
       "   317                                                               # of m1 and m2 components) for each M\n",
       "   318        34      11132.0    327.4      0.0                      new_cg = []\n",
       "   319       190      86028.0    452.8      0.2                      for M in range(2 * L + 1):\n",
       "   320       156    4348146.0  27872.7     10.2                          cg_nonzero = torch.where(abs(rcg[:, :, M]) > 1e-15)\n",
       "   321       312     803566.0   2575.5      1.9                          cg_M = torch.zeros(\n",
       "   322       156     591560.0   3792.1      1.4                              (len(cg_nonzero[0]), 3),\n",
       "   323                                                                       # dtype=[(torch.int32, torch.int32, torch.int32)],\n",
       "   324       156      36657.0    235.0      0.1                              device=self.device,\n",
       "   325                                                                   )\n",
       "   326       156    1833194.0  11751.2      4.3                          cg_M[:, 0] = cg_nonzero[0].type(torch.int)\n",
       "   327       156    1047720.0   6716.2      2.5                          cg_M[:, 1] = cg_nonzero[1].type(torch.int)\n",
       "   328       156    2322730.0  14889.3      5.5                          cg_M[:, 2] = rcg[cg_nonzero[0], cg_nonzero[1], M]\n",
       "   329       156      83535.0    535.5      0.2                          new_cg.append(cg_M)\n",
       "   330                                           \n",
       "   331        34      33937.0    998.1      0.1                      self._cg[(l1, l2, L)] = new_cg\n",
       "   332                                                   # self._cg.to(self.device)\n",
       "   333                                                   # self._cg = {\n",
       "   334                                                   #     k: v.to(device=self.device, non_blocking=True) for k, v in self._cg.items()\n",
       "   335                                                   # }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f ClebschGordanReal.__init__ ClebschGordanReal(3, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "11f1c73f-db77-41a1-914d-a8e2ddedb089",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2c = {}\n",
    "c2r = {}\n",
    "from mlelec.utils.symmetry import _real2complex\n",
    "for L in range(0, 3 + 1):\n",
    "    r2c[L] = _real2complex(L).to('cpu')\n",
    "    c2r[L] = torch.conj(r2c[L]).T\n",
    "rcg = _real_clebsch_gordan_matrix(1, 1, 2, r2c_l1=r2c[1], r2c_l2=r2c[1], c2r_L=c2r[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "38440ffd-2a96-4ea0-ae32-5bd2829894af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_M = {}\n",
    "for M in range(-2, 3):\n",
    "    cg_nonzero = torch.where(abs(rcg[:, :, M]) > 1e-15)\n",
    "    cg_M[M] = torch.zeros(\n",
    "        (len(cg_nonzero[0]), 3),\n",
    "        # dtype=[(torch.int32, torch.int32, torch.int32)],\n",
    "        device='cpu',\n",
    "    )\n",
    "    cg_M[M][:, 0] = cg_nonzero[0].type(torch.int)\n",
    "    cg_M[M][:, 1] = cg_nonzero[1].type(torch.int)\n",
    "    cg_M[M][:, 2] = rcg[cg_nonzero[0], cg_nonzero[1], M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d351c904-f455-40d1-9158-b6815d259c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 3])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcg.nonzero().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f80f9df9-09dd-4bac-87d6-8418c44be09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4082, -0.7071,  0.7071,  0.7071,  0.7071,  0.8165,  0.7071,  0.7071,\n",
       "         0.7071, -0.4082,  0.7071])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcg[rcg.nonzero(as_tuple = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "174a5f4b-8a83-4a83-90b0-451630efd802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 2.0000, 0.7071],\n",
       "        [2.0000, 0.0000, 0.7071]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg_M[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21e1f0-e7ff-4b0f-ad2d-0be600d5c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=2\n",
    "cg_nonzero = torch.where(abs(rcg[:, :, M]) > 1e-15)\n",
    "cg_M = torch.zeros(\n",
    "    (len(cg_nonzero[0]), 3),\n",
    "    # dtype=[(torch.int32, torch.int32, torch.int32)],\n",
    "    device='cpu',\n",
    ")\n",
    "cg_M[:, 0] = cg_nonzero[0].type(torch.int)\n",
    "cg_M[:, 1] = cg_nonzero[1].type(torch.int)\n",
    "cg_M[:, 2] = rcg[cg_nonzero[0], cg_nonzero[1], M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ccc7f157-a68a-4837-809c-06fa3f5990aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascaline.utils import DensityCorrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "78b74858-3802-4b9a-98e5-614141bd6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DensityCorrelations(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "713fec3c-ac85-4809-b23f-618ec5c8eb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels(\n",
       "    block_type  species_i  n_i  l_i  species_j  n_j  l_j\n",
       "        0           6       1    0       6       1    0\n",
       "        0           6       1    0       6       2    0\n",
       "        0           6       1    0       6       2    1\n",
       "        0           6       2    0       6       1    0\n",
       "        0           6       2    0       6       2    0\n",
       "        0           6       2    0       6       2    1\n",
       "        0           6       2    1       6       1    0\n",
       "        0           6       2    1       6       2    0\n",
       "        0           6       2    1       6       2    1\n",
       "        1           6       1    0       6       1    0\n",
       "        -1          6       1    0       6       1    0\n",
       "        1           6       1    0       6       2    0\n",
       "        -1          6       1    0       6       2    0\n",
       "        1           6       1    0       6       2    1\n",
       "        -1          6       1    0       6       2    1\n",
       "        1           6       2    0       6       1    0\n",
       "        -1          6       2    0       6       1    0\n",
       "        1           6       2    0       6       2    0\n",
       "        -1          6       2    0       6       2    0\n",
       "        1           6       2    0       6       2    1\n",
       "        -1          6       2    0       6       2    1\n",
       "        1           6       2    1       6       1    0\n",
       "        -1          6       2    1       6       1    0\n",
       "        1           6       2    1       6       2    0\n",
       "        -1          6       2    1       6       2    0\n",
       "        1           6       2    1       6       2    1\n",
       "        -1          6       2    1       6       2    1\n",
       ")"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_blocks.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "337ea173-8526-49a1-b309-f3e5963ffb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.14945 s\n",
       "File: /home/pegolo/Software/my_mlelec/src/mlelec/metrics.py\n",
       "Function: L2_kspace_loss at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                           def L2_kspace_loss(pred: Union[TensorMap], \n",
       "    11                                                              target: Union[TensorMap],\n",
       "    12                                                              dataset: QMDataset,\n",
       "    13                                                              cg: Optional[ClebschGordanReal] = None,\n",
       "    14                                                              ):\n",
       "    15                                               \n",
       "    16         1       1032.0   1032.0      0.0      assert isinstance(target, TensorMap), \"Target must be a TensorMap\"\n",
       "    17         1        181.0    181.0      0.0      assert isinstance(pred, TensorMap), \"Prediction must be a TensorMap\"\n",
       "    18                                           \n",
       "    19         1        120.0    120.0      0.0      loss = 0\n",
       "    20         1  102489880.0    1e+08     68.6      pred_real = blocks_to_matrix(pred, dataset, cg = cg)\n",
       "    21         1   46194531.0    5e+07     30.9      target_real = blocks_to_matrix(target, dataset, cg = cg)\n",
       "    22         1     449759.0 449759.0      0.3      pred_kspace = dataset.compute_matrices_kspace(pred_real)\n",
       "    23         1     120027.0 120027.0      0.1      target_kspace = dataset.compute_matrices_kspace(target_real)\n",
       "    24         2       2103.0   1051.5      0.0      for ifr in range(len(target_kspace)):\n",
       "    25         1     107823.0 107823.0      0.1          loss += torch.sum((pred_kspace[ifr] - target_kspace[ifr]) * torch.conj(pred_kspace[ifr] - target_kspace[ifr]))\n",
       "    26         1      79760.0  79760.0      0.1      assert torch.norm(loss-loss.real) <1e-10\n",
       "    27         1       4358.0   4358.0      0.0      return loss.real"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f L2_kspace_loss L2_kspace_loss(pred, target_blocks, dataset) #, cg = CG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "66f6a5fa-2f40-4583-87f9-8443b0b3f4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0903787 s\n",
       "File: /home/pegolo/Software/my_mlelec/src/mlelec/utils/pbc_utils.py\n",
       "Function: blocks_to_matrix at line 358\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   358                                           def blocks_to_matrix(blocks, dataset, device=None, return_negative=False, cg = None):\n",
       "   359         1        601.0    601.0      0.0      if device is None:\n",
       "   360         1       1092.0   1092.0      0.0          device = dataset.device\n",
       "   361                                           \n",
       "   362         1      81133.0  81133.0      0.1      if \"L\" in blocks.keys.names:\n",
       "   363         1       2806.0   2806.0      0.0          from mlelec.utils.twocenter_utils import _to_uncoupled_basis\n",
       "   364         1   19400914.0    2e+07     21.5          blocks = _to_uncoupled_basis(blocks, cg = cg)\n",
       "   365                                           \n",
       "   366         1       6222.0   6222.0      0.0      orbs_tot, orbs_offset = _orbs_offsets(dataset.basis)\n",
       "   367         1      16290.0  16290.0      0.0      atom_blocks_idx = _atom_blocks_idx(dataset.structures, orbs_tot)\n",
       "   368         2     153279.0  76639.5      0.2      orbs_mult = {\n",
       "   369                                                   species: \n",
       "   370                                                           {tuple(k): v\n",
       "   371                                                       for k, v in zip(\n",
       "   372                                                           *np.unique(\n",
       "   373                                                               np.asarray(dataset.basis[species])[:, :2],\n",
       "   374                                                               axis=0,\n",
       "   375                                                               return_counts=True,\n",
       "   376                                                           )\n",
       "   377                                                       )\n",
       "   378                                                   }\n",
       "   379         1        180.0    180.0      0.0          for species in dataset.basis\n",
       "   380                                               }\n",
       "   381                                           \n",
       "   382         1        391.0    391.0      0.0      reconstructed_matrices_plus = []\n",
       "   383         1        200.0    200.0      0.0      reconstructed_matrices_minus = []\n",
       "   384                                           \n",
       "   385                                               # Loop over frames\n",
       "   386         2       1351.0    675.5      0.0      for A, shifts in enumerate(dataset.realspace_translations):\n",
       "   387         1      15139.0  15139.0      0.0          norbs = np.sum([orbs_tot[ai] for ai in dataset.structures[A].numbers])\n",
       "   388                                           \n",
       "   389         1     133712.0 133712.0      0.1          reconstructed_matrices_plus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
       "   390         1     113514.0 113514.0      0.1          reconstructed_matrices_minus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
       "   391                                           \n",
       "   392                                               # loops over block types\n",
       "   393        28    1063480.0  37981.4      1.2      for key, block in blocks.items():\n",
       "   394        27      42832.0   1586.4      0.0          block_type = key[\"block_type\"]\n",
       "   395        27      53389.0   1977.4      0.1          ai, ni, li = key[\"species_i\"], key[\"n_i\"], key[\"l_i\"]\n",
       "   396        27      52369.0   1939.6      0.1          aj, nj, lj = key[\"species_j\"], key[\"n_j\"], key[\"l_j\"]\n",
       "   397                                                   \n",
       "   398                                                   # What's the multiplicity of the orbital type, ex. 2p_x, 2p_y, 2p_z makes the multiplicity \n",
       "   399                                                   # of a p block = 3\n",
       "   400        27      95140.0   3523.7      0.1          orbs_i = orbs_mult[ai]\n",
       "   401        27      32722.0   1211.9      0.0          orbs_j = orbs_mult[aj]\n",
       "   402                                                   \n",
       "   403                                                   # The shape of the block corresponding to the orbital pair\n",
       "   404        54     177803.0   3292.6      0.2          shapes = {\n",
       "   405                                                       (k1 + k2): (orbs_i[tuple(k1)], orbs_j[tuple(k2)])\n",
       "   406        27       2765.0    102.4      0.0              for k1 in orbs_i\n",
       "   407                                                       for k2 in orbs_j\n",
       "   408                                                   }\n",
       "   409                                                   # offset of the orbital (ni, li) within a block of atom i\n",
       "   410        27      86050.0   3187.0      0.1          ioffset = orbs_offset[(ai, ni, li)] \n",
       "   411                                                   # offset of the orbital (nj,lj) within a block of atom j\n",
       "   412        27      73118.0   2708.1      0.1          joffset = orbs_offset[(aj, nj, lj)]\n",
       "   413                                           \n",
       "   414        27      21757.0    805.8      0.0          i_end, j_end = shapes[(ni, li, nj, lj)]\n",
       "   415                                           \n",
       "   416                                                   # loops over samples (structure, i, j)\n",
       "   417      1665   10371682.0   6229.2     11.5          for sample, blockval in zip(block.samples, block.values):\n",
       "   418                                                       \n",
       "   419      1638    2072374.0   1265.2      2.3              A = sample[\"structure\"]\n",
       "   420      1638    1196498.0    730.5      1.3              i = sample[\"center\"]\n",
       "   421      1638    1133185.0    691.8      1.3              j = sample[\"neighbor\"]\n",
       "   422      1638    3058576.0   1867.3      3.4              Tx, Ty, Tz = sample[\"cell_shift_a\"], sample[\"cell_shift_b\"], sample[\"cell_shift_c\"]\n",
       "   423                                           \n",
       "   424      1638     789681.0    482.1      0.9              matrix_T_plus  = reconstructed_matrices_plus[A][Tx, Ty, Tz]\n",
       "   425                                           \n",
       "   426      1638     198692.0    121.3      0.2              if return_negative:\n",
       "   427                                                           matrix_T_minus = reconstructed_matrices_minus[A][Tx, Ty, Tz]\n",
       "   428                                                       # i_start, j_start = atom_blocks_idx[(A, i, j)]\n",
       "   429                                           \n",
       "   430      1638    7218326.0   4406.8      8.0              i_start, j_start = atom_blocks_idx[(A, i, j)]\n",
       "   431      1638     780813.0    476.7      0.9              i_slice = slice(i_start + ioffset, i_start + ioffset + i_end) \n",
       "   432      1638     472544.0    288.5      0.5              j_slice = slice(j_start + joffset, j_start + joffset + j_end)\n",
       "   433                                           \n",
       "   434                                                       # OPT (commented)\n",
       "   435                                                       # values = blockval[:, :, 0].clone()\n",
       "   436                                           \n",
       "   437      1638    1797958.0   1097.7      2.0              if block_type == 1:\n",
       "   438      2430   12994276.0   5347.4     14.4                  matrix_T_plus[\n",
       "   439                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   440                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   441       810      94342.0    116.5      0.1                      i_slice, j_slice\n",
       "   442       810    8783191.0  10843.4      9.7                  ] += blockval[:, :, 0]*ISQRT_2 # OPTvalues\n",
       "   443                                           \n",
       "   444       810     158672.0    195.9      0.2                  if return_negative:\n",
       "   445                                                               matrix_T_minus[\n",
       "   446                                                                   # j_start + ioffset : j_start + ioffset + i_end,\n",
       "   447                                                                   # i_start + joffset : i_start + joffset + j_end,\n",
       "   448                                                                   i_slice, j_slice\n",
       "   449                                                               ] += blockval[:, :, 0]*ISQRT_2 # values # OPT\n",
       "   450                                                                   \n",
       "   451       828     846518.0   1022.4      0.9              elif block_type == -1:\n",
       "   452                                                               \n",
       "   453      2430   12193714.0   5018.0     13.5                  matrix_T_plus[\n",
       "   454                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   455                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   456       810      95497.0    117.9      0.1                      i_slice, j_slice\n",
       "   457       810    3999046.0   4937.1      4.4                  ] += blockval[:, :, 0] # values # OPT\n",
       "   458                                           \n",
       "   459       810     152941.0    188.8      0.2                  if return_negative:\n",
       "   460                                                               matrix_T_minus[\n",
       "   461                                                                   # j_start + ioffset : j_start + ioffset + i_end,\n",
       "   462                                                                   # i_start + joffset : i_start + joffset + j_end,\n",
       "   463                                                                   i_slice, j_slice\n",
       "   464                                                               ] -= blockval[:, :, 0] # values # OPT\n",
       "   465                                           \n",
       "   466                                                       # if block_type == 0 or block_type == 2:\n",
       "   467                                                       else: # bt = 0 or 2\n",
       "   468                                           \n",
       "   469        36     181281.0   5035.6      0.2                  matrix_T_plus[\n",
       "   470                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   471                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   472        36       4397.0    122.1      0.0                      i_slice,\n",
       "   473        18       1552.0     86.2      0.0                      j_slice,\n",
       "   474        18     154341.0   8574.5      0.2                               ] = blockval[:, :, 0] # values # OPT\n",
       "   475                                           \n",
       "   476                                           \n",
       "   477         1        230.0    230.0      0.0      if return_negative:\n",
       "   478                                                   return reconstructed_matrices_plus, reconstructed_matrices_minus\n",
       "   479         1         80.0     80.0      0.0      return reconstructed_matrices_plus"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f blocks_to_matrix blocks_to_matrix(pred, dataset, cg = CG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "57d1ec24-c76e-40a2-9a55-6d9026769211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0522046 s\n",
       "File: /home/pegolo/Software/my_mlelec/src/mlelec/utils/pbc_utils.py\n",
       "Function: blocks_to_matrix at line 358\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   358                                           def blocks_to_matrix(blocks, dataset, device=None, return_negative=False, cg = None):\n",
       "   359         1        491.0    491.0      0.0      if device is None:\n",
       "   360         1       1122.0   1122.0      0.0          device = dataset.device\n",
       "   361                                           \n",
       "   362         1      78077.0  78077.0      0.1      if \"L\" in blocks.keys.names:\n",
       "   363                                                   from mlelec.utils.twocenter_utils import _to_uncoupled_basis\n",
       "   364                                                   blocks = _to_uncoupled_basis(blocks, cg = cg)\n",
       "   365                                           \n",
       "   366         1       5891.0   5891.0      0.0      orbs_tot, orbs_offset = _orbs_offsets(dataset.basis)\n",
       "   367         1      16942.0  16942.0      0.0      atom_blocks_idx = _atom_blocks_idx(dataset.structures, orbs_tot)\n",
       "   368         2     177024.0  88512.0      0.3      orbs_mult = {\n",
       "   369                                                   species: \n",
       "   370                                                           {tuple(k): v\n",
       "   371                                                       for k, v in zip(\n",
       "   372                                                           *np.unique(\n",
       "   373                                                               np.asarray(dataset.basis[species])[:, :2],\n",
       "   374                                                               axis=0,\n",
       "   375                                                               return_counts=True,\n",
       "   376                                                           )\n",
       "   377                                                       )\n",
       "   378                                                   }\n",
       "   379         1        160.0    160.0      0.0          for species in dataset.basis\n",
       "   380                                               }\n",
       "   381                                           \n",
       "   382         1        170.0    170.0      0.0      reconstructed_matrices_plus = []\n",
       "   383         1        100.0    100.0      0.0      reconstructed_matrices_minus = []\n",
       "   384                                           \n",
       "   385                                               # Loop over frames\n",
       "   386         2       1843.0    921.5      0.0      for A, shifts in enumerate(dataset.realspace_translations):\n",
       "   387         1      16040.0  16040.0      0.0          norbs = np.sum([orbs_tot[ai] for ai in dataset.structures[A].numbers])\n",
       "   388                                           \n",
       "   389         1     327098.0 327098.0      0.6          reconstructed_matrices_plus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
       "   390         1     144443.0 144443.0      0.3          reconstructed_matrices_minus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
       "   391                                           \n",
       "   392                                               # loops over block types\n",
       "   393        28    1033412.0  36907.6      2.0      for key, block in blocks.items():\n",
       "   394        27      45317.0   1678.4      0.1          block_type = key[\"block_type\"]\n",
       "   395        27      57991.0   2147.8      0.1          ai, ni, li = key[\"species_i\"], key[\"n_i\"], key[\"l_i\"]\n",
       "   396        27      56931.0   2108.6      0.1          aj, nj, lj = key[\"species_j\"], key[\"n_j\"], key[\"l_j\"]\n",
       "   397                                                   \n",
       "   398                                                   # What's the multiplicity of the orbital type, ex. 2p_x, 2p_y, 2p_z makes the multiplicity \n",
       "   399                                                   # of a p block = 3\n",
       "   400        27     103627.0   3838.0      0.2          orbs_i = orbs_mult[ai]\n",
       "   401        27      35838.0   1327.3      0.1          orbs_j = orbs_mult[aj]\n",
       "   402                                                   \n",
       "   403                                                   # The shape of the block corresponding to the orbital pair\n",
       "   404        54     176842.0   3274.9      0.3          shapes = {\n",
       "   405                                                       (k1 + k2): (orbs_i[tuple(k1)], orbs_j[tuple(k2)])\n",
       "   406        27       2828.0    104.7      0.0              for k1 in orbs_i\n",
       "   407                                                       for k2 in orbs_j\n",
       "   408                                                   }\n",
       "   409                                                   # offset of the orbital (ni, li) within a block of atom i\n",
       "   410        27      89669.0   3321.1      0.2          ioffset = orbs_offset[(ai, ni, li)] \n",
       "   411                                                   # offset of the orbital (nj,lj) within a block of atom j\n",
       "   412        27      77426.0   2867.6      0.1          joffset = orbs_offset[(aj, nj, lj)]\n",
       "   413                                           \n",
       "   414        27      21911.0    811.5      0.0          i_end, j_end = shapes[(ni, li, nj, lj)]\n",
       "   415                                           \n",
       "   416                                                   # loops over samples (structure, i, j)\n",
       "   417      1665    8916381.0   5355.2     17.1          for sample, blockval in zip(block.samples, block.values):\n",
       "   418                                                       \n",
       "   419      1638    1781596.0   1087.7      3.4              A = sample[\"structure\"]\n",
       "   420      1638    1175207.0    717.5      2.3              i = sample[\"center\"]\n",
       "   421      1638    1105162.0    674.7      2.1              j = sample[\"neighbor\"]\n",
       "   422      1638    3045511.0   1859.3      5.8              Tx, Ty, Tz = sample[\"cell_shift_a\"], sample[\"cell_shift_b\"], sample[\"cell_shift_c\"]\n",
       "   423                                           \n",
       "   424      1638     690647.0    421.6      1.3              matrix_T_plus  = reconstructed_matrices_plus[A][Tx, Ty, Tz]\n",
       "   425                                           \n",
       "   426      1638     187469.0    114.4      0.4              if return_negative:\n",
       "   427                                                           matrix_T_minus = reconstructed_matrices_minus[A][Tx, Ty, Tz]\n",
       "   428                                                       # i_start, j_start = atom_blocks_idx[(A, i, j)]\n",
       "   429                                           \n",
       "   430      1638    6427951.0   3924.3     12.3              i_start, j_start = atom_blocks_idx[(A, i, j)]\n",
       "   431      1638     679160.0    414.6      1.3              i_slice = slice(i_start + ioffset, i_start + ioffset + i_end) \n",
       "   432      1638     461701.0    281.9      0.9              j_slice = slice(j_start + joffset, j_start + joffset + j_end)\n",
       "   433                                           \n",
       "   434                                                       # OPT (commented)\n",
       "   435                                                       # values = blockval[:, :, 0].clone()\n",
       "   436                                           \n",
       "   437      1638    1803305.0   1100.9      3.5              if block_type == 1:\n",
       "   438      2430    6697623.0   2756.2     12.8                  matrix_T_plus[\n",
       "   439                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   440                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   441       810      96332.0    118.9      0.2                      i_slice, j_slice\n",
       "   442       810    5930362.0   7321.4     11.4                  ] += blockval[:, :, 0]*ISQRT_2 # OPTvalues\n",
       "   443                                           \n",
       "   444       810     140137.0    173.0      0.3                  if return_negative:\n",
       "   445                                                               matrix_T_minus[\n",
       "   446                                                                   # j_start + ioffset : j_start + ioffset + i_end,\n",
       "   447                                                                   # i_start + joffset : i_start + joffset + j_end,\n",
       "   448                                                                   i_slice, j_slice\n",
       "   449                                                               ] += blockval[:, :, 0]*ISQRT_2 # values # OPT\n",
       "   450                                                                   \n",
       "   451       828     856352.0   1034.2      1.6              elif block_type == -1:\n",
       "   452                                                               \n",
       "   453      2430    6460917.0   2658.8     12.4                  matrix_T_plus[\n",
       "   454                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   455                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   456       810      99427.0    122.7      0.2                      i_slice, j_slice\n",
       "   457       810    2789585.0   3443.9      5.3                  ] += blockval[:, :, 0] # values # OPT\n",
       "   458                                           \n",
       "   459       810     147527.0    182.1      0.3                  if return_negative:\n",
       "   460                                                               matrix_T_minus[\n",
       "   461                                                                   # j_start + ioffset : j_start + ioffset + i_end,\n",
       "   462                                                                   # i_start + joffset : i_start + joffset + j_end,\n",
       "   463                                                                   i_slice, j_slice\n",
       "   464                                                               ] -= blockval[:, :, 0] # values # OPT\n",
       "   465                                           \n",
       "   466                                                       # if block_type == 0 or block_type == 2:\n",
       "   467                                                       else: # bt = 0 or 2\n",
       "   468                                           \n",
       "   469        36     114822.0   3189.5      0.2                  matrix_T_plus[\n",
       "   470                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   471                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   472        36       4045.0    112.4      0.0                      i_slice,\n",
       "   473        18       1401.0     77.8      0.0                      j_slice,\n",
       "   474        18     120478.0   6693.2      0.2                               ] = blockval[:, :, 0] # values # OPT\n",
       "   475                                           \n",
       "   476                                           \n",
       "   477         1        220.0    220.0      0.0      if return_negative:\n",
       "   478                                                   return reconstructed_matrices_plus, reconstructed_matrices_minus\n",
       "   479         1         90.0     90.0      0.0      return reconstructed_matrices_plus"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f blocks_to_matrix blocks_to_matrix(target_blocks, dataset) #, cg = CG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1c0d89d3-2f49-4e54-ac9e-63648eb62cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0209131 s\n",
       "File: /home/pegolo/Software/my_mlelec/src/mlelec/utils/twocenter_utils.py\n",
       "Function: _to_uncoupled_basis at line 949\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   949                                           def _to_uncoupled_basis(\n",
       "   950                                               blocks: TensorMap,\n",
       "   951                                               # orbitals: Optional[dict] = None,\n",
       "   952                                               cg: Optional[ClebschGordanReal] = None,\n",
       "   953                                               device: str = \"cpu\",\n",
       "   954                                               translations: bool = False,\n",
       "   955                                           ):\n",
       "   956                                           \n",
       "   957         1        882.0    882.0      0.0      if cg is None:\n",
       "   958                                                   lmax = max(blocks.keys[\"L\"])\n",
       "   959                                                   cg = ClebschGordanReal(lmax, device=device)\n",
       "   960                                           \n",
       "   961         2       4137.0   2068.5      0.0      block_builder = TensorBuilder(\n",
       "   962                                                   # last key name is L, we remove it here\n",
       "   963         1      99448.0  99448.0      0.5          blocks.keys.names[:-1],\n",
       "   964                                                   # sample_names from the blocks\n",
       "   965                                                   # this is because, e.g. for multiple molecules, we\n",
       "   966                                                   # may have an additional sample name indexing the\n",
       "   967                                                   # molecule id\n",
       "   968         1     110208.0 110208.0      0.5          blocks.sample_names,\n",
       "   969         1        601.0    601.0      0.0          [[\"m1\"], [\"m2\"]],\n",
       "   970         1        250.0    250.0      0.0          [\"value\"],\n",
       "   971                                               )\n",
       "   972        34    1250353.0  36775.1      6.0      for idx, block in blocks.items():\n",
       "   973        33      74461.0   2256.4      0.4          block_type = idx[\"block_type\"]\n",
       "   974        33      36718.0   1112.7      0.2          ai = idx[\"species_i\"]\n",
       "   975        33      39746.0   1204.4      0.2          ni = idx[\"n_i\"]\n",
       "   976        33      32489.0    984.5      0.2          li = idx[\"l_i\"]\n",
       "   977        33      32981.0    999.4      0.2          aj = idx[\"species_j\"]\n",
       "   978        33      33011.0   1000.3      0.2          nj = idx[\"n_j\"]\n",
       "   979        33      33234.0   1007.1      0.2          lj = idx[\"l_j\"]\n",
       "   980        33      34015.0   1030.8      0.2          L = idx[\"L\"]\n",
       "   981        33      12461.0    377.6      0.1          block_idx = (block_type, ai, ni, li, aj, nj, lj)\n",
       "   982        33       5117.0    155.1      0.0          if translations:\n",
       "   983                                                       block_idx = (\n",
       "   984                                                           block_type,\n",
       "   985                                                           ai,\n",
       "   986                                                           ni,\n",
       "   987                                                           li,\n",
       "   988                                                           aj,\n",
       "   989                                                           nj,\n",
       "   990                                                           lj,\n",
       "   991                                                           idx[\"cell_shift_a\"],\n",
       "   992                                                           idx[\"cell_shift_b\"],\n",
       "   993                                                           idx[\"cell_shift_c\"],\n",
       "   994                                                       )\n",
       "   995                                                   # block_type, ai, ni, li, aj, nj, lj, L = tuple(idx)\n",
       "   996                                           \n",
       "   997        33      18615.0    564.1      0.1          if block_idx in block_builder.blocks:\n",
       "   998         6        832.0    138.7      0.0              continue\n",
       "   999        27      39433.0   1460.5      0.2          coupled = {}\n",
       "  1000        60     228647.0   3810.8      1.1          for L in range(np.abs(li - lj), li + lj + 1):\n",
       "  1001        33    1093767.0  33144.5      5.2              bidx = blocks.keys.position(block_idx + (L,))\n",
       "  1002        33       5410.0    163.9      0.0              if bidx is not None:\n",
       "  1003        33    1717744.0  52052.8      8.2                  coupled[L] = torch.moveaxis(blocks.block(bidx).values, -1, -2)\n",
       "  1004                                                   # if ai == aj== 6 and ni == nj == 2 and li == lj == 1 and block_type == 0:\n",
       "  1005                                                   #     print(idx, coupled)\n",
       "  1006        27    5179021.0 191815.6     24.8          decoupled = cg.decouple({(li, lj): coupled})\n",
       "  1007                                           \n",
       "  1008        54    3867854.0  71626.9     18.5          new_block = block_builder.add_block(\n",
       "  1009        27       3777.0    139.9      0.0              key=block_idx,\n",
       "  1010        27     111099.0   4114.8      0.5              properties=np.asarray([[0]], dtype=np.int32),\n",
       "  1011        27     508666.0  18839.5      2.4              components=[_components_idx(li), _components_idx(lj)],\n",
       "  1012                                                   )\n",
       "  1013        54     236515.0   4379.9      1.1          new_block.add_samples(\n",
       "  1014        54     702938.0  13017.4      3.4              labels=np.asarray(block.samples.values).reshape(\n",
       "  1015        27     504701.0  18692.6      2.4                  block.samples.values.shape[0], -1\n",
       "  1016                                                       ),\n",
       "  1017        27     229694.0   8507.2      1.1              data=torch.moveaxis(decoupled, 1, -1),\n",
       "  1018                                                   )\n",
       "  1019         1    4664299.0    5e+06     22.3      return block_builder.build()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f _to_uncoupled_basis _to_uncoupled_basis(target_coupled_blocks, cg = CG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7f94e108-46d4-4828-b536-201be964bf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.115653 s\n",
       "File: /home/pegolo/Software/my_mlelec/src/mlelec/utils/pbc_utils.py\n",
       "Function: blocks_to_matrix at line 358\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   358                                           def blocks_to_matrix(blocks, dataset, device=None, return_negative=False):\n",
       "   359         1        851.0    851.0      0.0      if device is None:\n",
       "   360         1        661.0    661.0      0.0          device = dataset.device\n",
       "   361                                           \n",
       "   362         1      82966.0  82966.0      0.1      if \"L\" in blocks.keys.names:\n",
       "   363         1       2265.0   2265.0      0.0          from mlelec.utils.twocenter_utils import _to_uncoupled_basis\n",
       "   364         1   31888992.0    3e+07     27.6          blocks = _to_uncoupled_basis(blocks)\n",
       "   365                                           \n",
       "   366         1       7054.0   7054.0      0.0      orbs_tot, orbs_offset = _orbs_offsets(dataset.basis)\n",
       "   367         1      16371.0  16371.0      0.0      atom_blocks_idx = _atom_blocks_idx(dataset.structures, orbs_tot)\n",
       "   368         2     158339.0  79169.5      0.1      orbs_mult = {\n",
       "   369                                                   species: \n",
       "   370                                                           {tuple(k): v\n",
       "   371                                                       for k, v in zip(\n",
       "   372                                                           *np.unique(\n",
       "   373                                                               np.asarray(dataset.basis[species])[:, :2],\n",
       "   374                                                               axis=0,\n",
       "   375                                                               return_counts=True,\n",
       "   376                                                           )\n",
       "   377                                                       )\n",
       "   378                                                   }\n",
       "   379         1        190.0    190.0      0.0          for species in dataset.basis\n",
       "   380                                               }\n",
       "   381                                           \n",
       "   382         1        190.0    190.0      0.0      reconstructed_matrices_plus = []\n",
       "   383         1        100.0    100.0      0.0      reconstructed_matrices_minus = []\n",
       "   384                                           \n",
       "   385                                               # Loop over frames\n",
       "   386         2       1703.0    851.5      0.0      for A, shifts in enumerate(dataset.realspace_translations):\n",
       "   387         1      15108.0  15108.0      0.0          norbs = np.sum([orbs_tot[ai] for ai in dataset.structures[A].numbers])\n",
       "   388                                           \n",
       "   389         1     151465.0 151465.0      0.1          reconstructed_matrices_plus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
       "   390         1     127441.0 127441.0      0.1          reconstructed_matrices_minus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
       "   391                                           \n",
       "   392                                               # loops over block types\n",
       "   393        28    1097114.0  39182.6      0.9      for key, block in blocks.items():\n",
       "   394        27      48665.0   1802.4      0.0          block_type = key[\"block_type\"]\n",
       "   395        27      60317.0   2234.0      0.1          ai, ni, li = key[\"species_i\"], key[\"n_i\"], key[\"l_i\"]\n",
       "   396        27      56220.0   2082.2      0.0          aj, nj, lj = key[\"species_j\"], key[\"n_j\"], key[\"l_j\"]\n",
       "   397                                                   \n",
       "   398                                                   # What's the multiplicity of the orbital type, ex. 2p_x, 2p_y, 2p_z makes the multiplicity \n",
       "   399                                                   # of a p block = 3\n",
       "   400        27     106020.0   3926.7      0.1          orbs_i = orbs_mult[ai]\n",
       "   401        27      35746.0   1323.9      0.0          orbs_j = orbs_mult[aj]\n",
       "   402                                                   \n",
       "   403                                                   # The shape of the block corresponding to the orbital pair\n",
       "   404        54     182543.0   3380.4      0.2          shapes = {\n",
       "   405                                                       (k1 + k2): (orbs_i[tuple(k1)], orbs_j[tuple(k2)])\n",
       "   406        27       2956.0    109.5      0.0              for k1 in orbs_i\n",
       "   407                                                       for k2 in orbs_j\n",
       "   408                                                   }\n",
       "   409                                                   # offset of the orbital (ni, li) within a block of atom i\n",
       "   410        27      91943.0   3405.3      0.1          ioffset = orbs_offset[(ai, ni, li)] \n",
       "   411                                                   # offset of the orbital (nj,lj) within a block of atom j\n",
       "   412        27      76704.0   2840.9      0.1          joffset = orbs_offset[(aj, nj, lj)]\n",
       "   413                                           \n",
       "   414        27      22649.0    838.9      0.0          i_end, j_end = shapes[(ni, li, nj, lj)]\n",
       "   415                                           \n",
       "   416                                                   # loops over samples (structure, i, j)\n",
       "   417      1665   11976938.0   7193.4     10.4          for sample, blockval in zip(block.samples, block.values):\n",
       "   418                                                       \n",
       "   419      1638    2512902.0   1534.1      2.2              A = sample[\"structure\"]\n",
       "   420      1638    1410771.0    861.3      1.2              i = sample[\"center\"]\n",
       "   421      1638    1293170.0    789.5      1.1              j = sample[\"neighbor\"]\n",
       "   422      1638    3398391.0   2074.7      2.9              Tx, Ty, Tz = sample[\"cell_shift_a\"], sample[\"cell_shift_b\"], sample[\"cell_shift_c\"]\n",
       "   423                                           \n",
       "   424      1638     961087.0    586.7      0.8              matrix_T_plus  = reconstructed_matrices_plus[A][Tx, Ty, Tz]\n",
       "   425                                           \n",
       "   426      1638     196065.0    119.7      0.2              if return_negative:\n",
       "   427                                                           matrix_T_minus = reconstructed_matrices_minus[A][Tx, Ty, Tz]\n",
       "   428                                                       # i_start, j_start = atom_blocks_idx[(A, i, j)]\n",
       "   429                                           \n",
       "   430      1638    8690066.0   5305.3      7.5              i_start, j_start = atom_blocks_idx[(A, i, j)]\n",
       "   431      1638     919781.0    561.5      0.8              i_slice = slice(i_start + ioffset, i_start + ioffset + i_end) \n",
       "   432      1638     564887.0    344.9      0.5              j_slice = slice(j_start + joffset, j_start + joffset + j_end)\n",
       "   433                                           \n",
       "   434                                                       # OPT (commented)\n",
       "   435                                                       # values = blockval[:, :, 0].clone()\n",
       "   436                                           \n",
       "   437      1638    1977213.0   1207.1      1.7              if block_type == 1:\n",
       "   438      2430   15481218.0   6370.9     13.4                  matrix_T_plus[\n",
       "   439                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   440                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   441       810     104780.0    129.4      0.1                      i_slice, j_slice\n",
       "   442       810   10444867.0  12894.9      9.0                  ] += blockval[:, :, 0]*ISQRT_2 # OPTvalues\n",
       "   443                                           \n",
       "   444       810     203044.0    250.7      0.2                  if return_negative:\n",
       "   445                                                               matrix_T_minus[\n",
       "   446                                                                   # j_start + ioffset : j_start + ioffset + i_end,\n",
       "   447                                                                   # i_start + joffset : i_start + joffset + j_end,\n",
       "   448                                                                   i_slice, j_slice\n",
       "   449                                                               ] += blockval[:, :, 0]*ISQRT_2 # values # OPT\n",
       "   450                                                                   \n",
       "   451       828     970637.0   1172.3      0.8              elif block_type == -1:\n",
       "   452                                                               \n",
       "   453      2430   14860445.0   6115.4     12.8                  matrix_T_plus[\n",
       "   454                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   455                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   456       810     101617.0    125.5      0.1                      i_slice, j_slice\n",
       "   457       810    4818131.0   5948.3      4.2                  ] += blockval[:, :, 0] # values # OPT\n",
       "   458                                           \n",
       "   459       810     193600.0    239.0      0.2                  if return_negative:\n",
       "   460                                                               matrix_T_minus[\n",
       "   461                                                                   # j_start + ioffset : j_start + ioffset + i_end,\n",
       "   462                                                                   # i_start + joffset : i_start + joffset + j_end,\n",
       "   463                                                                   i_slice, j_slice\n",
       "   464                                                               ] -= blockval[:, :, 0] # values # OPT\n",
       "   465                                           \n",
       "   466                                                       # if block_type == 0 or block_type == 2:\n",
       "   467                                                       else: # bt = 0 or 2\n",
       "   468                                           \n",
       "   469        36     183184.0   5088.4      0.2                  matrix_T_plus[\n",
       "   470                                                               # i_start + ioffset : i_start + ioffset + i_end,\n",
       "   471                                                               # j_start + joffset : j_start + joffset + j_end,\n",
       "   472        36       4280.0    118.9      0.0                      i_slice,\n",
       "   473        18       1381.0     76.7      0.0                      j_slice,\n",
       "   474        18     150222.0   8345.7      0.1                               ] = blockval[:, :, 0] # values # OPT\n",
       "   475                                           \n",
       "   476                                           \n",
       "   477         1        100.0    100.0      0.0      if return_negative:\n",
       "   478                                                   return reconstructed_matrices_plus, reconstructed_matrices_minus\n",
       "   479         1         80.0     80.0      0.0      return reconstructed_matrices_plus"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f blocks_to_matrix blocks_to_matrix(pred, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e8ef9bc1-51a4-40dd-a7ca-2a1ecb24b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef4ab336-14a7-4b7d-a39a-be66aab7e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.pbc_utils import _atom_blocks_idx, _orbs_offsets\n",
    "orbs_tot, orbs_offset = _orbs_offsets(dataset.basis)\n",
    "atom_blocks_idx = _atom_blocks_idx(dataset.structures, orbs_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "058fdda2-81e9-4236-8d20-3b4b6260ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.pbc_utils import blocks_to_matrix, move_cell_shifts_to_keys, OLD_blocks_to_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d299640b-6de4-419a-bdc6-7e6f41bb37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.twocenter_utils import (\n",
    "    _components_idx,\n",
    "    ISQRT_2,\n",
    "    _orbs_offsets,\n",
    "    _atom_blocks_idx,\n",
    ")\n",
    "\n",
    "def moveit(blocks):\n",
    "    if \"cell_shift_a\" not in blocks.keys.names:\n",
    "        assert \"cell_shift_b\" not in blocks.keys.names, \"Weird! keys contain 'cell_shift_b' but not 'cell_shift_a'.\"\n",
    "        assert \"cell_shift_c\" not in blocks.keys.names, \"Weird! keys contain 'cell_shift_c' but not 'cell_shift_a'.\"\n",
    "\n",
    "        assert \"cell_shift_a\" in blocks.sample_names, \"Cell shifts must be in samples.\"\n",
    "        assert \"cell_shift_b\" in blocks.sample_names, \"Cell shifts must be in samples.\"\n",
    "        assert \"cell_shift_c\" in blocks.sample_names, \"Cell shifts must be in samples.\"\n",
    "\n",
    "        if \"L\" in blocks.keys.names:\n",
    "            from mlelec.utils.twocenter_utils import _to_uncoupled_basis\n",
    "            blocks = _to_uncoupled_basis(blocks)\n",
    "        blocks = move_cell_shifts_to_keys(blocks) \n",
    "    return blocks\n",
    "\n",
    "def opt_blocks_to_matrix(blocks, dataset, device=None, return_negative=False):\n",
    "    if device is None:\n",
    "        device = dataset.device\n",
    "\n",
    "    orbs_tot, orbs_offset = _orbs_offsets(dataset.basis)\n",
    "    atom_blocks_idx = _atom_blocks_idx(dataset.structures, orbs_tot)\n",
    "    orbs_mult = {\n",
    "        species: \n",
    "                {tuple(k): v\n",
    "            for k, v in zip(\n",
    "                *np.unique(\n",
    "                    np.asarray(dataset.basis[species])[:, :2],\n",
    "                    axis=0,\n",
    "                    return_counts=True,\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "        for species in dataset.basis\n",
    "    }\n",
    "\n",
    "    reconstructed_matrices_plus = []\n",
    "    reconstructed_matrices_minus = []\n",
    "\n",
    "    # Loop over frames\n",
    "    for A, shifts in enumerate(dataset.realspace_translations):\n",
    "        norbs = np.sum([orbs_tot[ai] for ai in dataset.structures[A].numbers])\n",
    "\n",
    "        reconstructed_matrices_plus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
    "        reconstructed_matrices_minus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
    "\n",
    "    # loops over block types\n",
    "    for key, block in blocks.items():\n",
    "        block_type = key[\"block_type\"]\n",
    "        ai, ni, li = key[\"species_i\"], key[\"n_i\"], key[\"l_i\"]\n",
    "        aj, nj, lj = key[\"species_j\"], key[\"n_j\"], key[\"l_j\"]\n",
    "        \n",
    "        # What's the multiplicity of the orbital type, ex. 2p_x, 2p_y, 2p_z makes the multiplicity \n",
    "        # of a p block = 3\n",
    "        orbs_i = orbs_mult[ai]\n",
    "        orbs_j = orbs_mult[aj]\n",
    "        \n",
    "        # The shape of the block corresponding to the orbital pair\n",
    "        shapes = {\n",
    "            (k1 + k2): (orbs_i[tuple(k1)], orbs_j[tuple(k2)])\n",
    "            for k1 in orbs_i\n",
    "            for k2 in orbs_j\n",
    "        }\n",
    "        # offset of the orbital (ni, li) within a block of atom i\n",
    "        ioffset = orbs_offset[(ai, ni, li)] \n",
    "        # offset of the orbital (nj,lj) within a block of atom j\n",
    "        joffset = orbs_offset[(aj, nj, lj)]\n",
    "\n",
    "        i_end, j_end = shapes[(ni, li, nj, lj)]\n",
    "\n",
    "        # loops over samples (structure, i, j)\n",
    "        for sample, blockval in zip(block.samples, block.values):\n",
    "            \n",
    "            A = sample[\"structure\"]\n",
    "            i = sample[\"center\"]\n",
    "            j = sample[\"neighbor\"]\n",
    "            Tx, Ty, Tz = sample[\"cell_shift_a\"], sample[\"cell_shift_b\"], sample[\"cell_shift_c\"]\n",
    "\n",
    "            matrix_T_plus  = reconstructed_matrices_plus[A][Tx, Ty, Tz]\n",
    "            matrix_T_minus = reconstructed_matrices_minus[A][Tx, Ty, Tz]\n",
    "            i_start, j_start = atom_blocks_idx[(A, i, j)]\n",
    "            values = blockval[:, :, 0].clone()\n",
    "\n",
    "            if block_type == 0 or block_type == 2:\n",
    "\n",
    "                matrix_T_plus[\n",
    "                    i_start + ioffset : i_start + ioffset + i_end,\n",
    "                    j_start + joffset : j_start + joffset + j_end,\n",
    "                             ] = values\n",
    "\n",
    "            if abs(block_type) == 1:\n",
    "                values *= ISQRT_2\n",
    "                if block_type == 1:\n",
    "                    matrix_T_plus[\n",
    "                        i_start + ioffset : i_start + ioffset + i_end,\n",
    "                        j_start + joffset : j_start + joffset + j_end,\n",
    "                    ] += values\n",
    "\n",
    "                    matrix_T_minus[\n",
    "                        j_start + ioffset : j_start + ioffset + i_end,\n",
    "                        i_start + joffset : i_start + joffset + j_end,\n",
    "                    ] += values\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    matrix_T_plus[\n",
    "                        i_start + ioffset : i_start + ioffset + i_end,\n",
    "                        j_start + joffset : j_start + joffset + j_end,\n",
    "                    ] += values\n",
    "\n",
    "                    matrix_T_minus[\n",
    "                        j_start + ioffset : j_start + ioffset + i_end,\n",
    "                        i_start + joffset : i_start + joffset + j_end,\n",
    "                    ] -= values\n",
    "\n",
    "    if return_negative:\n",
    "        return reconstructed_matrices_plus, reconstructed_matrices_minus\n",
    "    return reconstructed_matrices_plus\n",
    "\n",
    "def opt_move_cell_shifts_to_keys(blocks):\n",
    "    \"\"\" Move cell shifts when present in samples, to keys\"\"\"\n",
    "    from metatensor import Labels, TensorBlock, TensorMap\n",
    "\n",
    "    out_blocks = []\n",
    "    out_block_keys = []\n",
    "\n",
    "    sample_names = blocks.sample_names[:-3]\n",
    "    \n",
    "    for key, block in blocks.items():        \n",
    "        translations = np.unique(block.samples.values[:, -3:], axis = 0)\n",
    "        block_view = block.samples.view([\"cell_shift_a\", \"cell_shift_b\", \"cell_shift_c\"]).values\n",
    "        for T in translations:\n",
    "            # idx = np.where(np.all(np.isclose(np.array(block_view),np.array([T[0], T[1], T[2]])), axis = 1))[0]\n",
    "            idx = np.where(np.all(np.isclose(np.array(block_view), T), axis = 1))[0]\n",
    "\n",
    "            if len(idx):\n",
    "                out_block_keys.append(list(key.values)+[T[0], T[1], T[2]])\n",
    "                out_blocks.append(TensorBlock(\n",
    "                        samples = Labels(\n",
    "                            sample_names,\n",
    "                            values = np.asarray(block.samples.values[idx])[:, :-3],\n",
    "                        ),\n",
    "                        values = block.values[idx],\n",
    "                        components = block.components,\n",
    "                        properties = block.properties,\n",
    "                    ))\n",
    "                \n",
    "    return TensorMap(Labels(blocks.keys.names + [\"cell_shift_a\", \"cell_shift_b\", \"cell_shift_c\"], np.asarray(out_block_keys)), out_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a715000-4407-4afd-96db-6e3daca3c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eab86b53-1c3e-4179-b516-edda16a76e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.483411 s\n",
       "File: /home/pegolo/Software/my_mlelec/src/mlelec/utils/pbc_utils.py\n",
       "Function: blocks_to_matrix at line 356\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   356                                           def blocks_to_matrix(blocks, dataset, device=None, return_negative=False):\n",
       "   357         1        481.0    481.0      0.0      if device is None:\n",
       "   358         1       1312.0   1312.0      0.0          device = dataset.device\n",
       "   359                                                   \n",
       "   360         1      74210.0  74210.0      0.0      if \"cell_shift_a\" not in blocks.keys.names:\n",
       "   361         1      18736.0  18736.0      0.0          assert \"cell_shift_b\" not in blocks.keys.names, \"Weird! keys contain 'cell_shift_b' but not 'cell_shift_a'.\"\n",
       "   362         1      13816.0  13816.0      0.0          assert \"cell_shift_c\" not in blocks.keys.names, \"Weird! keys contain 'cell_shift_c' but not 'cell_shift_a'.\"\n",
       "   363                                           \n",
       "   364         1      69972.0  69972.0      0.0          assert \"cell_shift_a\" in blocks.sample_names, \"Cell shifts must be in samples.\"\n",
       "   365         1      51267.0  51267.0      0.0          assert \"cell_shift_b\" in blocks.sample_names, \"Cell shifts must be in samples.\"\n",
       "   366         1      45405.0  45405.0      0.0          assert \"cell_shift_c\" in blocks.sample_names, \"Cell shifts must be in samples.\"\n",
       "   367                                           \n",
       "   368         1      11943.0  11943.0      0.0          if \"L\" in blocks.keys.names:\n",
       "   369                                                       from mlelec.utils.twocenter_utils import _to_uncoupled_basis\n",
       "   370                                                       blocks = _to_uncoupled_basis(blocks)\n",
       "   371         1  332324243.0    3e+08     68.7          blocks = move_cell_shifts_to_keys(blocks)      \n",
       "   372                                           \n",
       "   373         1       7314.0   7314.0      0.0      orbs_tot, orbs_offset = _orbs_offsets(dataset.basis)\n",
       "   374         1      14007.0  14007.0      0.0      atom_blocks_idx = _atom_blocks_idx(dataset.structures, orbs_tot)\n",
       "   375         2     122551.0  61275.5      0.0      orbs_mult = {\n",
       "   376                                                   species: \n",
       "   377                                                           {tuple(k): v\n",
       "   378                                                       for k, v in zip(\n",
       "   379                                                           *np.unique(\n",
       "   380                                                               np.asarray(dataset.basis[species])[:, :2],\n",
       "   381                                                               axis=0,\n",
       "   382                                                               return_counts=True,\n",
       "   383                                                           )\n",
       "   384                                                       )\n",
       "   385                                                   }\n",
       "   386         1        150.0    150.0      0.0          for species in dataset.basis\n",
       "   387                                               }\n",
       "   388                                           \n",
       "   389         1        211.0    211.0      0.0      reconstructed_matrices_plus = []\n",
       "   390         1        130.0    130.0      0.0      reconstructed_matrices_minus = []\n",
       "   391                                           \n",
       "   392                                               # Loop over frames\n",
       "   393         2       1193.0    596.5      0.0      for A, shifts in enumerate(dataset.realspace_translations):\n",
       "   394         1      14458.0  14458.0      0.0          norbs = np.sum([orbs_tot[ai] for ai in dataset.structures[A].numbers])\n",
       "   395                                           \n",
       "   396         1     137249.0 137249.0      0.0          reconstructed_matrices_plus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
       "   397         1     110298.0 110298.0      0.0          reconstructed_matrices_minus.append({T: torch.zeros(norbs, norbs, device = device) for T in shifts})\n",
       "   398                                           \n",
       "   399                                               # loops over block types\n",
       "   400       640   22351762.0  34924.6      4.6      for key, block in blocks.items():\n",
       "   401       639     996488.0   1559.4      0.2          block_type = key[\"block_type\"]\n",
       "   402       639    1329242.0   2080.2      0.3          ai, ni, li = key[\"species_i\"], key[\"n_i\"], key[\"l_i\"]\n",
       "   403       639    1271859.0   1990.4      0.3          aj, nj, lj = key[\"species_j\"], key[\"n_j\"], key[\"l_j\"]\n",
       "   404       639    1297832.0   2031.0      0.3          Tx, Ty, Tz = key[\"cell_shift_a\"], key[\"cell_shift_b\"], key[\"cell_shift_c\"]\n",
       "   405                                                   # What's the multiplicity of the orbital type, ex. 2p_x, 2p_y, 2p_z makes the multiplicity \n",
       "   406                                                   # of a p block = 3\n",
       "   407       639    1854467.0   2902.1      0.4          orbs_i = orbs_mult[ai]\n",
       "   408       639     731303.0   1144.4      0.2          orbs_j = orbs_mult[aj]\n",
       "   409                                                   \n",
       "   410                                                   # The shape of the block corresponding to the orbital pair\n",
       "   411      1278    3686820.0   2884.8      0.8          shapes = {\n",
       "   412                                                       (k1 + k2): (orbs_i[tuple(k1)], orbs_j[tuple(k2)])\n",
       "   413       639      63540.0     99.4      0.0              for k1 in orbs_i\n",
       "   414                                                       for k2 in orbs_j\n",
       "   415                                                   }\n",
       "   416                                                   # offset of the orbital (ni, li) within a block of atom i\n",
       "   417       639    1962094.0   3070.6      0.4          ioffset = orbs_offset[(ai, ni, li)] \n",
       "   418                                                   # offset of the orbital (nj,lj) within a block of atom j\n",
       "   419       639    1722315.0   2695.3      0.4          joffset = orbs_offset[(aj, nj, lj)]\n",
       "   420                                           \n",
       "   421                                                   # j_end = joffset + shapes[(ni, li, nj, lj)][1]\n",
       "   422                                                   # print('jend 1')\n",
       "   423                                           \n",
       "   424                                                   # loops over samples (structure, i, j)\n",
       "   425      2277   30438362.0  13367.7      6.3          for sample, blockval in zip(block.samples, block.values):\n",
       "   426                                                       \n",
       "   427      1638    2255963.0   1377.3      0.5              A = sample[\"structure\"]\n",
       "   428      1638    1271365.0    776.2      0.3              i = sample[\"center\"]\n",
       "   429      1638    1181386.0    721.2      0.2              j = sample[\"neighbor\"]\n",
       "   430                                           \n",
       "   431                                           \n",
       "   432      1638     914240.0    558.1      0.2              matrix_T_plus  = reconstructed_matrices_plus[A][Tx, Ty, Tz]\n",
       "   433      1638     458082.0    279.7      0.1              matrix_T_minus = reconstructed_matrices_minus[A][Tx, Ty, Tz]\n",
       "   434                                                       # beginning of the block corresponding to the atom i-j pair\n",
       "   435      1638    6486021.0   3959.7      1.3              i_start, j_start = atom_blocks_idx[(A, i, j)]\n",
       "   436                                                       \n",
       "   437      1638    1083155.0    661.3      0.2              i_end = shapes[(ni, li, nj, lj)][0]  # orb end\n",
       "   438      1638     703234.0    429.3      0.1              j_end = shapes[(ni, li, nj, lj)][1]  # orb end\n",
       "   439                                           \n",
       "   440                                                       # print()\n",
       "   441                                                       # print((i,j),(ni, li, nj, lj), (i_start + ioffset, i_start + ioffset + i_end), (j_start + joffset, j_start + joffset + j_end))\n",
       "   442                                           \n",
       "   443      1638   26189702.0  15988.8      5.4              values = blockval[:, :, 0].clone().reshape(2 * li + 1, 2 * lj + 1)\n",
       "   444                                           \n",
       "   445                                                       # position of the orbital within this block\n",
       "   446                                           \n",
       "   447      1638    4096057.0   2500.6      0.8              if block_type == 0 or block_type == 2:\n",
       "   448                                           \n",
       "   449        36      91481.0   2541.1      0.0                  matrix_T_plus[\n",
       "   450        36       9545.0    265.1      0.0                      i_start + ioffset : i_start + ioffset + i_end,\n",
       "   451        18       4626.0    257.0      0.0                      j_start + joffset : j_start + joffset + j_end,\n",
       "   452        18       1583.0     87.9      0.0                               ] = values\n",
       "   453                                           \n",
       "   454                                                           # Add the corresponding hermitian part\n",
       "   455                                                           # if (ni, li)!=(nj, lj):\n",
       "   456                                                           #     matrix_T_plus[j_start + joffset : j_start + joffset + j_end, \n",
       "   457                                                           #                 i_start + ioffset : i_start + ioffset + i_end\n",
       "   458                                                           #                 ] = values.T\n",
       "   459                                           \n",
       "   460      1638    2161086.0   1319.3      0.4              if abs(block_type) == 1:\n",
       "   461      1620    6516467.0   4022.5      1.3                  values *= ISQRT_2\n",
       "   462      1620    2184580.0   1348.5      0.5                  if block_type == 1:\n",
       "   463      2430    7192378.0   2959.8      1.5                      matrix_T_plus[\n",
       "   464      1620     386956.0    238.9      0.1                          i_start + ioffset : i_start + ioffset + i_end,\n",
       "   465       810     203233.0    250.9      0.0                          j_start + joffset : j_start + joffset + j_end,\n",
       "   466       810      88611.0    109.4      0.0                      ] += values\n",
       "   467                                           \n",
       "   468                                           \n",
       "   469                                                               # matrix_T_plus[\n",
       "   470                                                               #         j_start + ioffset : j_start + ioffset + i_end,\n",
       "   471                                                               #         i_start + joffset : i_start + joffset + j_end,\n",
       "   472                                                               #     ] += values\n",
       "   473                                                              \n",
       "   474                                           \n",
       "   475      2430    4790044.0   1971.2      1.0                      matrix_T_minus[\n",
       "   476      1620     317541.0    196.0      0.1                          j_start + ioffset : j_start + ioffset + i_end,\n",
       "   477       810     164515.0    203.1      0.0                          i_start + joffset : i_start + joffset + j_end,\n",
       "   478       810      78133.0     96.5      0.0                      ] += values\n",
       "   479                                           \n",
       "   480                                                               # print([Tx,Ty,Tz],i,j, slice(i_start + ioffset, i_start + ioffset + i_end), slice(j_start + joffset, j_start + joffset + j_end))\n",
       "   481                                                           \n",
       "   482                                                               # # Add the corresponding hermitian part\n",
       "   483                                                               # if (ni, li)!= (nj, lj):\n",
       "   484                                           \n",
       "   485                                                               #     # <i \\phi |H| j \\psi> = <j \\psi |H| i \\phi>^\\dagger\n",
       "   486                                                               #     matrix_T_plus[\n",
       "   487                                                               #     j_start + joffset : j_start + joffset + j_end,\n",
       "   488                                                               #     i_start + ioffset : i_start + ioffset + i_end,\n",
       "   489                                                               # ] += values.T\n",
       "   490                                                                   \n",
       "   491                                                               #     matrix_T_plus[\n",
       "   492                                                               #         i_start + joffset : i_start + joffset + j_end,\n",
       "   493                                                               #         j_start + ioffset : j_start + ioffset + i_end,\n",
       "   494                                                               #     ] += values.T\n",
       "   495                                           \n",
       "   496                                                           else:\n",
       "   497                                                               \n",
       "   498      2430    7252417.0   2984.5      1.5                      matrix_T_plus[\n",
       "   499      1620     388653.0    239.9      0.1                          i_start + ioffset : i_start + ioffset + i_end,\n",
       "   500       810     205265.0    253.4      0.0                          j_start + joffset : j_start + joffset + j_end,\n",
       "   501       810      85421.0    105.5      0.0                      ] += values\n",
       "   502                                           \n",
       "   503                                                               # matrix_T_plus[\n",
       "   504                                                               #         j_start + ioffset : j_start + ioffset + i_end,\n",
       "   505                                                               #         i_start + joffset : i_start + joffset + j_end,\n",
       "   506                                                               #     ] -= values\n",
       "   507                                                               \n",
       "   508      2430    5378286.0   2213.3      1.1                      matrix_T_minus[\n",
       "   509      1620     297357.0    183.6      0.1                          j_start + ioffset : j_start + ioffset + i_end,\n",
       "   510       810     166606.0    205.7      0.0                          i_start + joffset : i_start + joffset + j_end,\n",
       "   511       810      82168.0    101.4      0.0                      ] -= values\n",
       "   512                                           \n",
       "   513                                                               # Add the corresponding hermitian part\n",
       "   514                                                               # if (ni, li)!= (nj, lj):\n",
       "   515                                                               #     matrix_T_plus[\n",
       "   516                                                               #         j_start + joffset : j_start + joffset + j_end,\n",
       "   517                                                               #         i_start + ioffset : i_start + ioffset + i_end,\n",
       "   518                                                               #     ] += values.T\n",
       "   519                                           \n",
       "   520                                                               #     matrix_T_plus[\n",
       "   521                                                               #         i_start + joffset : i_start + joffset + j_end,\n",
       "   522                                                               #         j_start + ioffset : j_start + ioffset + i_end,\n",
       "   523                                                               #     ] -= values.T\n",
       "   524                                           \n",
       "   525                                           \n",
       "   526                                           \n",
       "   527         1        141.0    141.0      0.0      if return_negative:\n",
       "   528                                                   return reconstructed_matrices_plus, reconstructed_matrices_minus\n",
       "   529         1         80.0     80.0      0.0      return reconstructed_matrices_plus"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f blocks_to_matrix blocks_to_matrix(target_blocks, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bd3b177-3b22-449a-8c1e-9c20b242fee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0761989 s\n",
       "File: /tmp/ipykernel_3449353/866751707.py\n",
       "Function: opt_blocks_to_matrix at line 23\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "=============================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f opt_blocks_to_matrix opt_blocks_to_matrix(target_blocks, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "03bc42b5-38b7-43e0-8ebc-d5c587d17825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.212813 s\n",
       "File: /tmp/ipykernel_3394842/1718792389.py\n",
       "Function: opt_move_cell_shifts_to_keys at line 130\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   130                                           def opt_move_cell_shifts_to_keys(blocks):\n",
       "   131                                               \"\"\" Move cell shifts when present in samples, to keys\"\"\"\n",
       "   132         1      11372.0  11372.0      0.0      from metatensor import Labels, TensorBlock, TensorMap\n",
       "   133                                           \n",
       "   134         1        321.0    321.0      0.0      out_blocks = []\n",
       "   135         1        200.0    200.0      0.0      out_block_keys = []\n",
       "   136                                           \n",
       "   137         1     236757.0 236757.0      0.1      sample_names = blocks.sample_names[:-3]\n",
       "   138                                               \n",
       "   139        28    1307199.0  46685.7      0.6      for key, block in blocks.items():        \n",
       "   140        27    4287509.0 158796.6      2.0          translations = np.unique(block.samples.values[:, -3:], axis = 0)\n",
       "   141        27    1386442.0  51349.7      0.7          block_view = block.samples.view([\"cell_shift_a\", \"cell_shift_b\", \"cell_shift_c\"]).values\n",
       "   142       666     484805.0    727.9      0.2          for T in translations:\n",
       "   143                                                       # idx = np.where(np.all(np.isclose(np.array(block_view),np.array([T[0], T[1], T[2]])), axis = 1))[0]\n",
       "   144       639   37321091.0  58405.5     17.5              idx = np.where(np.all(np.isclose(np.array(block_view), T), axis = 1))[0]\n",
       "   145                                           \n",
       "   146       639     255413.0    399.7      0.1              if len(idx):\n",
       "   147       639    3108718.0   4865.0      1.5                  out_block_keys.append(list(key.values)+[T[0], T[1], T[2]])\n",
       "   148      1278   40002869.0  31301.1     18.8                  out_blocks.append(TensorBlock(\n",
       "   149      1278   23008876.0  18003.8     10.8                          samples = Labels(\n",
       "   150       639      65788.0    103.0      0.0                              sample_names,\n",
       "   151       639   18318912.0  28668.1      8.6                              values = np.asarray(block.samples.values[idx])[:, :-3],\n",
       "   152                                                                   ),\n",
       "   153       639   20006917.0  31309.7      9.4                          values = block.values[idx],\n",
       "   154       639   28466536.0  44548.6     13.4                          components = block.components,\n",
       "   155       639   14435661.0  22591.0      6.8                          properties = block.properties,\n",
       "   156                                                               ))\n",
       "   157                                                           \n",
       "   158         1   20107375.0    2e+07      9.4      return TensorMap(Labels(blocks.keys.names + [\"cell_shift_a\", \"cell_shift_b\", \"cell_shift_c\"], np.asarray(out_block_keys)), out_blocks)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f opt_move_cell_shifts_to_keys opt_move_cell_shifts_to_keys(target_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7225246b-ab8a-49a3-b054-a56980dc01a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mblocks_to_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mblocks_to_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "blocks_to_matrix(target_blocks, dataset) - blocks_to_matrix(target_blocks, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77739267-16ae-419f-b843-009d5e722465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{(0,\n",
       "   0,\n",
       "   0): tensor([[-8.8181e+01, -2.3805e+01,  1.7539e-03,  5.1804e-03,  4.4494e-03,\n",
       "           -2.1599e-03, -4.2054e+00,  6.9387e+00, -1.1433e-01,  1.2741e-01],\n",
       "          [-2.3805e+01, -1.3864e+01,  3.1209e-02,  7.7723e-02,  1.0866e-01,\n",
       "           -4.2054e+00, -6.2384e+00,  5.5694e+00, -9.7268e-02,  9.4786e-02],\n",
       "          [ 1.7539e-03,  3.1209e-02, -4.7524e+00, -1.2551e-03, -1.3782e-01,\n",
       "           -6.9387e+00, -5.5694e+00,  2.4265e+00, -7.4755e-02,  6.7299e-02],\n",
       "          [ 5.1804e-03,  7.7723e-02, -1.2551e-03, -1.3138e+00, -2.2829e-03,\n",
       "            1.1436e-01,  9.7270e-02, -7.4757e-02, -2.0365e+00, -1.1528e-03],\n",
       "          [ 4.4494e-03,  1.0866e-01, -1.3782e-01, -2.2829e-03, -4.9473e+00,\n",
       "           -1.2743e-01, -9.4767e-02,  6.7300e-02, -1.1528e-03, -2.1046e+00],\n",
       "          [-2.1599e-03, -4.2054e+00, -6.9387e+00,  1.1433e-01, -1.2741e-01,\n",
       "           -8.8181e+01, -2.3805e+01, -1.7539e-03, -5.1804e-03, -4.4494e-03],\n",
       "          [-4.2054e+00, -6.2384e+00, -5.5694e+00,  9.7268e-02, -9.4786e-02,\n",
       "           -2.3805e+01, -1.3864e+01, -3.1209e-02, -7.7723e-02, -1.0866e-01],\n",
       "          [ 6.9387e+00,  5.5694e+00,  2.4265e+00, -7.4755e-02,  6.7299e-02,\n",
       "           -1.7539e-03, -3.1209e-02, -4.7524e+00, -1.2551e-03, -1.3782e-01],\n",
       "          [-1.1436e-01, -9.7270e-02, -7.4757e-02, -2.0365e+00, -1.1528e-03,\n",
       "           -5.1804e-03, -7.7723e-02, -1.2551e-03, -1.3138e+00, -2.2829e-03],\n",
       "          [ 1.2743e-01,  9.4767e-02,  6.7300e-02, -1.1528e-03, -2.1046e+00,\n",
       "           -4.4494e-03, -1.0866e-01, -1.3782e-01, -2.2829e-03, -4.9473e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   1,\n",
       "   0): tensor([[ 4.6194e-05, -2.8143e-01,  5.2780e-01,  2.5633e-05, -3.0602e-01,\n",
       "            1.5939e-05, -9.9127e-04,  3.1811e-03, -3.7922e-05, -1.6729e-03],\n",
       "          [-2.8139e-01, -1.3448e+00,  1.4184e+00,  7.8485e-03, -1.0383e+00,\n",
       "           -1.3285e-03, -9.9280e-02,  1.6691e-01, -8.3091e-04, -5.2370e-02],\n",
       "          [-5.2836e-01, -1.6026e+00,  1.3111e+00,  9.4559e-03, -1.3329e+00,\n",
       "           -3.1797e-03, -1.6685e-01,  2.6652e-01, -2.1517e-03, -8.4503e-02],\n",
       "          [ 2.4091e-05,  7.8692e-03, -9.5202e-03, -3.8986e-01,  5.5048e-03,\n",
       "            4.5636e-05,  8.2854e-04, -2.1516e-03, -3.7629e-03,  8.6139e-04],\n",
       "          [ 3.0579e-01,  7.1803e-01, -7.8256e-01, -5.5403e-03,  1.0805e-01,\n",
       "            1.5760e-03,  5.2384e-02, -8.4504e-02,  8.6142e-04, -8.1549e-06],\n",
       "          [-2.1035e-03, -4.1805e+00,  3.3026e+00,  1.1442e-01, -6.0567e+00,\n",
       "            4.6482e-05, -2.8138e-01,  5.2798e-01, -2.1456e-05, -3.0554e-01],\n",
       "          [-4.1805e+00, -6.2117e+00,  2.6637e+00,  9.7474e-02, -4.8676e+00,\n",
       "           -2.8144e-01, -1.3448e+00,  1.6025e+00, -7.8673e-03, -7.1822e-01],\n",
       "          [-3.3026e+00, -2.6637e+00, -1.0476e+00,  3.6259e-02, -1.9008e+00,\n",
       "           -5.2818e-01, -1.4185e+00,  1.3111e+00, -9.5201e-03, -7.8256e-01],\n",
       "          [-1.1443e-01, -9.7468e-02,  3.6259e-02, -2.0225e+00, -6.6134e-02,\n",
       "           -2.3099e-05, -7.8498e-03,  9.4559e-03, -3.8986e-01, -5.5402e-03],\n",
       "          [ 6.0567e+00,  4.8677e+00, -1.9008e+00, -6.6136e-02,  1.3755e+00,\n",
       "            3.0627e-01,  1.0381e+00, -1.3329e+00,  5.5048e-03,  1.0805e-01]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   2,\n",
       "   0): tensor([[-9.8341e-07,  2.7160e-04, -4.9630e-05, -6.7960e-08,  7.4848e-04,\n",
       "            4.4194e-06, -2.8730e-05,  1.3805e-04,  3.6328e-06, -1.6148e-04],\n",
       "          [ 3.7620e-04, -2.6585e-03,  7.2087e-03,  3.5109e-05, -2.5821e-03,\n",
       "           -1.2701e-04, -5.8537e-04,  8.0757e-04,  1.1941e-04, -6.7137e-05],\n",
       "          [-1.1117e-05, -6.3375e-03,  1.3401e-02,  6.1146e-05, -6.7313e-03,\n",
       "           -1.2990e-04, -8.4263e-04,  8.9654e-04, -1.4870e-04,  3.1443e-04],\n",
       "          [ 1.6142e-06,  3.6139e-05, -7.5791e-05,  2.2911e-03,  2.8651e-05,\n",
       "           -5.2700e-06, -1.1756e-04, -1.4844e-04,  1.0021e-02, -3.8766e-04],\n",
       "          [-7.8935e-04,  4.0205e-03, -9.1669e-03, -5.1054e-05,  3.7435e-03,\n",
       "            1.5619e-04,  1.2832e-04,  3.1493e-04, -3.8755e-04,  2.8734e-04],\n",
       "          [ 1.6018e-05, -1.2893e-03,  2.4259e-03,  3.5474e-05, -2.6252e-03,\n",
       "           -3.3091e-07,  2.7072e-04, -3.8316e-05,  1.1386e-06,  7.6679e-04],\n",
       "          [-1.5798e-03, -9.9086e-02,  1.2631e-01,  8.2035e-04, -1.1943e-01,\n",
       "            3.7722e-04, -2.6586e-03,  6.3420e-03, -3.6950e-05, -4.0867e-03],\n",
       "          [-2.4092e-03, -1.2626e-01,  1.3793e-01,  1.8014e-03, -1.5734e-01,\n",
       "           -1.4755e-06, -7.2003e-03,  1.3399e-02, -7.5922e-05, -9.1670e-03],\n",
       "          [-3.7278e-05, -8.1870e-04,  1.8013e-03, -2.6171e-03, -1.4356e-03,\n",
       "           -6.7115e-07, -3.5518e-05,  6.1210e-05,  2.2930e-03, -5.1207e-05],\n",
       "          [ 2.5126e-03,  1.1940e-01, -1.5734e-01, -1.4358e-03,  1.2573e-01,\n",
       "           -7.7012e-04,  2.5135e-03, -6.7307e-03,  2.8611e-05,  3.7424e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.9332e-06,  2.0113e-04, -2.2306e-04, -1.3533e-06, -3.1161e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.5345e-04,  1.9778e-04,  7.7870e-05, -1.1900e-04, -8.1011e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.5183e-04, -8.8615e-05,  3.1253e-04, -2.2995e-04,  4.1972e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.1443e-06,  1.1602e-04, -2.3045e-04,  8.1965e-03, -3.0132e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.9885e-04,  8.8126e-04,  4.2024e-04, -3.0169e-04,  2.5576e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (0,\n",
       "   -3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.9332e-06,  2.0113e-04,  2.2306e-04,  1.3533e-06,  3.1161e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.5345e-04,  1.9778e-04, -7.7870e-05,  1.1900e-04,  8.1011e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.5183e-04,  8.8615e-05,  3.1253e-04, -2.2995e-04,  4.1972e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.1443e-06, -1.1602e-04, -2.3045e-04,  8.1965e-03, -3.0132e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.9885e-04, -8.8126e-04,  4.2024e-04, -3.0169e-04,  2.5576e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   -2,\n",
       "   0): tensor([[-3.3091e-07,  2.7072e-04,  3.8316e-05, -1.1386e-06, -7.6679e-04,\n",
       "            1.6018e-05, -1.2893e-03, -2.4259e-03, -3.5474e-05,  2.6252e-03],\n",
       "          [ 3.7722e-04, -2.6586e-03, -6.3420e-03,  3.6950e-05,  4.0867e-03,\n",
       "           -1.5798e-03, -9.9086e-02, -1.2631e-01, -8.2035e-04,  1.1943e-01],\n",
       "          [ 1.4755e-06,  7.2003e-03,  1.3399e-02, -7.5922e-05, -9.1670e-03,\n",
       "            2.4092e-03,  1.2626e-01,  1.3793e-01,  1.8014e-03, -1.5734e-01],\n",
       "          [ 6.7115e-07,  3.5518e-05,  6.1210e-05,  2.2930e-03, -5.1207e-05,\n",
       "            3.7278e-05,  8.1870e-04,  1.8013e-03, -2.6171e-03, -1.4356e-03],\n",
       "          [ 7.7012e-04, -2.5135e-03, -6.7307e-03,  2.8611e-05,  3.7424e-03,\n",
       "           -2.5126e-03, -1.1940e-01, -1.5734e-01, -1.4358e-03,  1.2573e-01],\n",
       "          [ 4.4194e-06, -2.8730e-05, -1.3805e-04, -3.6328e-06,  1.6148e-04,\n",
       "           -9.8341e-07,  2.7160e-04,  4.9630e-05,  6.7960e-08, -7.4848e-04],\n",
       "          [-1.2701e-04, -5.8537e-04, -8.0757e-04, -1.1941e-04,  6.7137e-05,\n",
       "            3.7620e-04, -2.6585e-03, -7.2087e-03, -3.5109e-05,  2.5821e-03],\n",
       "          [ 1.2990e-04,  8.4263e-04,  8.9654e-04, -1.4870e-04,  3.1443e-04,\n",
       "            1.1117e-05,  6.3375e-03,  1.3401e-02,  6.1146e-05, -6.7313e-03],\n",
       "          [ 5.2700e-06,  1.1756e-04, -1.4844e-04,  1.0021e-02, -3.8766e-04,\n",
       "           -1.6142e-06, -3.6139e-05, -7.5791e-05,  2.2911e-03,  2.8651e-05],\n",
       "          [-1.5619e-04, -1.2832e-04,  3.1493e-04, -3.8755e-04,  2.8734e-04,\n",
       "            7.8935e-04, -4.0205e-03, -9.1669e-03, -5.1054e-05,  3.7435e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   -1,\n",
       "   0): tensor([[ 4.6482e-05, -2.8138e-01, -5.2798e-01,  2.1456e-05,  3.0554e-01,\n",
       "           -2.1035e-03, -4.1805e+00, -3.3026e+00, -1.1442e-01,  6.0567e+00],\n",
       "          [-2.8144e-01, -1.3448e+00, -1.6025e+00,  7.8673e-03,  7.1822e-01,\n",
       "           -4.1805e+00, -6.2117e+00, -2.6637e+00, -9.7474e-02,  4.8676e+00],\n",
       "          [ 5.2818e-01,  1.4185e+00,  1.3111e+00, -9.5201e-03, -7.8256e-01,\n",
       "            3.3026e+00,  2.6637e+00, -1.0476e+00,  3.6259e-02, -1.9008e+00],\n",
       "          [ 2.3099e-05,  7.8498e-03,  9.4559e-03, -3.8986e-01, -5.5402e-03,\n",
       "            1.1443e-01,  9.7468e-02,  3.6259e-02, -2.0225e+00, -6.6134e-02],\n",
       "          [-3.0627e-01, -1.0381e+00, -1.3329e+00,  5.5048e-03,  1.0805e-01,\n",
       "           -6.0567e+00, -4.8677e+00, -1.9008e+00, -6.6136e-02,  1.3755e+00],\n",
       "          [ 1.5939e-05, -9.9127e-04, -3.1811e-03,  3.7922e-05,  1.6729e-03,\n",
       "            4.6194e-05, -2.8143e-01, -5.2780e-01, -2.5633e-05,  3.0602e-01],\n",
       "          [-1.3285e-03, -9.9280e-02, -1.6691e-01,  8.3091e-04,  5.2370e-02,\n",
       "           -2.8139e-01, -1.3448e+00, -1.4184e+00, -7.8485e-03,  1.0383e+00],\n",
       "          [ 3.1797e-03,  1.6685e-01,  2.6652e-01, -2.1517e-03, -8.4503e-02,\n",
       "            5.2836e-01,  1.6026e+00,  1.3111e+00,  9.4559e-03, -1.3329e+00],\n",
       "          [-4.5636e-05, -8.2854e-04, -2.1516e-03, -3.7629e-03,  8.6139e-04,\n",
       "           -2.4091e-05, -7.8692e-03, -9.5202e-03, -3.8986e-01,  5.5048e-03],\n",
       "          [-1.5760e-03, -5.2384e-02, -8.4504e-02,  8.6142e-04, -8.1549e-06,\n",
       "           -3.0579e-01, -7.1803e-01, -7.8256e-01, -5.5403e-03,  1.0805e-01]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   0,\n",
       "   0): tensor([[ 2.1843e-05, -2.6660e-01, -1.9365e-05,  1.3441e-05,  5.7944e-01,\n",
       "            6.2632e-05, -6.2098e-02,  7.8683e-02, -1.4971e-03,  1.3701e-01],\n",
       "          [-2.6656e-01, -1.3277e+00,  1.8183e-01,  8.0799e-03,  1.7298e+00,\n",
       "           -6.2102e-02, -5.1374e-01,  3.6187e-01, -4.6428e-03,  6.3331e-01],\n",
       "          [ 3.6504e-04,  1.7909e-01, -4.8996e-01, -7.7829e-06, -2.6888e-01,\n",
       "           -7.8694e-02, -3.6186e-01,  3.6985e-02, -4.9833e-03,  4.7751e-01],\n",
       "          [ 3.4070e-05,  8.0527e-03, -7.7829e-06, -3.8284e-01, -1.1315e-02,\n",
       "            1.5072e-03,  4.6971e-03, -4.9839e-03, -8.9361e-03, -8.6664e-03],\n",
       "          [-5.7909e-01, -1.7298e+00,  2.7502e-01,  1.1398e-02,  1.9338e+00,\n",
       "           -1.3702e-01, -6.3332e-01,  4.7751e-01, -8.6655e-03,  6.0053e-01],\n",
       "          [ 6.5386e-05, -7.3635e-02, -9.3019e-02,  1.6122e-03,  1.5923e-01,\n",
       "            2.2137e-05, -2.6664e-01, -6.2903e-04, -3.3967e-05,  5.7951e-01],\n",
       "          [-7.3640e-02, -5.6248e-01, -3.9580e-01,  4.9199e-03,  6.8125e-01,\n",
       "           -2.6652e-01, -1.3277e+00, -1.7897e-01, -8.0496e-03,  1.7300e+00],\n",
       "          [ 9.3029e-02,  3.9580e-01,  3.5066e-02, -5.2958e-03, -5.1374e-01,\n",
       "           -2.4463e-04, -1.8171e-01, -4.8994e-01, -6.8090e-06,  2.7501e-01],\n",
       "          [-1.5984e-03, -4.9078e-03, -5.2954e-03, -2.2839e-02,  8.6944e-03,\n",
       "           -1.2559e-05, -8.0681e-03, -6.8090e-06, -3.8286e-01,  1.1399e-02],\n",
       "          [-1.5923e-01, -6.8125e-01, -5.1374e-01,  8.6950e-03,  6.2604e-01,\n",
       "           -5.7902e-01, -1.7297e+00, -2.6887e-01, -1.1314e-02,  1.9338e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   1,\n",
       "   0): tensor([[ 2.6044e-05, -2.7483e-01,  5.1703e-01,  1.4732e-05,  3.0177e-01,\n",
       "           -1.6102e-05, -4.4003e-03,  8.8133e-03, -5.4799e-05,  3.7755e-03],\n",
       "          [-2.7487e-01, -1.3488e+00,  1.4228e+00,  8.0647e-03,  1.0537e+00,\n",
       "           -4.0914e-03, -9.9232e-02,  1.6207e-01, -7.8773e-04,  5.3398e-02],\n",
       "          [-5.1712e-01, -1.6122e+00,  1.3237e+00,  9.7791e-03,  1.3588e+00,\n",
       "           -8.7598e-03, -1.6211e-01,  2.5377e-01, -2.0944e-03,  8.6594e-02],\n",
       "          [ 3.5285e-05,  8.0631e-03, -9.7127e-03, -3.9399e-01, -5.7271e-03,\n",
       "            6.8641e-05,  7.8457e-04, -2.0943e-03, -1.3155e-03, -8.7634e-04],\n",
       "          [-3.0152e-01, -7.2797e-01,  7.9421e-01,  5.7087e-03,  1.2593e-01,\n",
       "           -3.6578e-03, -5.3453e-02,  8.6593e-02, -8.7634e-04,  2.9005e-03],\n",
       "          [-2.7978e-03, -4.5375e+00,  3.6840e+00,  1.2690e-01,  6.5239e+00,\n",
       "            2.5754e-05, -2.7481e-01,  5.1732e-01, -3.2384e-05,  3.0127e-01],\n",
       "          [-4.5375e+00, -6.5599e+00,  2.8498e+00,  1.0367e-01,  5.0447e+00,\n",
       "           -2.7489e-01, -1.3488e+00,  1.6119e+00, -8.0527e-03,  7.2820e-01],\n",
       "          [-3.6840e+00, -2.8498e+00, -1.0870e+00,  3.9055e-02,  1.9642e+00,\n",
       "           -5.1684e-01, -1.4230e+00,  1.3237e+00, -9.7138e-03,  7.9420e-01],\n",
       "          [-1.2686e-01, -1.0368e-01,  3.9055e-02, -2.1515e+00,  6.9271e-02,\n",
       "           -1.2498e-05, -8.0597e-03,  9.7781e-03, -3.9401e-01,  5.7092e-03],\n",
       "          [-6.5239e+00, -5.0447e+00,  1.9642e+00,  6.9271e-02,  1.2935e+00,\n",
       "           -3.0203e-01, -1.0535e+00,  1.3588e+00, -5.7267e-03,  1.2594e-01]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   2,\n",
       "   0): tensor([[-1.5336e-05,  1.5848e-03, -2.2447e-03,  7.5846e-07, -1.5874e-04,\n",
       "           -3.7801e-06,  6.6904e-04, -8.2426e-04, -4.4096e-06, -4.5443e-04],\n",
       "          [ 1.8012e-03, -2.2029e-02,  4.5203e-02,  1.9650e-04, -6.5600e-04,\n",
       "            7.4476e-04,  9.7797e-04,  4.1169e-05, -2.2342e-04, -1.9799e-04],\n",
       "          [ 2.4265e-03, -4.1893e-02,  8.3021e-02,  5.1850e-04, -1.4172e-03,\n",
       "            8.9213e-04, -8.9904e-05,  1.8912e-03,  4.3526e-05,  1.3392e-05],\n",
       "          [ 1.7063e-06,  1.9772e-04, -5.2575e-04,  4.6567e-03,  9.6614e-06,\n",
       "            1.5277e-05,  2.1988e-04,  4.3294e-05, -1.3850e-02,  3.0084e-05],\n",
       "          [ 1.4793e-04,  4.9966e-04, -9.8457e-04,  1.2087e-05, -7.4668e-03,\n",
       "            4.6058e-04,  2.1092e-04,  1.4510e-05,  3.0081e-05, -1.3837e-03],\n",
       "          [ 6.8304e-05, -8.3345e-02,  2.0573e-01,  1.7575e-03, -1.3665e-03,\n",
       "           -1.5342e-05,  1.6376e-03, -2.3719e-03,  4.0843e-06, -1.6729e-04],\n",
       "          [-8.3339e-02, -5.9732e-01,  8.2796e-01,  5.0916e-03, -3.1183e-03,\n",
       "            1.7483e-03, -2.2029e-02,  4.1847e-02, -1.9525e-04, -4.3235e-04],\n",
       "          [-2.0573e-01, -8.2795e-01,  9.5522e-01,  1.0460e-02, -2.8822e-03,\n",
       "            2.2993e-03, -4.5250e-02,  8.3021e-02, -5.2618e-04, -9.8356e-04],\n",
       "          [-1.7484e-03, -5.0536e-03,  1.0460e-02, -3.2080e-02, -2.3031e-04,\n",
       "            5.5293e-06, -2.0527e-04,  5.1863e-04,  4.6576e-03,  1.2376e-05],\n",
       "          [ 1.3562e-03,  3.1112e-03, -2.8804e-03, -2.3029e-04, -2.7936e-01,\n",
       "            1.3810e-04,  7.2104e-04, -1.4175e-03,  9.9493e-06, -7.4677e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.9811e-06,  2.4974e-04, -8.1754e-04, -2.3347e-05, -9.0218e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 3.1506e-04, -1.3202e-03,  3.4137e-03,  4.4272e-04, -1.5268e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 8.9841e-04, -3.4599e-03,  8.3868e-03,  5.9030e-05, -2.5432e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.1627e-05, -4.4998e-04,  5.9323e-05, -2.5399e-02,  1.0307e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 8.0561e-04,  1.5857e-03, -2.5428e-03,  1.0315e-04,  2.6014e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (1,\n",
       "   -3,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (1,\n",
       "   -2,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.2462e-06, -1.0981e-03, -7.3055e-04, -2.2624e-06,  1.0623e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.1585e-03, -2.2463e-03, -6.8719e-04, -1.9485e-04,  1.1650e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            7.7867e-04,  6.5797e-04,  5.2029e-04,  2.5882e-05, -8.0738e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.5630e-05,  1.8869e-04,  2.5807e-05, -1.5724e-02,  4.8975e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.1124e-03, -1.1319e-03, -8.0630e-04,  4.8852e-05,  1.5950e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   -1,\n",
       "   0): tensor([[ 4.7353e-06, -1.0871e-03, -1.1728e-03, -1.7076e-06,  1.7902e-03,\n",
       "           -1.1712e-05,  2.0167e-03, -1.6567e-04,  4.1828e-05, -4.1170e-04],\n",
       "          [-9.4483e-04, -2.3729e-02, -2.3636e-02,  1.8231e-04,  4.0504e-02,\n",
       "            2.1326e-03, -8.5126e-02, -3.3245e-02, -6.3975e-04,  1.5213e-01],\n",
       "          [ 1.1251e-03,  2.1985e-02,  1.5250e-02, -2.3808e-04, -3.8381e-02,\n",
       "            1.8114e-04,  3.3224e-02, -9.0698e-03,  2.2446e-04, -6.1543e-02],\n",
       "          [ 2.9217e-06,  1.9230e-04,  2.6799e-04,  5.2029e-03, -4.5341e-04,\n",
       "           -2.8166e-05,  6.3297e-04,  2.2450e-04,  4.3953e-03, -2.0804e-03],\n",
       "          [-1.6897e-03, -3.7788e-02, -3.8543e-02,  4.3262e-04,  5.7691e-02,\n",
       "            2.1762e-04, -1.5213e-01, -6.1545e-02, -2.0802e-03,  2.5020e-01],\n",
       "          [ 4.3835e-07, -5.5200e-04, -4.9079e-05, -1.2448e-05,  2.5522e-04,\n",
       "            4.7666e-06, -1.0378e-03, -1.1206e-03,  8.3608e-07,  1.6847e-03],\n",
       "          [-4.9365e-04, -2.3214e-03, -2.8997e-03,  4.6006e-04,  2.5745e-03,\n",
       "           -9.9404e-04, -2.3729e-02, -2.1996e-02, -1.9422e-04,  3.7833e-02],\n",
       "          [ 8.9631e-05,  2.9129e-03,  4.9983e-03,  8.0853e-05, -2.9465e-03,\n",
       "            1.1785e-03,  2.3627e-02,  1.5249e-02,  2.6830e-04, -3.8544e-02],\n",
       "          [ 7.1065e-06, -4.6761e-04,  8.0677e-05, -2.5578e-02,  1.1154e-04,\n",
       "            3.4901e-06, -1.8247e-04, -2.3792e-04,  5.2051e-03,  4.3322e-04],\n",
       "          [-2.0038e-04, -2.5743e-03, -2.9467e-03,  1.1136e-04,  4.9381e-03,\n",
       "           -1.7946e-03, -4.0458e-02, -3.8382e-02, -4.5308e-04,  5.7690e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   0,\n",
       "   0): tensor([[-1.6037e-06,  5.0604e-04, -6.4093e-05, -3.0959e-06, -7.6800e-04,\n",
       "           -6.3866e-06,  1.2188e-03,  8.4296e-04,  2.8367e-05, -2.0486e-03],\n",
       "          [ 5.8713e-04, -1.0943e-03, -7.3182e-04,  5.3632e-05,  4.3473e-03,\n",
       "            1.2219e-03,  6.4552e-04,  7.5582e-04, -4.4962e-04,  1.0742e-03],\n",
       "          [-4.4552e-05, -1.0109e-03,  9.8637e-04, -3.1479e-06,  1.1947e-03,\n",
       "           -8.1327e-04, -8.5753e-04,  1.7737e-03, -8.4627e-05,  2.1955e-03],\n",
       "          [-6.0317e-07,  5.5090e-05, -3.1479e-06,  1.3891e-03, -7.1962e-05,\n",
       "           -3.7235e-05,  4.4407e-04, -8.4397e-05, -2.6809e-02,  2.5890e-05],\n",
       "          [ 8.8866e-04, -4.2813e-03, -1.0961e-03,  6.8593e-05,  1.2988e-02,\n",
       "            2.1083e-03, -1.0607e-03,  2.1968e-03,  2.5068e-05,  6.3824e-03],\n",
       "          [-5.7492e-06,  3.7615e-04,  7.1394e-04, -1.7238e-05, -3.9939e-05,\n",
       "           -9.7820e-07,  5.0199e-04, -8.7196e-05, -2.2327e-06, -7.5954e-04],\n",
       "          [ 3.0442e-04, -1.1232e-03, -9.0294e-05,  4.6033e-04,  3.2081e-03,\n",
       "            5.9130e-04, -1.0944e-03,  1.0235e-03, -5.3272e-05,  4.2349e-03],\n",
       "          [-7.4727e-04,  1.5432e-05,  1.4909e-03, -9.8099e-05, -1.2752e-03,\n",
       "           -6.7640e-05,  7.4453e-04,  9.8711e-04, -2.7345e-06, -1.0953e-03],\n",
       "          [ 1.3824e-05, -4.6217e-04, -9.8219e-05, -2.5469e-02, -1.0292e-05,\n",
       "            2.8627e-06, -5.7955e-05, -2.7345e-06,  1.3893e-03,  6.9166e-05],\n",
       "          [ 2.2467e-05, -3.2132e-03, -1.2744e-03, -1.0717e-05,  8.4032e-03,\n",
       "            8.9527e-04, -4.3891e-03,  1.1939e-03, -7.2732e-05,  1.2987e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   1,\n",
       "   0): tensor([[ 5.8008e-06, -1.0907e-03,  7.6837e-04,  1.0743e-06,  1.3349e-03,\n",
       "            4.4700e-06, -1.2844e-03,  1.0199e-04,  5.7150e-06,  2.4768e-03],\n",
       "          [-1.4092e-03, -2.4652e-02,  2.1583e-02,  2.5304e-04,  3.8320e-02,\n",
       "           -1.3263e-03, -3.2714e-03,  3.1224e-03, -4.6925e-04,  4.0576e-03],\n",
       "          [-8.5628e-04, -2.3150e-02,  1.5252e-02,  2.9229e-04,  3.7230e-02,\n",
       "           -1.8787e-04, -3.0372e-03,  3.5606e-03,  9.2174e-05,  2.3593e-03],\n",
       "          [ 5.1851e-06,  2.5485e-04, -3.1318e-04,  7.2380e-03, -5.4756e-04,\n",
       "           -1.5285e-05,  4.6525e-04,  9.2789e-05, -2.7700e-02, -9.9479e-05],\n",
       "          [-1.4209e-03, -4.1066e-02,  3.7169e-02,  5.1531e-04,  5.9432e-02,\n",
       "           -2.5063e-03, -4.0831e-03,  2.3585e-03, -1.0012e-04,  5.3674e-03],\n",
       "          [-2.8170e-06,  4.5176e-03, -1.0146e-03, -1.6589e-05, -4.4579e-03,\n",
       "            5.8249e-06, -1.1364e-03,  8.2429e-04,  2.3495e-06,  1.4356e-03],\n",
       "          [ 4.5133e-03, -9.0080e-02,  3.4728e-02,  7.7726e-04,  1.6300e-01,\n",
       "           -1.3636e-03, -2.4652e-02,  2.3198e-02, -2.6399e-04,  4.1039e-02],\n",
       "          [ 9.8901e-04, -3.4750e-02, -8.7308e-03,  3.2708e-04,  6.8559e-02,\n",
       "           -8.0156e-04, -2.1537e-02,  1.5250e-02, -3.1359e-04,  3.7171e-02],\n",
       "          [ 2.9934e-05, -7.7862e-04,  3.2711e-04,  7.9375e-04,  2.2377e-03,\n",
       "            8.1854e-06, -2.5235e-04,  2.9233e-04,  7.2410e-03,  5.1567e-04],\n",
       "          [ 4.2320e-03, -1.6294e-01,  6.8558e-02,  2.2374e-03,  2.6753e-01,\n",
       "           -1.3195e-03, -3.8345e-02,  3.7232e-02, -5.4799e-04,  5.9431e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   2,\n",
       "   0): tensor([[ 6.1313e-06, -2.9545e-04,  8.9947e-04, -1.9532e-06, -2.7188e-04,\n",
       "           -6.0839e-06, -4.5597e-04,  3.8320e-04,  9.6357e-06,  9.7489e-05],\n",
       "          [-4.7790e-04, -3.8579e-03,  7.9057e-03,  4.0331e-05,  3.1809e-03,\n",
       "           -4.3798e-04, -6.4307e-04,  6.2127e-04,  1.3995e-04, -2.0161e-04],\n",
       "          [-9.8886e-04, -6.9509e-03,  1.2637e-02,  6.9344e-05,  5.6499e-03,\n",
       "           -3.9600e-04, -5.4069e-04,  2.1191e-03, -2.0466e-04,  4.2209e-04],\n",
       "          [ 1.3974e-06,  3.7839e-05, -6.2102e-05,  2.0956e-03, -4.9249e-05,\n",
       "           -1.7925e-05, -1.4199e-04, -2.0532e-04,  7.5634e-03,  4.6256e-04],\n",
       "          [ 1.4235e-04, -4.5471e-03,  8.0034e-03,  2.7870e-05,  4.5050e-03,\n",
       "           -9.3796e-05,  2.3115e-04,  4.2261e-04,  4.6285e-04, -1.3502e-03],\n",
       "          [-1.1879e-05, -7.2473e-03,  1.0828e-02,  1.3535e-04,  9.9073e-03,\n",
       "            5.4840e-06, -2.9778e-04,  9.1624e-04, -1.9933e-06, -2.8497e-04],\n",
       "          [-7.0370e-03, -1.1154e-01,  1.3757e-01,  9.6138e-04,  1.2724e-01,\n",
       "           -4.7571e-04, -3.8579e-03,  6.9232e-03, -4.2172e-05,  4.6189e-03],\n",
       "          [-1.0754e-02, -1.3761e-01,  1.4396e-01,  1.8838e-03,  1.6541e-01,\n",
       "           -9.7042e-04, -7.9373e-03,  1.2638e-02, -6.2984e-05,  8.0041e-03],\n",
       "          [-1.1486e-04, -9.6703e-04,  1.8837e-03, -5.8169e-03,  1.5859e-03,\n",
       "            2.1076e-06, -3.9987e-05,  6.9832e-05,  2.0963e-03,  2.8738e-05],\n",
       "          [-9.7426e-03, -1.2733e-01,  1.6540e-01,  1.5860e-03,  1.2989e-01,\n",
       "            1.3017e-04, -3.1116e-03,  5.6518e-03, -4.9185e-05,  4.5041e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.9790e-07, -5.2765e-04,  5.1688e-04, -1.3316e-05,  1.4629e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-5.3991e-04, -2.6230e-03,  4.8198e-03,  4.5172e-04,  2.0587e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-6.0860e-04, -4.7766e-03,  8.2340e-03,  6.1279e-05,  2.9245e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.4394e-05, -4.5498e-04,  6.1765e-05, -2.6113e-02, -1.0628e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.4013e-03, -2.1092e-03,  2.9239e-03, -1.0640e-04,  2.9195e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (2,\n",
       "   5,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (2,\n",
       "   -2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (2,\n",
       "   -1,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            2.8238e-06,  6.0014e-04, -2.0648e-04, -2.1398e-06, -8.1973e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            6.6041e-04,  3.6008e-04, -6.4725e-04,  1.4959e-04,  5.1406e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            2.2121e-04,  6.9195e-04,  6.4794e-05,  5.3438e-04, -1.2324e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -7.9818e-06, -1.4765e-04,  5.3442e-04,  7.7453e-03,  3.9051e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            8.0805e-04, -5.3215e-04, -1.2320e-03,  3.9393e-05,  8.3739e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (3,\n",
       "   0,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (3,\n",
       "   1,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 3.3333e-06, -1.9802e-04, -2.2793e-04,  2.8080e-05,  3.7486e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.5953e-04, -8.8881e-04,  2.8811e-04, -1.1626e-04,  1.0786e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.4994e-04, -2.5384e-04,  4.2040e-04,  3.3134e-04,  2.5333e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.2311e-05,  1.1083e-04,  3.3132e-04,  7.0509e-03, -1.7968e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-4.4057e-04, -1.0902e-03,  2.5359e-04, -1.7786e-05,  8.0176e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (3,\n",
       "   2,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.0193e-06,  2.3745e-05, -1.5080e-04, -2.1839e-05,  3.6174e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.3274e-05, -2.4525e-04,  3.3108e-04,  2.0630e-04,  7.4484e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.5273e-04, -3.3972e-04,  1.8337e-05, -3.0218e-05,  9.6066e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 9.1898e-06, -1.9609e-04, -3.0058e-05, -1.3129e-02, -7.3118e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.3642e-05, -7.3189e-04,  9.6221e-04, -7.3388e-05,  1.0227e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (3,\n",
       "   3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.2104e-06,  1.5001e-04, -1.5575e-04,  9.4042e-06, -5.6043e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.7035e-04,  4.1734e-04, -4.2488e-04, -1.0940e-04, -1.1501e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.8499e-04,  4.5967e-04,  9.6238e-04, -1.6101e-04,  1.4797e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.2663e-06,  1.0701e-04, -1.6108e-04,  5.9379e-03,  2.2119e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 5.9092e-04,  1.4760e-04,  1.4831e-04,  2.2124e-04,  1.2639e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (3,\n",
       "   4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (3,\n",
       "   5,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (3,\n",
       "   -2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (3,\n",
       "   -1,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   0,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (4,\n",
       "   1,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (4,\n",
       "   2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (4,\n",
       "   3,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   -3,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   -2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   -1,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   0,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   1,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   -5,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   -3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -7.2104e-06,  1.5001e-04,  1.5575e-04, -9.4042e-06,  5.6043e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.7035e-04,  4.1734e-04,  4.2488e-04,  1.0940e-04,  1.1501e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.8499e-04, -4.5967e-04,  9.6238e-04, -1.6101e-04,  1.4797e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            7.2663e-06, -1.0701e-04, -1.6108e-04,  5.9379e-03,  2.2119e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -5.9092e-04, -1.4760e-04,  1.4831e-04,  2.2124e-04,  1.2639e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-3,\n",
       "   -2,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.0193e-06,  2.3745e-05,  1.5080e-04,  2.1839e-05, -3.6174e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.3274e-05, -2.4525e-04, -3.3108e-04, -2.0630e-04, -7.4484e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.5273e-04,  3.3972e-04,  1.8337e-05, -3.0218e-05,  9.6066e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -9.1898e-06,  1.9609e-04, -3.0058e-05, -1.3129e-02, -7.3118e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            2.3642e-05,  7.3189e-04,  9.6221e-04, -7.3388e-05,  1.0227e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-3,\n",
       "   -1,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            3.3333e-06, -1.9802e-04,  2.2793e-04, -2.8080e-05, -3.7486e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.5953e-04, -8.8881e-04, -2.8811e-04,  1.1626e-04, -1.0786e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.4994e-04,  2.5384e-04,  4.2040e-04,  3.3134e-04,  2.5333e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            2.2311e-05, -1.1083e-04,  3.3132e-04,  7.0509e-03, -1.7968e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            4.4057e-04,  1.0902e-03,  2.5359e-04, -1.7786e-05,  8.0176e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   0,\n",
       "   0): tensor([[-9.7820e-07,  5.0199e-04,  8.7196e-05,  2.2327e-06,  7.5954e-04,\n",
       "           -5.7492e-06,  3.7615e-04, -7.1394e-04,  1.7238e-05,  3.9939e-05],\n",
       "          [ 5.9130e-04, -1.0944e-03, -1.0235e-03,  5.3272e-05, -4.2349e-03,\n",
       "            3.0442e-04, -1.1232e-03,  9.0294e-05, -4.6033e-04, -3.2081e-03],\n",
       "          [ 6.7640e-05, -7.4453e-04,  9.8711e-04, -2.7345e-06, -1.0953e-03,\n",
       "            7.4727e-04, -1.5432e-05,  1.4909e-03, -9.8099e-05, -1.2752e-03],\n",
       "          [-2.8627e-06,  5.7955e-05, -2.7345e-06,  1.3893e-03,  6.9166e-05,\n",
       "           -1.3824e-05,  4.6217e-04, -9.8219e-05, -2.5469e-02, -1.0292e-05],\n",
       "          [-8.9527e-04,  4.3891e-03,  1.1939e-03, -7.2732e-05,  1.2987e-02,\n",
       "           -2.2467e-05,  3.2132e-03, -1.2744e-03, -1.0717e-05,  8.4032e-03],\n",
       "          [-6.3866e-06,  1.2188e-03, -8.4296e-04, -2.8367e-05,  2.0486e-03,\n",
       "           -1.6037e-06,  5.0604e-04,  6.4093e-05,  3.0959e-06,  7.6800e-04],\n",
       "          [ 1.2219e-03,  6.4552e-04, -7.5582e-04,  4.4962e-04, -1.0742e-03,\n",
       "            5.8713e-04, -1.0943e-03,  7.3182e-04, -5.3632e-05, -4.3473e-03],\n",
       "          [ 8.1327e-04,  8.5753e-04,  1.7737e-03, -8.4627e-05,  2.1955e-03,\n",
       "            4.4552e-05,  1.0109e-03,  9.8637e-04, -3.1479e-06,  1.1947e-03],\n",
       "          [ 3.7235e-05, -4.4407e-04, -8.4397e-05, -2.6809e-02,  2.5890e-05,\n",
       "            6.0317e-07, -5.5090e-05, -3.1479e-06,  1.3891e-03, -7.1962e-05],\n",
       "          [-2.1083e-03,  1.0607e-03,  2.1968e-03,  2.5068e-05,  6.3824e-03,\n",
       "           -8.8866e-04,  4.2813e-03, -1.0961e-03,  6.8593e-05,  1.2988e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   1,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.8238e-06,  6.0014e-04,  2.0648e-04,  2.1398e-06,  8.1973e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6041e-04,  3.6008e-04,  6.4725e-04, -1.4959e-04, -5.1406e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.2121e-04, -6.9195e-04,  6.4794e-05,  5.3438e-04, -1.2324e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 7.9818e-06,  1.4765e-04,  5.3442e-04,  7.7453e-03,  3.9051e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-8.0805e-04,  5.3215e-04, -1.2320e-03,  3.9393e-05,  8.3739e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-2,\n",
       "   -5,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-2,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-2,\n",
       "   -3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            6.9790e-07, -5.2765e-04, -5.1688e-04,  1.3316e-05, -1.4629e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -5.3991e-04, -2.6230e-03, -4.8198e-03, -4.5172e-04, -2.0587e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            6.0860e-04,  4.7766e-03,  8.2340e-03,  6.1279e-05,  2.9245e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.4394e-05,  4.5498e-04,  6.1765e-05, -2.6113e-02, -1.0628e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.4013e-03,  2.1092e-03,  2.9239e-03, -1.0640e-04,  2.9195e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   -2,\n",
       "   0): tensor([[ 5.4840e-06, -2.9778e-04, -9.1624e-04,  1.9933e-06,  2.8497e-04,\n",
       "           -1.1879e-05, -7.2473e-03, -1.0828e-02, -1.3535e-04, -9.9073e-03],\n",
       "          [-4.7571e-04, -3.8579e-03, -6.9232e-03,  4.2172e-05, -4.6189e-03,\n",
       "           -7.0370e-03, -1.1154e-01, -1.3757e-01, -9.6138e-04, -1.2724e-01],\n",
       "          [ 9.7042e-04,  7.9373e-03,  1.2638e-02, -6.2984e-05,  8.0041e-03,\n",
       "            1.0754e-02,  1.3761e-01,  1.4396e-01,  1.8838e-03,  1.6541e-01],\n",
       "          [-2.1076e-06,  3.9987e-05,  6.9832e-05,  2.0963e-03,  2.8738e-05,\n",
       "            1.1486e-04,  9.6703e-04,  1.8837e-03, -5.8169e-03,  1.5859e-03],\n",
       "          [-1.3017e-04,  3.1116e-03,  5.6518e-03, -4.9185e-05,  4.5041e-03,\n",
       "            9.7426e-03,  1.2733e-01,  1.6540e-01,  1.5860e-03,  1.2989e-01],\n",
       "          [-6.0839e-06, -4.5597e-04, -3.8320e-04, -9.6357e-06, -9.7489e-05,\n",
       "            6.1313e-06, -2.9545e-04, -8.9947e-04,  1.9532e-06,  2.7188e-04],\n",
       "          [-4.3798e-04, -6.4307e-04, -6.2127e-04, -1.3995e-04,  2.0161e-04,\n",
       "           -4.7790e-04, -3.8579e-03, -7.9057e-03, -4.0331e-05, -3.1809e-03],\n",
       "          [ 3.9600e-04,  5.4069e-04,  2.1191e-03, -2.0466e-04,  4.2209e-04,\n",
       "            9.8886e-04,  6.9509e-03,  1.2637e-02,  6.9344e-05,  5.6499e-03],\n",
       "          [ 1.7925e-05,  1.4199e-04, -2.0532e-04,  7.5634e-03,  4.6256e-04,\n",
       "           -1.3974e-06, -3.7839e-05, -6.2102e-05,  2.0956e-03, -4.9249e-05],\n",
       "          [ 9.3796e-05, -2.3115e-04,  4.2261e-04,  4.6285e-04, -1.3502e-03,\n",
       "           -1.4235e-04,  4.5471e-03,  8.0034e-03,  2.7870e-05,  4.5050e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   -1,\n",
       "   0): tensor([[ 5.8249e-06, -1.1364e-03, -8.2429e-04, -2.3495e-06, -1.4356e-03,\n",
       "           -2.8170e-06,  4.5176e-03,  1.0146e-03,  1.6589e-05,  4.4579e-03],\n",
       "          [-1.3636e-03, -2.4652e-02, -2.3198e-02,  2.6399e-04, -4.1039e-02,\n",
       "            4.5133e-03, -9.0080e-02, -3.4728e-02, -7.7726e-04, -1.6300e-01],\n",
       "          [ 8.0156e-04,  2.1537e-02,  1.5250e-02, -3.1359e-04,  3.7171e-02,\n",
       "           -9.8901e-04,  3.4750e-02, -8.7308e-03,  3.2708e-04,  6.8559e-02],\n",
       "          [-8.1854e-06,  2.5235e-04,  2.9233e-04,  7.2410e-03,  5.1567e-04,\n",
       "           -2.9934e-05,  7.7862e-04,  3.2711e-04,  7.9375e-04,  2.2377e-03],\n",
       "          [ 1.3195e-03,  3.8345e-02,  3.7232e-02, -5.4799e-04,  5.9431e-02,\n",
       "           -4.2320e-03,  1.6294e-01,  6.8558e-02,  2.2374e-03,  2.6753e-01],\n",
       "          [ 4.4700e-06, -1.2844e-03, -1.0199e-04, -5.7150e-06, -2.4768e-03,\n",
       "            5.8008e-06, -1.0907e-03, -7.6837e-04, -1.0743e-06, -1.3349e-03],\n",
       "          [-1.3263e-03, -3.2714e-03, -3.1224e-03,  4.6925e-04, -4.0576e-03,\n",
       "           -1.4092e-03, -2.4652e-02, -2.1583e-02, -2.5304e-04, -3.8320e-02],\n",
       "          [ 1.8787e-04,  3.0372e-03,  3.5606e-03,  9.2174e-05,  2.3593e-03,\n",
       "            8.5628e-04,  2.3150e-02,  1.5252e-02,  2.9229e-04,  3.7230e-02],\n",
       "          [ 1.5285e-05, -4.6525e-04,  9.2789e-05, -2.7700e-02, -9.9479e-05,\n",
       "           -5.1851e-06, -2.5485e-04, -3.1318e-04,  7.2380e-03, -5.4756e-04],\n",
       "          [ 2.5063e-03,  4.0831e-03,  2.3585e-03, -1.0012e-04,  5.3674e-03,\n",
       "            1.4209e-03,  4.1066e-02,  3.7169e-02,  5.1531e-04,  5.9432e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   0,\n",
       "   0): tensor([[ 2.2137e-05, -2.6664e-01,  6.2903e-04,  3.3967e-05, -5.7951e-01,\n",
       "            6.5386e-05, -7.3635e-02,  9.3019e-02, -1.6122e-03, -1.5923e-01],\n",
       "          [-2.6652e-01, -1.3277e+00,  1.7897e-01,  8.0496e-03, -1.7300e+00,\n",
       "           -7.3640e-02, -5.6248e-01,  3.9580e-01, -4.9199e-03, -6.8125e-01],\n",
       "          [ 2.4463e-04,  1.8171e-01, -4.8994e-01, -6.8090e-06,  2.7501e-01,\n",
       "           -9.3029e-02, -3.9580e-01,  3.5066e-02, -5.2958e-03, -5.1374e-01],\n",
       "          [ 1.2559e-05,  8.0681e-03, -6.8090e-06, -3.8286e-01,  1.1399e-02,\n",
       "            1.5984e-03,  4.9078e-03, -5.2954e-03, -2.2839e-02,  8.6944e-03],\n",
       "          [ 5.7902e-01,  1.7297e+00, -2.6887e-01, -1.1314e-02,  1.9338e+00,\n",
       "            1.5923e-01,  6.8125e-01, -5.1374e-01,  8.6950e-03,  6.2604e-01],\n",
       "          [ 6.2632e-05, -6.2098e-02, -7.8683e-02,  1.4971e-03, -1.3701e-01,\n",
       "            2.1843e-05, -2.6660e-01,  1.9365e-05, -1.3441e-05, -5.7944e-01],\n",
       "          [-6.2102e-02, -5.1374e-01, -3.6187e-01,  4.6428e-03, -6.3331e-01,\n",
       "           -2.6656e-01, -1.3277e+00, -1.8183e-01, -8.0799e-03, -1.7298e+00],\n",
       "          [ 7.8694e-02,  3.6186e-01,  3.6985e-02, -4.9833e-03,  4.7751e-01,\n",
       "           -3.6504e-04, -1.7909e-01, -4.8996e-01, -7.7829e-06, -2.6888e-01],\n",
       "          [-1.5072e-03, -4.6971e-03, -4.9839e-03, -8.9361e-03, -8.6664e-03,\n",
       "           -3.4070e-05, -8.0527e-03, -7.7829e-06, -3.8284e-01, -1.1315e-02],\n",
       "          [ 1.3702e-01,  6.3332e-01,  4.7751e-01, -8.6655e-03,  6.0053e-01,\n",
       "            5.7909e-01,  1.7298e+00,  2.7502e-01,  1.1398e-02,  1.9338e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   1,\n",
       "   0): tensor([[ 4.7666e-06, -1.0378e-03,  1.1206e-03, -8.3608e-07, -1.6847e-03,\n",
       "            4.3835e-07, -5.5200e-04,  4.9079e-05,  1.2448e-05, -2.5522e-04],\n",
       "          [-9.9404e-04, -2.3729e-02,  2.1996e-02,  1.9422e-04, -3.7833e-02,\n",
       "           -4.9365e-04, -2.3214e-03,  2.8997e-03, -4.6006e-04, -2.5745e-03],\n",
       "          [-1.1785e-03, -2.3627e-02,  1.5249e-02,  2.6830e-04, -3.8544e-02,\n",
       "           -8.9631e-05, -2.9129e-03,  4.9983e-03,  8.0853e-05, -2.9465e-03],\n",
       "          [-3.4901e-06,  1.8247e-04, -2.3792e-04,  5.2051e-03,  4.3322e-04,\n",
       "           -7.1065e-06,  4.6761e-04,  8.0677e-05, -2.5578e-02,  1.1154e-04],\n",
       "          [ 1.7946e-03,  4.0458e-02, -3.8382e-02, -4.5308e-04,  5.7690e-02,\n",
       "            2.0038e-04,  2.5743e-03, -2.9467e-03,  1.1136e-04,  4.9381e-03],\n",
       "          [-1.1712e-05,  2.0167e-03,  1.6567e-04, -4.1828e-05,  4.1170e-04,\n",
       "            4.7353e-06, -1.0871e-03,  1.1728e-03,  1.7076e-06, -1.7902e-03],\n",
       "          [ 2.1326e-03, -8.5126e-02,  3.3245e-02,  6.3975e-04, -1.5213e-01,\n",
       "           -9.4483e-04, -2.3729e-02,  2.3636e-02, -1.8231e-04, -4.0504e-02],\n",
       "          [-1.8114e-04, -3.3224e-02, -9.0698e-03,  2.2446e-04, -6.1543e-02,\n",
       "           -1.1251e-03, -2.1985e-02,  1.5250e-02, -2.3808e-04, -3.8381e-02],\n",
       "          [ 2.8166e-05, -6.3297e-04,  2.2450e-04,  4.3953e-03, -2.0804e-03,\n",
       "           -2.9217e-06, -1.9230e-04,  2.6799e-04,  5.2029e-03, -4.5341e-04],\n",
       "          [-2.1762e-04,  1.5213e-01, -6.1545e-02, -2.0802e-03,  2.5020e-01,\n",
       "            1.6897e-03,  3.7788e-02, -3.8543e-02,  4.3262e-04,  5.7691e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   2,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.2462e-06, -1.0981e-03,  7.3055e-04,  2.2624e-06, -1.0623e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.1585e-03, -2.2463e-03,  6.8719e-04,  1.9485e-04, -1.1650e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.7867e-04, -6.5797e-04,  5.2029e-04,  2.5882e-05, -8.0738e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.5630e-05, -1.8869e-04,  2.5807e-05, -1.5724e-02,  4.8975e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.1124e-03,  1.1319e-03, -8.0630e-04,  4.8852e-05,  1.5950e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   3,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-1,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-1,\n",
       "   -3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.9811e-06,  2.4974e-04,  8.1754e-04,  2.3347e-05,  9.0218e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            3.1506e-04, -1.3202e-03, -3.4137e-03, -4.4272e-04,  1.5268e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -8.9841e-04,  3.4599e-03,  8.3868e-03,  5.9030e-05, -2.5432e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.1627e-05,  4.4998e-04,  5.9323e-05, -2.5399e-02,  1.0307e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -8.0561e-04, -1.5857e-03, -2.5428e-03,  1.0315e-04,  2.6014e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   -2,\n",
       "   0): tensor([[-1.5342e-05,  1.6376e-03,  2.3719e-03, -4.0843e-06,  1.6729e-04,\n",
       "            6.8304e-05, -8.3345e-02, -2.0573e-01, -1.7575e-03,  1.3665e-03],\n",
       "          [ 1.7483e-03, -2.2029e-02, -4.1847e-02,  1.9525e-04,  4.3235e-04,\n",
       "           -8.3339e-02, -5.9732e-01, -8.2796e-01, -5.0916e-03,  3.1183e-03],\n",
       "          [-2.2993e-03,  4.5250e-02,  8.3021e-02, -5.2618e-04, -9.8356e-04,\n",
       "            2.0573e-01,  8.2795e-01,  9.5522e-01,  1.0460e-02, -2.8822e-03],\n",
       "          [-5.5293e-06,  2.0527e-04,  5.1863e-04,  4.6576e-03,  1.2376e-05,\n",
       "            1.7484e-03,  5.0536e-03,  1.0460e-02, -3.2080e-02, -2.3031e-04],\n",
       "          [-1.3810e-04, -7.2104e-04, -1.4175e-03,  9.9493e-06, -7.4677e-03,\n",
       "           -1.3562e-03, -3.1112e-03, -2.8804e-03, -2.3029e-04, -2.7936e-01],\n",
       "          [-3.7801e-06,  6.6904e-04,  8.2426e-04,  4.4096e-06,  4.5443e-04,\n",
       "           -1.5336e-05,  1.5848e-03,  2.2447e-03, -7.5846e-07,  1.5874e-04],\n",
       "          [ 7.4476e-04,  9.7797e-04, -4.1169e-05,  2.2342e-04,  1.9799e-04,\n",
       "            1.8012e-03, -2.2029e-02, -4.5203e-02, -1.9650e-04,  6.5600e-04],\n",
       "          [-8.9213e-04,  8.9904e-05,  1.8912e-03,  4.3526e-05,  1.3392e-05,\n",
       "           -2.4265e-03,  4.1893e-02,  8.3021e-02,  5.1850e-04, -1.4172e-03],\n",
       "          [-1.5277e-05, -2.1988e-04,  4.3294e-05, -1.3850e-02,  3.0084e-05,\n",
       "           -1.7063e-06, -1.9772e-04, -5.2575e-04,  4.6567e-03,  9.6614e-06],\n",
       "          [-4.6058e-04, -2.1092e-04,  1.4510e-05,  3.0081e-05, -1.3837e-03,\n",
       "           -1.4793e-04, -4.9966e-04, -9.8457e-04,  1.2087e-05, -7.4668e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   -1,\n",
       "   0): tensor([[ 2.5754e-05, -2.7481e-01, -5.1732e-01,  3.2384e-05, -3.0127e-01,\n",
       "           -2.7978e-03, -4.5375e+00, -3.6840e+00, -1.2690e-01, -6.5239e+00],\n",
       "          [-2.7489e-01, -1.3488e+00, -1.6119e+00,  8.0527e-03, -7.2820e-01,\n",
       "           -4.5375e+00, -6.5599e+00, -2.8498e+00, -1.0367e-01, -5.0447e+00],\n",
       "          [ 5.1684e-01,  1.4230e+00,  1.3237e+00, -9.7138e-03,  7.9420e-01,\n",
       "            3.6840e+00,  2.8498e+00, -1.0870e+00,  3.9055e-02,  1.9642e+00],\n",
       "          [ 1.2498e-05,  8.0597e-03,  9.7781e-03, -3.9401e-01,  5.7092e-03,\n",
       "            1.2686e-01,  1.0368e-01,  3.9055e-02, -2.1515e+00,  6.9271e-02],\n",
       "          [ 3.0203e-01,  1.0535e+00,  1.3588e+00, -5.7267e-03,  1.2594e-01,\n",
       "            6.5239e+00,  5.0447e+00,  1.9642e+00,  6.9271e-02,  1.2935e+00],\n",
       "          [-1.6102e-05, -4.4003e-03, -8.8133e-03,  5.4799e-05, -3.7755e-03,\n",
       "            2.6044e-05, -2.7483e-01, -5.1703e-01, -1.4732e-05, -3.0177e-01],\n",
       "          [-4.0914e-03, -9.9232e-02, -1.6207e-01,  7.8773e-04, -5.3398e-02,\n",
       "           -2.7487e-01, -1.3488e+00, -1.4228e+00, -8.0647e-03, -1.0537e+00],\n",
       "          [ 8.7598e-03,  1.6211e-01,  2.5377e-01, -2.0944e-03,  8.6594e-02,\n",
       "            5.1712e-01,  1.6122e+00,  1.3237e+00,  9.7791e-03,  1.3588e+00],\n",
       "          [-6.8641e-05, -7.8457e-04, -2.0943e-03, -1.3155e-03, -8.7634e-04,\n",
       "           -3.5285e-05, -8.0631e-03, -9.7127e-03, -3.9399e-01, -5.7271e-03],\n",
       "          [ 3.6578e-03,  5.3453e-02,  8.6593e-02, -8.7634e-04,  2.9005e-03,\n",
       "            3.0152e-01,  7.2797e-01,  7.9421e-01,  5.7087e-03,  1.2593e-01]],\n",
       "         grad_fn=<CopySlices>)}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_to_matrix(pred, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "87b27d3d-e47c-4aa0-bcff-03cd46785a39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{(0,\n",
       "   0,\n",
       "   0): tensor([[-8.8181e+01, -2.3805e+01,  1.7539e-03,  5.1804e-03,  4.4494e-03,\n",
       "           -2.1599e-03, -4.2054e+00,  6.9387e+00, -1.1433e-01,  1.2741e-01],\n",
       "          [-2.3805e+01, -1.3864e+01,  3.1209e-02,  7.7723e-02,  1.0866e-01,\n",
       "           -4.2054e+00, -6.2384e+00,  5.5694e+00, -9.7268e-02,  9.4786e-02],\n",
       "          [ 1.7539e-03,  3.1209e-02, -4.7524e+00, -1.2551e-03, -1.3782e-01,\n",
       "           -6.9387e+00, -5.5694e+00,  2.4265e+00, -7.4755e-02,  6.7299e-02],\n",
       "          [ 5.1804e-03,  7.7723e-02, -1.2551e-03, -1.3138e+00, -2.2829e-03,\n",
       "            1.1436e-01,  9.7270e-02, -7.4757e-02, -2.0365e+00, -1.1528e-03],\n",
       "          [ 4.4494e-03,  1.0866e-01, -1.3782e-01, -2.2829e-03, -4.9473e+00,\n",
       "           -1.2743e-01, -9.4767e-02,  6.7300e-02, -1.1528e-03, -2.1046e+00],\n",
       "          [-2.1599e-03, -4.2054e+00, -6.9387e+00,  1.1433e-01, -1.2741e-01,\n",
       "           -8.8181e+01, -2.3805e+01, -1.7539e-03, -5.1804e-03, -4.4494e-03],\n",
       "          [-4.2054e+00, -6.2384e+00, -5.5694e+00,  9.7268e-02, -9.4786e-02,\n",
       "           -2.3805e+01, -1.3864e+01, -3.1209e-02, -7.7723e-02, -1.0866e-01],\n",
       "          [ 6.9387e+00,  5.5694e+00,  2.4265e+00, -7.4755e-02,  6.7299e-02,\n",
       "           -1.7539e-03, -3.1209e-02, -4.7524e+00, -1.2551e-03, -1.3782e-01],\n",
       "          [-1.1436e-01, -9.7270e-02, -7.4757e-02, -2.0365e+00, -1.1528e-03,\n",
       "           -5.1804e-03, -7.7723e-02, -1.2551e-03, -1.3138e+00, -2.2829e-03],\n",
       "          [ 1.2743e-01,  9.4767e-02,  6.7300e-02, -1.1528e-03, -2.1046e+00,\n",
       "           -4.4494e-03, -1.0866e-01, -1.3782e-01, -2.2829e-03, -4.9473e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   1,\n",
       "   0): tensor([[ 4.6194e-05, -2.8143e-01,  5.2780e-01,  2.5633e-05, -3.0602e-01,\n",
       "            1.5939e-05, -9.9127e-04,  3.1811e-03, -3.7922e-05, -1.6729e-03],\n",
       "          [-2.8139e-01, -1.3448e+00,  1.4184e+00,  7.8485e-03, -1.0383e+00,\n",
       "           -1.3285e-03, -9.9280e-02,  1.6691e-01, -8.3091e-04, -5.2370e-02],\n",
       "          [-5.2836e-01, -1.6026e+00,  1.3111e+00,  9.4559e-03, -1.3329e+00,\n",
       "           -3.1797e-03, -1.6685e-01,  2.6652e-01, -2.1517e-03, -8.4503e-02],\n",
       "          [ 2.4091e-05,  7.8692e-03, -9.5202e-03, -3.8986e-01,  5.5048e-03,\n",
       "            4.5636e-05,  8.2854e-04, -2.1516e-03, -3.7629e-03,  8.6139e-04],\n",
       "          [ 3.0579e-01,  7.1803e-01, -7.8256e-01, -5.5403e-03,  1.0805e-01,\n",
       "            1.5760e-03,  5.2384e-02, -8.4504e-02,  8.6142e-04, -8.1549e-06],\n",
       "          [-2.1035e-03, -4.1805e+00,  3.3026e+00,  1.1442e-01, -6.0567e+00,\n",
       "            4.6482e-05, -2.8138e-01,  5.2798e-01, -2.1456e-05, -3.0554e-01],\n",
       "          [-4.1805e+00, -6.2117e+00,  2.6637e+00,  9.7474e-02, -4.8676e+00,\n",
       "           -2.8144e-01, -1.3448e+00,  1.6025e+00, -7.8673e-03, -7.1822e-01],\n",
       "          [-3.3026e+00, -2.6637e+00, -1.0476e+00,  3.6259e-02, -1.9008e+00,\n",
       "           -5.2818e-01, -1.4185e+00,  1.3111e+00, -9.5201e-03, -7.8256e-01],\n",
       "          [-1.1443e-01, -9.7468e-02,  3.6259e-02, -2.0225e+00, -6.6134e-02,\n",
       "           -2.3099e-05, -7.8498e-03,  9.4559e-03, -3.8986e-01, -5.5402e-03],\n",
       "          [ 6.0567e+00,  4.8677e+00, -1.9008e+00, -6.6136e-02,  1.3755e+00,\n",
       "            3.0627e-01,  1.0381e+00, -1.3329e+00,  5.5048e-03,  1.0805e-01]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   2,\n",
       "   0): tensor([[-9.8341e-07,  2.7160e-04, -4.9630e-05, -6.7960e-08,  7.4848e-04,\n",
       "            4.4194e-06, -2.8730e-05,  1.3805e-04,  3.6328e-06, -1.6148e-04],\n",
       "          [ 3.7620e-04, -2.6585e-03,  7.2087e-03,  3.5109e-05, -2.5821e-03,\n",
       "           -1.2701e-04, -5.8537e-04,  8.0757e-04,  1.1941e-04, -6.7137e-05],\n",
       "          [-1.1117e-05, -6.3375e-03,  1.3401e-02,  6.1146e-05, -6.7313e-03,\n",
       "           -1.2990e-04, -8.4263e-04,  8.9654e-04, -1.4870e-04,  3.1443e-04],\n",
       "          [ 1.6142e-06,  3.6139e-05, -7.5791e-05,  2.2911e-03,  2.8651e-05,\n",
       "           -5.2700e-06, -1.1756e-04, -1.4844e-04,  1.0021e-02, -3.8766e-04],\n",
       "          [-7.8935e-04,  4.0205e-03, -9.1669e-03, -5.1054e-05,  3.7435e-03,\n",
       "            1.5619e-04,  1.2832e-04,  3.1493e-04, -3.8755e-04,  2.8734e-04],\n",
       "          [ 1.6018e-05, -1.2893e-03,  2.4259e-03,  3.5474e-05, -2.6252e-03,\n",
       "           -3.3091e-07,  2.7072e-04, -3.8316e-05,  1.1386e-06,  7.6679e-04],\n",
       "          [-1.5798e-03, -9.9086e-02,  1.2631e-01,  8.2035e-04, -1.1943e-01,\n",
       "            3.7722e-04, -2.6586e-03,  6.3420e-03, -3.6950e-05, -4.0867e-03],\n",
       "          [-2.4092e-03, -1.2626e-01,  1.3793e-01,  1.8014e-03, -1.5734e-01,\n",
       "           -1.4755e-06, -7.2003e-03,  1.3399e-02, -7.5922e-05, -9.1670e-03],\n",
       "          [-3.7278e-05, -8.1870e-04,  1.8013e-03, -2.6171e-03, -1.4356e-03,\n",
       "           -6.7115e-07, -3.5518e-05,  6.1210e-05,  2.2930e-03, -5.1207e-05],\n",
       "          [ 2.5126e-03,  1.1940e-01, -1.5734e-01, -1.4358e-03,  1.2573e-01,\n",
       "           -7.7012e-04,  2.5135e-03, -6.7307e-03,  2.8611e-05,  3.7424e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.9332e-06,  2.0113e-04, -2.2306e-04, -1.3533e-06, -3.1161e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.5345e-04,  1.9778e-04,  7.7870e-05, -1.1900e-04, -8.1011e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.5183e-04, -8.8615e-05,  3.1253e-04, -2.2995e-04,  4.1972e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.1443e-06,  1.1602e-04, -2.3045e-04,  8.1965e-03, -3.0132e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.9885e-04,  8.8126e-04,  4.2024e-04, -3.0169e-04,  2.5576e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (0,\n",
       "   -3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.9332e-06,  2.0113e-04,  2.2306e-04,  1.3533e-06,  3.1161e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.5345e-04,  1.9778e-04, -7.7870e-05,  1.1900e-04,  8.1011e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.5183e-04,  8.8615e-05,  3.1253e-04, -2.2995e-04,  4.1972e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.1443e-06, -1.1602e-04, -2.3045e-04,  8.1965e-03, -3.0132e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.9885e-04, -8.8126e-04,  4.2024e-04, -3.0169e-04,  2.5576e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   -2,\n",
       "   0): tensor([[-3.3091e-07,  2.7072e-04,  3.8316e-05, -1.1386e-06, -7.6679e-04,\n",
       "            1.6018e-05, -1.2893e-03, -2.4259e-03, -3.5474e-05,  2.6252e-03],\n",
       "          [ 3.7722e-04, -2.6586e-03, -6.3420e-03,  3.6950e-05,  4.0867e-03,\n",
       "           -1.5798e-03, -9.9086e-02, -1.2631e-01, -8.2035e-04,  1.1943e-01],\n",
       "          [ 1.4755e-06,  7.2003e-03,  1.3399e-02, -7.5922e-05, -9.1670e-03,\n",
       "            2.4092e-03,  1.2626e-01,  1.3793e-01,  1.8014e-03, -1.5734e-01],\n",
       "          [ 6.7115e-07,  3.5518e-05,  6.1210e-05,  2.2930e-03, -5.1207e-05,\n",
       "            3.7278e-05,  8.1870e-04,  1.8013e-03, -2.6171e-03, -1.4356e-03],\n",
       "          [ 7.7012e-04, -2.5135e-03, -6.7307e-03,  2.8611e-05,  3.7424e-03,\n",
       "           -2.5126e-03, -1.1940e-01, -1.5734e-01, -1.4358e-03,  1.2573e-01],\n",
       "          [ 4.4194e-06, -2.8730e-05, -1.3805e-04, -3.6328e-06,  1.6148e-04,\n",
       "           -9.8341e-07,  2.7160e-04,  4.9630e-05,  6.7960e-08, -7.4848e-04],\n",
       "          [-1.2701e-04, -5.8537e-04, -8.0757e-04, -1.1941e-04,  6.7137e-05,\n",
       "            3.7620e-04, -2.6585e-03, -7.2087e-03, -3.5109e-05,  2.5821e-03],\n",
       "          [ 1.2990e-04,  8.4263e-04,  8.9654e-04, -1.4870e-04,  3.1443e-04,\n",
       "            1.1117e-05,  6.3375e-03,  1.3401e-02,  6.1146e-05, -6.7313e-03],\n",
       "          [ 5.2700e-06,  1.1756e-04, -1.4844e-04,  1.0021e-02, -3.8766e-04,\n",
       "           -1.6142e-06, -3.6139e-05, -7.5791e-05,  2.2911e-03,  2.8651e-05],\n",
       "          [-1.5619e-04, -1.2832e-04,  3.1493e-04, -3.8755e-04,  2.8734e-04,\n",
       "            7.8935e-04, -4.0205e-03, -9.1669e-03, -5.1054e-05,  3.7435e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (0,\n",
       "   -1,\n",
       "   0): tensor([[ 4.6482e-05, -2.8138e-01, -5.2798e-01,  2.1456e-05,  3.0554e-01,\n",
       "           -2.1035e-03, -4.1805e+00, -3.3026e+00, -1.1442e-01,  6.0567e+00],\n",
       "          [-2.8144e-01, -1.3448e+00, -1.6025e+00,  7.8673e-03,  7.1822e-01,\n",
       "           -4.1805e+00, -6.2117e+00, -2.6637e+00, -9.7474e-02,  4.8676e+00],\n",
       "          [ 5.2818e-01,  1.4185e+00,  1.3111e+00, -9.5201e-03, -7.8256e-01,\n",
       "            3.3026e+00,  2.6637e+00, -1.0476e+00,  3.6259e-02, -1.9008e+00],\n",
       "          [ 2.3099e-05,  7.8498e-03,  9.4559e-03, -3.8986e-01, -5.5402e-03,\n",
       "            1.1443e-01,  9.7468e-02,  3.6259e-02, -2.0225e+00, -6.6134e-02],\n",
       "          [-3.0627e-01, -1.0381e+00, -1.3329e+00,  5.5048e-03,  1.0805e-01,\n",
       "           -6.0567e+00, -4.8677e+00, -1.9008e+00, -6.6136e-02,  1.3755e+00],\n",
       "          [ 1.5939e-05, -9.9127e-04, -3.1811e-03,  3.7922e-05,  1.6729e-03,\n",
       "            4.6194e-05, -2.8143e-01, -5.2780e-01, -2.5633e-05,  3.0602e-01],\n",
       "          [-1.3285e-03, -9.9280e-02, -1.6691e-01,  8.3091e-04,  5.2370e-02,\n",
       "           -2.8139e-01, -1.3448e+00, -1.4184e+00, -7.8485e-03,  1.0383e+00],\n",
       "          [ 3.1797e-03,  1.6685e-01,  2.6652e-01, -2.1517e-03, -8.4503e-02,\n",
       "            5.2836e-01,  1.6026e+00,  1.3111e+00,  9.4559e-03, -1.3329e+00],\n",
       "          [-4.5636e-05, -8.2854e-04, -2.1516e-03, -3.7629e-03,  8.6139e-04,\n",
       "           -2.4091e-05, -7.8692e-03, -9.5202e-03, -3.8986e-01,  5.5048e-03],\n",
       "          [-1.5760e-03, -5.2384e-02, -8.4504e-02,  8.6142e-04, -8.1549e-06,\n",
       "           -3.0579e-01, -7.1803e-01, -7.8256e-01, -5.5403e-03,  1.0805e-01]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   0,\n",
       "   0): tensor([[ 2.1843e-05, -2.6660e-01, -1.9365e-05,  1.3441e-05,  5.7944e-01,\n",
       "            6.2632e-05, -6.2098e-02,  7.8683e-02, -1.4971e-03,  1.3701e-01],\n",
       "          [-2.6656e-01, -1.3277e+00,  1.8183e-01,  8.0799e-03,  1.7298e+00,\n",
       "           -6.2102e-02, -5.1374e-01,  3.6187e-01, -4.6428e-03,  6.3331e-01],\n",
       "          [ 3.6504e-04,  1.7909e-01, -4.8996e-01, -7.7829e-06, -2.6888e-01,\n",
       "           -7.8694e-02, -3.6186e-01,  3.6985e-02, -4.9833e-03,  4.7751e-01],\n",
       "          [ 3.4070e-05,  8.0527e-03, -7.7829e-06, -3.8284e-01, -1.1315e-02,\n",
       "            1.5072e-03,  4.6971e-03, -4.9839e-03, -8.9361e-03, -8.6664e-03],\n",
       "          [-5.7909e-01, -1.7298e+00,  2.7502e-01,  1.1398e-02,  1.9338e+00,\n",
       "           -1.3702e-01, -6.3332e-01,  4.7751e-01, -8.6655e-03,  6.0053e-01],\n",
       "          [ 6.5386e-05, -7.3635e-02, -9.3019e-02,  1.6122e-03,  1.5923e-01,\n",
       "            2.2137e-05, -2.6664e-01, -6.2903e-04, -3.3967e-05,  5.7951e-01],\n",
       "          [-7.3640e-02, -5.6248e-01, -3.9580e-01,  4.9199e-03,  6.8125e-01,\n",
       "           -2.6652e-01, -1.3277e+00, -1.7897e-01, -8.0496e-03,  1.7300e+00],\n",
       "          [ 9.3029e-02,  3.9580e-01,  3.5066e-02, -5.2958e-03, -5.1374e-01,\n",
       "           -2.4463e-04, -1.8171e-01, -4.8994e-01, -6.8090e-06,  2.7501e-01],\n",
       "          [-1.5984e-03, -4.9078e-03, -5.2954e-03, -2.2839e-02,  8.6944e-03,\n",
       "           -1.2559e-05, -8.0681e-03, -6.8090e-06, -3.8286e-01,  1.1399e-02],\n",
       "          [-1.5923e-01, -6.8125e-01, -5.1374e-01,  8.6950e-03,  6.2604e-01,\n",
       "           -5.7902e-01, -1.7297e+00, -2.6887e-01, -1.1314e-02,  1.9338e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   1,\n",
       "   0): tensor([[ 2.6044e-05, -2.7483e-01,  5.1703e-01,  1.4732e-05,  3.0177e-01,\n",
       "           -1.6102e-05, -4.4003e-03,  8.8133e-03, -5.4799e-05,  3.7755e-03],\n",
       "          [-2.7487e-01, -1.3488e+00,  1.4228e+00,  8.0647e-03,  1.0537e+00,\n",
       "           -4.0914e-03, -9.9232e-02,  1.6207e-01, -7.8773e-04,  5.3398e-02],\n",
       "          [-5.1712e-01, -1.6122e+00,  1.3237e+00,  9.7791e-03,  1.3588e+00,\n",
       "           -8.7598e-03, -1.6211e-01,  2.5377e-01, -2.0944e-03,  8.6594e-02],\n",
       "          [ 3.5285e-05,  8.0631e-03, -9.7127e-03, -3.9399e-01, -5.7271e-03,\n",
       "            6.8641e-05,  7.8457e-04, -2.0943e-03, -1.3155e-03, -8.7634e-04],\n",
       "          [-3.0152e-01, -7.2797e-01,  7.9421e-01,  5.7087e-03,  1.2593e-01,\n",
       "           -3.6578e-03, -5.3453e-02,  8.6593e-02, -8.7634e-04,  2.9005e-03],\n",
       "          [-2.7978e-03, -4.5375e+00,  3.6840e+00,  1.2690e-01,  6.5239e+00,\n",
       "            2.5754e-05, -2.7481e-01,  5.1732e-01, -3.2384e-05,  3.0127e-01],\n",
       "          [-4.5375e+00, -6.5599e+00,  2.8498e+00,  1.0367e-01,  5.0447e+00,\n",
       "           -2.7489e-01, -1.3488e+00,  1.6119e+00, -8.0527e-03,  7.2820e-01],\n",
       "          [-3.6840e+00, -2.8498e+00, -1.0870e+00,  3.9055e-02,  1.9642e+00,\n",
       "           -5.1684e-01, -1.4230e+00,  1.3237e+00, -9.7138e-03,  7.9420e-01],\n",
       "          [-1.2686e-01, -1.0368e-01,  3.9055e-02, -2.1515e+00,  6.9271e-02,\n",
       "           -1.2498e-05, -8.0597e-03,  9.7781e-03, -3.9401e-01,  5.7092e-03],\n",
       "          [-6.5239e+00, -5.0447e+00,  1.9642e+00,  6.9271e-02,  1.2935e+00,\n",
       "           -3.0203e-01, -1.0535e+00,  1.3588e+00, -5.7267e-03,  1.2594e-01]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   2,\n",
       "   0): tensor([[-1.5336e-05,  1.5848e-03, -2.2447e-03,  7.5846e-07, -1.5874e-04,\n",
       "           -3.7801e-06,  6.6904e-04, -8.2426e-04, -4.4096e-06, -4.5443e-04],\n",
       "          [ 1.8012e-03, -2.2029e-02,  4.5203e-02,  1.9650e-04, -6.5600e-04,\n",
       "            7.4476e-04,  9.7797e-04,  4.1169e-05, -2.2342e-04, -1.9799e-04],\n",
       "          [ 2.4265e-03, -4.1893e-02,  8.3021e-02,  5.1850e-04, -1.4172e-03,\n",
       "            8.9213e-04, -8.9904e-05,  1.8912e-03,  4.3526e-05,  1.3392e-05],\n",
       "          [ 1.7063e-06,  1.9772e-04, -5.2575e-04,  4.6567e-03,  9.6614e-06,\n",
       "            1.5277e-05,  2.1988e-04,  4.3294e-05, -1.3850e-02,  3.0084e-05],\n",
       "          [ 1.4793e-04,  4.9966e-04, -9.8457e-04,  1.2087e-05, -7.4668e-03,\n",
       "            4.6058e-04,  2.1092e-04,  1.4510e-05,  3.0081e-05, -1.3837e-03],\n",
       "          [ 6.8304e-05, -8.3345e-02,  2.0573e-01,  1.7575e-03, -1.3665e-03,\n",
       "           -1.5342e-05,  1.6376e-03, -2.3719e-03,  4.0843e-06, -1.6729e-04],\n",
       "          [-8.3339e-02, -5.9732e-01,  8.2796e-01,  5.0916e-03, -3.1183e-03,\n",
       "            1.7483e-03, -2.2029e-02,  4.1847e-02, -1.9525e-04, -4.3235e-04],\n",
       "          [-2.0573e-01, -8.2795e-01,  9.5522e-01,  1.0460e-02, -2.8822e-03,\n",
       "            2.2993e-03, -4.5250e-02,  8.3021e-02, -5.2618e-04, -9.8356e-04],\n",
       "          [-1.7484e-03, -5.0536e-03,  1.0460e-02, -3.2080e-02, -2.3031e-04,\n",
       "            5.5293e-06, -2.0527e-04,  5.1863e-04,  4.6576e-03,  1.2376e-05],\n",
       "          [ 1.3562e-03,  3.1112e-03, -2.8804e-03, -2.3029e-04, -2.7936e-01,\n",
       "            1.3810e-04,  7.2104e-04, -1.4175e-03,  9.9493e-06, -7.4677e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.9811e-06,  2.4974e-04, -8.1754e-04, -2.3347e-05, -9.0218e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 3.1506e-04, -1.3202e-03,  3.4137e-03,  4.4272e-04, -1.5268e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 8.9841e-04, -3.4599e-03,  8.3868e-03,  5.9030e-05, -2.5432e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.1627e-05, -4.4998e-04,  5.9323e-05, -2.5399e-02,  1.0307e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 8.0561e-04,  1.5857e-03, -2.5428e-03,  1.0315e-04,  2.6014e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (1,\n",
       "   -3,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (1,\n",
       "   -2,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.2462e-06, -1.0981e-03, -7.3055e-04, -2.2624e-06,  1.0623e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.1585e-03, -2.2463e-03, -6.8719e-04, -1.9485e-04,  1.1650e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            7.7867e-04,  6.5797e-04,  5.2029e-04,  2.5882e-05, -8.0738e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.5630e-05,  1.8869e-04,  2.5807e-05, -1.5724e-02,  4.8975e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.1124e-03, -1.1319e-03, -8.0630e-04,  4.8852e-05,  1.5950e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (1,\n",
       "   -1,\n",
       "   0): tensor([[ 4.7353e-06, -1.0871e-03, -1.1728e-03, -1.7076e-06,  1.7902e-03,\n",
       "           -1.1712e-05,  2.0167e-03, -1.6567e-04,  4.1828e-05, -4.1170e-04],\n",
       "          [-9.4483e-04, -2.3729e-02, -2.3636e-02,  1.8231e-04,  4.0504e-02,\n",
       "            2.1326e-03, -8.5126e-02, -3.3245e-02, -6.3975e-04,  1.5213e-01],\n",
       "          [ 1.1251e-03,  2.1985e-02,  1.5250e-02, -2.3808e-04, -3.8381e-02,\n",
       "            1.8114e-04,  3.3224e-02, -9.0698e-03,  2.2446e-04, -6.1543e-02],\n",
       "          [ 2.9217e-06,  1.9230e-04,  2.6799e-04,  5.2029e-03, -4.5341e-04,\n",
       "           -2.8166e-05,  6.3297e-04,  2.2450e-04,  4.3953e-03, -2.0804e-03],\n",
       "          [-1.6897e-03, -3.7788e-02, -3.8543e-02,  4.3262e-04,  5.7691e-02,\n",
       "            2.1762e-04, -1.5213e-01, -6.1545e-02, -2.0802e-03,  2.5020e-01],\n",
       "          [ 4.3835e-07, -5.5200e-04, -4.9079e-05, -1.2448e-05,  2.5522e-04,\n",
       "            4.7666e-06, -1.0378e-03, -1.1206e-03,  8.3608e-07,  1.6847e-03],\n",
       "          [-4.9365e-04, -2.3214e-03, -2.8997e-03,  4.6006e-04,  2.5745e-03,\n",
       "           -9.9404e-04, -2.3729e-02, -2.1996e-02, -1.9422e-04,  3.7833e-02],\n",
       "          [ 8.9631e-05,  2.9129e-03,  4.9983e-03,  8.0853e-05, -2.9465e-03,\n",
       "            1.1785e-03,  2.3627e-02,  1.5249e-02,  2.6830e-04, -3.8544e-02],\n",
       "          [ 7.1065e-06, -4.6761e-04,  8.0677e-05, -2.5578e-02,  1.1154e-04,\n",
       "            3.4901e-06, -1.8247e-04, -2.3792e-04,  5.2051e-03,  4.3322e-04],\n",
       "          [-2.0038e-04, -2.5743e-03, -2.9467e-03,  1.1136e-04,  4.9381e-03,\n",
       "           -1.7946e-03, -4.0458e-02, -3.8382e-02, -4.5308e-04,  5.7690e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   0,\n",
       "   0): tensor([[-1.6037e-06,  5.0604e-04, -6.4093e-05, -3.0959e-06, -7.6800e-04,\n",
       "           -6.3866e-06,  1.2188e-03,  8.4296e-04,  2.8367e-05, -2.0486e-03],\n",
       "          [ 5.8713e-04, -1.0943e-03, -7.3182e-04,  5.3632e-05,  4.3473e-03,\n",
       "            1.2219e-03,  6.4552e-04,  7.5582e-04, -4.4962e-04,  1.0742e-03],\n",
       "          [-4.4552e-05, -1.0109e-03,  9.8637e-04, -3.1479e-06,  1.1947e-03,\n",
       "           -8.1327e-04, -8.5753e-04,  1.7737e-03, -8.4627e-05,  2.1955e-03],\n",
       "          [-6.0317e-07,  5.5090e-05, -3.1479e-06,  1.3891e-03, -7.1962e-05,\n",
       "           -3.7235e-05,  4.4407e-04, -8.4397e-05, -2.6809e-02,  2.5890e-05],\n",
       "          [ 8.8866e-04, -4.2813e-03, -1.0961e-03,  6.8593e-05,  1.2988e-02,\n",
       "            2.1083e-03, -1.0607e-03,  2.1968e-03,  2.5068e-05,  6.3824e-03],\n",
       "          [-5.7492e-06,  3.7615e-04,  7.1394e-04, -1.7238e-05, -3.9939e-05,\n",
       "           -9.7820e-07,  5.0199e-04, -8.7196e-05, -2.2327e-06, -7.5954e-04],\n",
       "          [ 3.0442e-04, -1.1232e-03, -9.0294e-05,  4.6033e-04,  3.2081e-03,\n",
       "            5.9130e-04, -1.0944e-03,  1.0235e-03, -5.3272e-05,  4.2349e-03],\n",
       "          [-7.4727e-04,  1.5432e-05,  1.4909e-03, -9.8099e-05, -1.2752e-03,\n",
       "           -6.7640e-05,  7.4453e-04,  9.8711e-04, -2.7345e-06, -1.0953e-03],\n",
       "          [ 1.3824e-05, -4.6217e-04, -9.8219e-05, -2.5469e-02, -1.0292e-05,\n",
       "            2.8627e-06, -5.7955e-05, -2.7345e-06,  1.3893e-03,  6.9166e-05],\n",
       "          [ 2.2467e-05, -3.2132e-03, -1.2744e-03, -1.0717e-05,  8.4032e-03,\n",
       "            8.9527e-04, -4.3891e-03,  1.1939e-03, -7.2732e-05,  1.2987e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   1,\n",
       "   0): tensor([[ 5.8008e-06, -1.0907e-03,  7.6837e-04,  1.0743e-06,  1.3349e-03,\n",
       "            4.4700e-06, -1.2844e-03,  1.0199e-04,  5.7150e-06,  2.4768e-03],\n",
       "          [-1.4092e-03, -2.4652e-02,  2.1583e-02,  2.5304e-04,  3.8320e-02,\n",
       "           -1.3263e-03, -3.2714e-03,  3.1224e-03, -4.6925e-04,  4.0576e-03],\n",
       "          [-8.5628e-04, -2.3150e-02,  1.5252e-02,  2.9229e-04,  3.7230e-02,\n",
       "           -1.8787e-04, -3.0372e-03,  3.5606e-03,  9.2174e-05,  2.3593e-03],\n",
       "          [ 5.1851e-06,  2.5485e-04, -3.1318e-04,  7.2380e-03, -5.4756e-04,\n",
       "           -1.5285e-05,  4.6525e-04,  9.2789e-05, -2.7700e-02, -9.9479e-05],\n",
       "          [-1.4209e-03, -4.1066e-02,  3.7169e-02,  5.1531e-04,  5.9432e-02,\n",
       "           -2.5063e-03, -4.0831e-03,  2.3585e-03, -1.0012e-04,  5.3674e-03],\n",
       "          [-2.8170e-06,  4.5176e-03, -1.0146e-03, -1.6589e-05, -4.4579e-03,\n",
       "            5.8249e-06, -1.1364e-03,  8.2429e-04,  2.3495e-06,  1.4356e-03],\n",
       "          [ 4.5133e-03, -9.0080e-02,  3.4728e-02,  7.7726e-04,  1.6300e-01,\n",
       "           -1.3636e-03, -2.4652e-02,  2.3198e-02, -2.6399e-04,  4.1039e-02],\n",
       "          [ 9.8901e-04, -3.4750e-02, -8.7308e-03,  3.2708e-04,  6.8559e-02,\n",
       "           -8.0156e-04, -2.1537e-02,  1.5250e-02, -3.1359e-04,  3.7171e-02],\n",
       "          [ 2.9934e-05, -7.7862e-04,  3.2711e-04,  7.9375e-04,  2.2377e-03,\n",
       "            8.1854e-06, -2.5235e-04,  2.9233e-04,  7.2410e-03,  5.1567e-04],\n",
       "          [ 4.2320e-03, -1.6294e-01,  6.8558e-02,  2.2374e-03,  2.6753e-01,\n",
       "           -1.3195e-03, -3.8345e-02,  3.7232e-02, -5.4799e-04,  5.9431e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   2,\n",
       "   0): tensor([[ 6.1313e-06, -2.9545e-04,  8.9947e-04, -1.9532e-06, -2.7188e-04,\n",
       "           -6.0839e-06, -4.5597e-04,  3.8320e-04,  9.6357e-06,  9.7489e-05],\n",
       "          [-4.7790e-04, -3.8579e-03,  7.9057e-03,  4.0331e-05,  3.1809e-03,\n",
       "           -4.3798e-04, -6.4307e-04,  6.2127e-04,  1.3995e-04, -2.0161e-04],\n",
       "          [-9.8886e-04, -6.9509e-03,  1.2637e-02,  6.9344e-05,  5.6499e-03,\n",
       "           -3.9600e-04, -5.4069e-04,  2.1191e-03, -2.0466e-04,  4.2209e-04],\n",
       "          [ 1.3974e-06,  3.7839e-05, -6.2102e-05,  2.0956e-03, -4.9249e-05,\n",
       "           -1.7925e-05, -1.4199e-04, -2.0532e-04,  7.5634e-03,  4.6256e-04],\n",
       "          [ 1.4235e-04, -4.5471e-03,  8.0034e-03,  2.7870e-05,  4.5050e-03,\n",
       "           -9.3796e-05,  2.3115e-04,  4.2261e-04,  4.6285e-04, -1.3502e-03],\n",
       "          [-1.1879e-05, -7.2473e-03,  1.0828e-02,  1.3535e-04,  9.9073e-03,\n",
       "            5.4840e-06, -2.9778e-04,  9.1624e-04, -1.9933e-06, -2.8497e-04],\n",
       "          [-7.0370e-03, -1.1154e-01,  1.3757e-01,  9.6138e-04,  1.2724e-01,\n",
       "           -4.7571e-04, -3.8579e-03,  6.9232e-03, -4.2172e-05,  4.6189e-03],\n",
       "          [-1.0754e-02, -1.3761e-01,  1.4396e-01,  1.8838e-03,  1.6541e-01,\n",
       "           -9.7042e-04, -7.9373e-03,  1.2638e-02, -6.2984e-05,  8.0041e-03],\n",
       "          [-1.1486e-04, -9.6703e-04,  1.8837e-03, -5.8169e-03,  1.5859e-03,\n",
       "            2.1076e-06, -3.9987e-05,  6.9832e-05,  2.0963e-03,  2.8738e-05],\n",
       "          [-9.7426e-03, -1.2733e-01,  1.6540e-01,  1.5860e-03,  1.2989e-01,\n",
       "            1.3017e-04, -3.1116e-03,  5.6518e-03, -4.9185e-05,  4.5041e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.9790e-07, -5.2765e-04,  5.1688e-04, -1.3316e-05,  1.4629e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-5.3991e-04, -2.6230e-03,  4.8198e-03,  4.5172e-04,  2.0587e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-6.0860e-04, -4.7766e-03,  8.2340e-03,  6.1279e-05,  2.9245e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.4394e-05, -4.5498e-04,  6.1765e-05, -2.6113e-02, -1.0628e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.4013e-03, -2.1092e-03,  2.9239e-03, -1.0640e-04,  2.9195e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (2,\n",
       "   4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (2,\n",
       "   5,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (2,\n",
       "   -2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (2,\n",
       "   -1,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            2.8238e-06,  6.0014e-04, -2.0648e-04, -2.1398e-06, -8.1973e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            6.6041e-04,  3.6008e-04, -6.4725e-04,  1.4959e-04,  5.1406e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            2.2121e-04,  6.9195e-04,  6.4794e-05,  5.3438e-04, -1.2324e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -7.9818e-06, -1.4765e-04,  5.3442e-04,  7.7453e-03,  3.9051e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            8.0805e-04, -5.3215e-04, -1.2320e-03,  3.9393e-05,  8.3739e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (3,\n",
       "   0,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (3,\n",
       "   1,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 3.3333e-06, -1.9802e-04, -2.2793e-04,  2.8080e-05,  3.7486e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.5953e-04, -8.8881e-04,  2.8811e-04, -1.1626e-04,  1.0786e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.4994e-04, -2.5384e-04,  4.2040e-04,  3.3134e-04,  2.5333e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.2311e-05,  1.1083e-04,  3.3132e-04,  7.0509e-03, -1.7968e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-4.4057e-04, -1.0902e-03,  2.5359e-04, -1.7786e-05,  8.0176e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (3,\n",
       "   2,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.0193e-06,  2.3745e-05, -1.5080e-04, -2.1839e-05,  3.6174e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.3274e-05, -2.4525e-04,  3.3108e-04,  2.0630e-04,  7.4484e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.5273e-04, -3.3972e-04,  1.8337e-05, -3.0218e-05,  9.6066e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 9.1898e-06, -1.9609e-04, -3.0058e-05, -1.3129e-02, -7.3118e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.3642e-05, -7.3189e-04,  9.6221e-04, -7.3388e-05,  1.0227e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (3,\n",
       "   3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.2104e-06,  1.5001e-04, -1.5575e-04,  9.4042e-06, -5.6043e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.7035e-04,  4.1734e-04, -4.2488e-04, -1.0940e-04, -1.1501e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.8499e-04,  4.5967e-04,  9.6238e-04, -1.6101e-04,  1.4797e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.2663e-06,  1.0701e-04, -1.6108e-04,  5.9379e-03,  2.2119e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 5.9092e-04,  1.4760e-04,  1.4831e-04,  2.2124e-04,  1.2639e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (3,\n",
       "   4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (3,\n",
       "   5,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (3,\n",
       "   -2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (3,\n",
       "   -1,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   0,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (4,\n",
       "   1,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (4,\n",
       "   2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (4,\n",
       "   3,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   -3,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   -2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-4,\n",
       "   -1,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   0,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   1,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   -5,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-3,\n",
       "   -3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -7.2104e-06,  1.5001e-04,  1.5575e-04, -9.4042e-06,  5.6043e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.7035e-04,  4.1734e-04,  4.2488e-04,  1.0940e-04,  1.1501e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.8499e-04, -4.5967e-04,  9.6238e-04, -1.6101e-04,  1.4797e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            7.2663e-06, -1.0701e-04, -1.6108e-04,  5.9379e-03,  2.2119e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -5.9092e-04, -1.4760e-04,  1.4831e-04,  2.2124e-04,  1.2639e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-3,\n",
       "   -2,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.0193e-06,  2.3745e-05,  1.5080e-04,  2.1839e-05, -3.6174e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.3274e-05, -2.4525e-04, -3.3108e-04, -2.0630e-04, -7.4484e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.5273e-04,  3.3972e-04,  1.8337e-05, -3.0218e-05,  9.6066e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -9.1898e-06,  1.9609e-04, -3.0058e-05, -1.3129e-02, -7.3118e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            2.3642e-05,  7.3189e-04,  9.6221e-04, -7.3388e-05,  1.0227e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-3,\n",
       "   -1,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            3.3333e-06, -1.9802e-04,  2.2793e-04, -2.8080e-05, -3.7486e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.5953e-04, -8.8881e-04, -2.8811e-04,  1.1626e-04, -1.0786e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.4994e-04,  2.5384e-04,  4.2040e-04,  3.3134e-04,  2.5333e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            2.2311e-05, -1.1083e-04,  3.3132e-04,  7.0509e-03, -1.7968e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            4.4057e-04,  1.0902e-03,  2.5359e-04, -1.7786e-05,  8.0176e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   0,\n",
       "   0): tensor([[-9.7820e-07,  5.0199e-04,  8.7196e-05,  2.2327e-06,  7.5954e-04,\n",
       "           -5.7492e-06,  3.7615e-04, -7.1394e-04,  1.7238e-05,  3.9939e-05],\n",
       "          [ 5.9130e-04, -1.0944e-03, -1.0235e-03,  5.3272e-05, -4.2349e-03,\n",
       "            3.0442e-04, -1.1232e-03,  9.0294e-05, -4.6033e-04, -3.2081e-03],\n",
       "          [ 6.7640e-05, -7.4453e-04,  9.8711e-04, -2.7345e-06, -1.0953e-03,\n",
       "            7.4727e-04, -1.5432e-05,  1.4909e-03, -9.8099e-05, -1.2752e-03],\n",
       "          [-2.8627e-06,  5.7955e-05, -2.7345e-06,  1.3893e-03,  6.9166e-05,\n",
       "           -1.3824e-05,  4.6217e-04, -9.8219e-05, -2.5469e-02, -1.0292e-05],\n",
       "          [-8.9527e-04,  4.3891e-03,  1.1939e-03, -7.2732e-05,  1.2987e-02,\n",
       "           -2.2467e-05,  3.2132e-03, -1.2744e-03, -1.0717e-05,  8.4032e-03],\n",
       "          [-6.3866e-06,  1.2188e-03, -8.4296e-04, -2.8367e-05,  2.0486e-03,\n",
       "           -1.6037e-06,  5.0604e-04,  6.4093e-05,  3.0959e-06,  7.6800e-04],\n",
       "          [ 1.2219e-03,  6.4552e-04, -7.5582e-04,  4.4962e-04, -1.0742e-03,\n",
       "            5.8713e-04, -1.0943e-03,  7.3182e-04, -5.3632e-05, -4.3473e-03],\n",
       "          [ 8.1327e-04,  8.5753e-04,  1.7737e-03, -8.4627e-05,  2.1955e-03,\n",
       "            4.4552e-05,  1.0109e-03,  9.8637e-04, -3.1479e-06,  1.1947e-03],\n",
       "          [ 3.7235e-05, -4.4407e-04, -8.4397e-05, -2.6809e-02,  2.5890e-05,\n",
       "            6.0317e-07, -5.5090e-05, -3.1479e-06,  1.3891e-03, -7.1962e-05],\n",
       "          [-2.1083e-03,  1.0607e-03,  2.1968e-03,  2.5068e-05,  6.3824e-03,\n",
       "           -8.8866e-04,  4.2813e-03, -1.0961e-03,  6.8593e-05,  1.2988e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   1,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.8238e-06,  6.0014e-04,  2.0648e-04,  2.1398e-06,  8.1973e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6041e-04,  3.6008e-04,  6.4725e-04, -1.4959e-04, -5.1406e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.2121e-04, -6.9195e-04,  6.4794e-05,  5.3438e-04, -1.2324e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 7.9818e-06,  1.4765e-04,  5.3442e-04,  7.7453e-03,  3.9051e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-8.0805e-04,  5.3215e-04, -1.2320e-03,  3.9393e-05,  8.3739e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   2,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-2,\n",
       "   -5,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-2,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-2,\n",
       "   -3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            6.9790e-07, -5.2765e-04, -5.1688e-04,  1.3316e-05, -1.4629e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -5.3991e-04, -2.6230e-03, -4.8198e-03, -4.5172e-04, -2.0587e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            6.0860e-04,  4.7766e-03,  8.2340e-03,  6.1279e-05,  2.9245e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -1.4394e-05,  4.5498e-04,  6.1765e-05, -2.6113e-02, -1.0628e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            1.4013e-03,  2.1092e-03,  2.9239e-03, -1.0640e-04,  2.9195e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   -2,\n",
       "   0): tensor([[ 5.4840e-06, -2.9778e-04, -9.1624e-04,  1.9933e-06,  2.8497e-04,\n",
       "           -1.1879e-05, -7.2473e-03, -1.0828e-02, -1.3535e-04, -9.9073e-03],\n",
       "          [-4.7571e-04, -3.8579e-03, -6.9232e-03,  4.2172e-05, -4.6189e-03,\n",
       "           -7.0370e-03, -1.1154e-01, -1.3757e-01, -9.6138e-04, -1.2724e-01],\n",
       "          [ 9.7042e-04,  7.9373e-03,  1.2638e-02, -6.2984e-05,  8.0041e-03,\n",
       "            1.0754e-02,  1.3761e-01,  1.4396e-01,  1.8838e-03,  1.6541e-01],\n",
       "          [-2.1076e-06,  3.9987e-05,  6.9832e-05,  2.0963e-03,  2.8738e-05,\n",
       "            1.1486e-04,  9.6703e-04,  1.8837e-03, -5.8169e-03,  1.5859e-03],\n",
       "          [-1.3017e-04,  3.1116e-03,  5.6518e-03, -4.9185e-05,  4.5041e-03,\n",
       "            9.7426e-03,  1.2733e-01,  1.6540e-01,  1.5860e-03,  1.2989e-01],\n",
       "          [-6.0839e-06, -4.5597e-04, -3.8320e-04, -9.6357e-06, -9.7489e-05,\n",
       "            6.1313e-06, -2.9545e-04, -8.9947e-04,  1.9532e-06,  2.7188e-04],\n",
       "          [-4.3798e-04, -6.4307e-04, -6.2127e-04, -1.3995e-04,  2.0161e-04,\n",
       "           -4.7790e-04, -3.8579e-03, -7.9057e-03, -4.0331e-05, -3.1809e-03],\n",
       "          [ 3.9600e-04,  5.4069e-04,  2.1191e-03, -2.0466e-04,  4.2209e-04,\n",
       "            9.8886e-04,  6.9509e-03,  1.2637e-02,  6.9344e-05,  5.6499e-03],\n",
       "          [ 1.7925e-05,  1.4199e-04, -2.0532e-04,  7.5634e-03,  4.6256e-04,\n",
       "           -1.3974e-06, -3.7839e-05, -6.2102e-05,  2.0956e-03, -4.9249e-05],\n",
       "          [ 9.3796e-05, -2.3115e-04,  4.2261e-04,  4.6285e-04, -1.3502e-03,\n",
       "           -1.4235e-04,  4.5471e-03,  8.0034e-03,  2.7870e-05,  4.5050e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-2,\n",
       "   -1,\n",
       "   0): tensor([[ 5.8249e-06, -1.1364e-03, -8.2429e-04, -2.3495e-06, -1.4356e-03,\n",
       "           -2.8170e-06,  4.5176e-03,  1.0146e-03,  1.6589e-05,  4.4579e-03],\n",
       "          [-1.3636e-03, -2.4652e-02, -2.3198e-02,  2.6399e-04, -4.1039e-02,\n",
       "            4.5133e-03, -9.0080e-02, -3.4728e-02, -7.7726e-04, -1.6300e-01],\n",
       "          [ 8.0156e-04,  2.1537e-02,  1.5250e-02, -3.1359e-04,  3.7171e-02,\n",
       "           -9.8901e-04,  3.4750e-02, -8.7308e-03,  3.2708e-04,  6.8559e-02],\n",
       "          [-8.1854e-06,  2.5235e-04,  2.9233e-04,  7.2410e-03,  5.1567e-04,\n",
       "           -2.9934e-05,  7.7862e-04,  3.2711e-04,  7.9375e-04,  2.2377e-03],\n",
       "          [ 1.3195e-03,  3.8345e-02,  3.7232e-02, -5.4799e-04,  5.9431e-02,\n",
       "           -4.2320e-03,  1.6294e-01,  6.8558e-02,  2.2374e-03,  2.6753e-01],\n",
       "          [ 4.4700e-06, -1.2844e-03, -1.0199e-04, -5.7150e-06, -2.4768e-03,\n",
       "            5.8008e-06, -1.0907e-03, -7.6837e-04, -1.0743e-06, -1.3349e-03],\n",
       "          [-1.3263e-03, -3.2714e-03, -3.1224e-03,  4.6925e-04, -4.0576e-03,\n",
       "           -1.4092e-03, -2.4652e-02, -2.1583e-02, -2.5304e-04, -3.8320e-02],\n",
       "          [ 1.8787e-04,  3.0372e-03,  3.5606e-03,  9.2174e-05,  2.3593e-03,\n",
       "            8.5628e-04,  2.3150e-02,  1.5252e-02,  2.9229e-04,  3.7230e-02],\n",
       "          [ 1.5285e-05, -4.6525e-04,  9.2789e-05, -2.7700e-02, -9.9479e-05,\n",
       "           -5.1851e-06, -2.5485e-04, -3.1318e-04,  7.2380e-03, -5.4756e-04],\n",
       "          [ 2.5063e-03,  4.0831e-03,  2.3585e-03, -1.0012e-04,  5.3674e-03,\n",
       "            1.4209e-03,  4.1066e-02,  3.7169e-02,  5.1531e-04,  5.9432e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   0,\n",
       "   0): tensor([[ 2.2137e-05, -2.6664e-01,  6.2903e-04,  3.3967e-05, -5.7951e-01,\n",
       "            6.5386e-05, -7.3635e-02,  9.3019e-02, -1.6122e-03, -1.5923e-01],\n",
       "          [-2.6652e-01, -1.3277e+00,  1.7897e-01,  8.0496e-03, -1.7300e+00,\n",
       "           -7.3640e-02, -5.6248e-01,  3.9580e-01, -4.9199e-03, -6.8125e-01],\n",
       "          [ 2.4463e-04,  1.8171e-01, -4.8994e-01, -6.8090e-06,  2.7501e-01,\n",
       "           -9.3029e-02, -3.9580e-01,  3.5066e-02, -5.2958e-03, -5.1374e-01],\n",
       "          [ 1.2559e-05,  8.0681e-03, -6.8090e-06, -3.8286e-01,  1.1399e-02,\n",
       "            1.5984e-03,  4.9078e-03, -5.2954e-03, -2.2839e-02,  8.6944e-03],\n",
       "          [ 5.7902e-01,  1.7297e+00, -2.6887e-01, -1.1314e-02,  1.9338e+00,\n",
       "            1.5923e-01,  6.8125e-01, -5.1374e-01,  8.6950e-03,  6.2604e-01],\n",
       "          [ 6.2632e-05, -6.2098e-02, -7.8683e-02,  1.4971e-03, -1.3701e-01,\n",
       "            2.1843e-05, -2.6660e-01,  1.9365e-05, -1.3441e-05, -5.7944e-01],\n",
       "          [-6.2102e-02, -5.1374e-01, -3.6187e-01,  4.6428e-03, -6.3331e-01,\n",
       "           -2.6656e-01, -1.3277e+00, -1.8183e-01, -8.0799e-03, -1.7298e+00],\n",
       "          [ 7.8694e-02,  3.6186e-01,  3.6985e-02, -4.9833e-03,  4.7751e-01,\n",
       "           -3.6504e-04, -1.7909e-01, -4.8996e-01, -7.7829e-06, -2.6888e-01],\n",
       "          [-1.5072e-03, -4.6971e-03, -4.9839e-03, -8.9361e-03, -8.6664e-03,\n",
       "           -3.4070e-05, -8.0527e-03, -7.7829e-06, -3.8284e-01, -1.1315e-02],\n",
       "          [ 1.3702e-01,  6.3332e-01,  4.7751e-01, -8.6655e-03,  6.0053e-01,\n",
       "            5.7909e-01,  1.7298e+00,  2.7502e-01,  1.1398e-02,  1.9338e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   1,\n",
       "   0): tensor([[ 4.7666e-06, -1.0378e-03,  1.1206e-03, -8.3608e-07, -1.6847e-03,\n",
       "            4.3835e-07, -5.5200e-04,  4.9079e-05,  1.2448e-05, -2.5522e-04],\n",
       "          [-9.9404e-04, -2.3729e-02,  2.1996e-02,  1.9422e-04, -3.7833e-02,\n",
       "           -4.9365e-04, -2.3214e-03,  2.8997e-03, -4.6006e-04, -2.5745e-03],\n",
       "          [-1.1785e-03, -2.3627e-02,  1.5249e-02,  2.6830e-04, -3.8544e-02,\n",
       "           -8.9631e-05, -2.9129e-03,  4.9983e-03,  8.0853e-05, -2.9465e-03],\n",
       "          [-3.4901e-06,  1.8247e-04, -2.3792e-04,  5.2051e-03,  4.3322e-04,\n",
       "           -7.1065e-06,  4.6761e-04,  8.0677e-05, -2.5578e-02,  1.1154e-04],\n",
       "          [ 1.7946e-03,  4.0458e-02, -3.8382e-02, -4.5308e-04,  5.7690e-02,\n",
       "            2.0038e-04,  2.5743e-03, -2.9467e-03,  1.1136e-04,  4.9381e-03],\n",
       "          [-1.1712e-05,  2.0167e-03,  1.6567e-04, -4.1828e-05,  4.1170e-04,\n",
       "            4.7353e-06, -1.0871e-03,  1.1728e-03,  1.7076e-06, -1.7902e-03],\n",
       "          [ 2.1326e-03, -8.5126e-02,  3.3245e-02,  6.3975e-04, -1.5213e-01,\n",
       "           -9.4483e-04, -2.3729e-02,  2.3636e-02, -1.8231e-04, -4.0504e-02],\n",
       "          [-1.8114e-04, -3.3224e-02, -9.0698e-03,  2.2446e-04, -6.1543e-02,\n",
       "           -1.1251e-03, -2.1985e-02,  1.5250e-02, -2.3808e-04, -3.8381e-02],\n",
       "          [ 2.8166e-05, -6.3297e-04,  2.2450e-04,  4.3953e-03, -2.0804e-03,\n",
       "           -2.9217e-06, -1.9230e-04,  2.6799e-04,  5.2029e-03, -4.5341e-04],\n",
       "          [-2.1762e-04,  1.5213e-01, -6.1545e-02, -2.0802e-03,  2.5020e-01,\n",
       "            1.6897e-03,  3.7788e-02, -3.8543e-02,  4.3262e-04,  5.7691e-02]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   2,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.2462e-06, -1.0981e-03,  7.3055e-04,  2.2624e-06, -1.0623e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.1585e-03, -2.2463e-03,  6.8719e-04,  1.9485e-04, -1.1650e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.7867e-04, -6.5797e-04,  5.2029e-04,  2.5882e-05, -8.0738e-04,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.5630e-05, -1.8869e-04,  2.5807e-05, -1.5724e-02,  4.8975e-05,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.1124e-03,  1.1319e-03, -8.0630e-04,  4.8852e-05,  1.5950e-03,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   3,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-1,\n",
       "   -4,\n",
       "   0): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  (-1,\n",
       "   -3,\n",
       "   0): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.9811e-06,  2.4974e-04,  8.1754e-04,  2.3347e-05,  9.0218e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            3.1506e-04, -1.3202e-03, -3.4137e-03, -4.4272e-04,  1.5268e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -8.9841e-04,  3.4599e-03,  8.3868e-03,  5.9030e-05, -2.5432e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -2.1627e-05,  4.4998e-04,  5.9323e-05, -2.5399e-02,  1.0307e-04],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           -8.0561e-04, -1.5857e-03, -2.5428e-03,  1.0315e-04,  2.6014e-03],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   -2,\n",
       "   0): tensor([[-1.5342e-05,  1.6376e-03,  2.3719e-03, -4.0843e-06,  1.6729e-04,\n",
       "            6.8304e-05, -8.3345e-02, -2.0573e-01, -1.7575e-03,  1.3665e-03],\n",
       "          [ 1.7483e-03, -2.2029e-02, -4.1847e-02,  1.9525e-04,  4.3235e-04,\n",
       "           -8.3339e-02, -5.9732e-01, -8.2796e-01, -5.0916e-03,  3.1183e-03],\n",
       "          [-2.2993e-03,  4.5250e-02,  8.3021e-02, -5.2618e-04, -9.8356e-04,\n",
       "            2.0573e-01,  8.2795e-01,  9.5522e-01,  1.0460e-02, -2.8822e-03],\n",
       "          [-5.5293e-06,  2.0527e-04,  5.1863e-04,  4.6576e-03,  1.2376e-05,\n",
       "            1.7484e-03,  5.0536e-03,  1.0460e-02, -3.2080e-02, -2.3031e-04],\n",
       "          [-1.3810e-04, -7.2104e-04, -1.4175e-03,  9.9493e-06, -7.4677e-03,\n",
       "           -1.3562e-03, -3.1112e-03, -2.8804e-03, -2.3029e-04, -2.7936e-01],\n",
       "          [-3.7801e-06,  6.6904e-04,  8.2426e-04,  4.4096e-06,  4.5443e-04,\n",
       "           -1.5336e-05,  1.5848e-03,  2.2447e-03, -7.5846e-07,  1.5874e-04],\n",
       "          [ 7.4476e-04,  9.7797e-04, -4.1169e-05,  2.2342e-04,  1.9799e-04,\n",
       "            1.8012e-03, -2.2029e-02, -4.5203e-02, -1.9650e-04,  6.5600e-04],\n",
       "          [-8.9213e-04,  8.9904e-05,  1.8912e-03,  4.3526e-05,  1.3392e-05,\n",
       "           -2.4265e-03,  4.1893e-02,  8.3021e-02,  5.1850e-04, -1.4172e-03],\n",
       "          [-1.5277e-05, -2.1988e-04,  4.3294e-05, -1.3850e-02,  3.0084e-05,\n",
       "           -1.7063e-06, -1.9772e-04, -5.2575e-04,  4.6567e-03,  9.6614e-06],\n",
       "          [-4.6058e-04, -2.1092e-04,  1.4510e-05,  3.0081e-05, -1.3837e-03,\n",
       "           -1.4793e-04, -4.9966e-04, -9.8457e-04,  1.2087e-05, -7.4668e-03]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  (-1,\n",
       "   -1,\n",
       "   0): tensor([[ 2.5754e-05, -2.7481e-01, -5.1732e-01,  3.2384e-05, -3.0127e-01,\n",
       "           -2.7978e-03, -4.5375e+00, -3.6840e+00, -1.2690e-01, -6.5239e+00],\n",
       "          [-2.7489e-01, -1.3488e+00, -1.6119e+00,  8.0527e-03, -7.2820e-01,\n",
       "           -4.5375e+00, -6.5599e+00, -2.8498e+00, -1.0367e-01, -5.0447e+00],\n",
       "          [ 5.1684e-01,  1.4230e+00,  1.3237e+00, -9.7138e-03,  7.9420e-01,\n",
       "            3.6840e+00,  2.8498e+00, -1.0870e+00,  3.9055e-02,  1.9642e+00],\n",
       "          [ 1.2498e-05,  8.0597e-03,  9.7781e-03, -3.9401e-01,  5.7092e-03,\n",
       "            1.2686e-01,  1.0368e-01,  3.9055e-02, -2.1515e+00,  6.9271e-02],\n",
       "          [ 3.0203e-01,  1.0535e+00,  1.3588e+00, -5.7267e-03,  1.2594e-01,\n",
       "            6.5239e+00,  5.0447e+00,  1.9642e+00,  6.9271e-02,  1.2935e+00],\n",
       "          [-1.6102e-05, -4.4003e-03, -8.8133e-03,  5.4799e-05, -3.7755e-03,\n",
       "            2.6044e-05, -2.7483e-01, -5.1703e-01, -1.4732e-05, -3.0177e-01],\n",
       "          [-4.0914e-03, -9.9232e-02, -1.6207e-01,  7.8773e-04, -5.3398e-02,\n",
       "           -2.7487e-01, -1.3488e+00, -1.4228e+00, -8.0647e-03, -1.0537e+00],\n",
       "          [ 8.7598e-03,  1.6211e-01,  2.5377e-01, -2.0944e-03,  8.6594e-02,\n",
       "            5.1712e-01,  1.6122e+00,  1.3237e+00,  9.7791e-03,  1.3588e+00],\n",
       "          [-6.8641e-05, -7.8457e-04, -2.0943e-03, -1.3155e-03, -8.7634e-04,\n",
       "           -3.5285e-05, -8.0631e-03, -9.7127e-03, -3.9399e-01, -5.7271e-03],\n",
       "          [ 3.6578e-03,  5.3453e-02,  8.6593e-02, -8.7634e-04,  2.9005e-03,\n",
       "            3.0152e-01,  7.2797e-01,  7.9421e-01,  5.7087e-03,  1.2593e-01]],\n",
       "         grad_fn=<CopySlices>)}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_blocks_to_matrix(pred, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbbbf1-dafa-4bbf-9b05-e6010a66cf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
