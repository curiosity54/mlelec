{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d8f12c-62ee-4d46-b766-c3b49d817fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "635a399b-c69b-4438-bac6-4ba0712d0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "from ase.visualize import view\n",
    "import numpy as np \n",
    "import torch \n",
    "import metatensor \n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from metatensor import Labels, TensorBlock, TensorMap\n",
    "from mlelec.data.dataset import PySCFPeriodicDataset\n",
    "\n",
    "from mlelec.utils.plot_utils import print_matrix, matrix_norm, block_matrix_norm\n",
    "\n",
    "from metatensor import load, sort\n",
    "from mlelec.utils.twocenter_utils import _to_coupled_basis\n",
    "from mlelec.utils.pbc_utils import matrix_to_blocks, kmatrix_to_blocks, TMap_bloch_sums, precompute_phase\n",
    "\n",
    "from mlelec.features.acdc import pair_features, single_center_features, twocenter_features_periodic_NH, twocenter_hermitian_features\n",
    "import rascaline\n",
    "from mlelec.utils.pbc_utils import kblocks_to_matrix, kmatrix_to_blocks, blocks_to_matrix, matrix_to_blocks\n",
    "from mlelec.utils.plot_utils import plot_block_errors\n",
    "\n",
    "import rascaline\n",
    "from mlelec.models.linear import LinearModelPeriodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a54e69-a6cf-413a-a1fa-bec6edae654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(dataset, device =\"cpu\", cutoff = None, target='fock', all_pairs = False, sort_orbs = True):\n",
    "    \n",
    "    blocks = matrix_to_blocks(dataset, device = device, cutoff = cutoff, all_pairs = all_pairs, target = target, sort_orbs = sort_orbs)\n",
    "    coupled_blocks = _to_coupled_basis(blocks, skip_symmetry = True, device = device, translations = True)\n",
    "\n",
    "    blocks = blocks.to(arrays='numpy')\n",
    "    blocks = sort(blocks)\n",
    "    blocks = blocks.to(arrays='torch')\n",
    "    \n",
    "    coupled_blocks = coupled_blocks.to(arrays='numpy')\n",
    "    coupled_blocks = sort(coupled_blocks)\n",
    "    coupled_blocks = coupled_blocks.to(arrays='torch')\n",
    "    \n",
    "    return blocks, coupled_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc04a6ae-03c9-489e-b7e3-347cc86f8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(dataset, all_pairs=False):\n",
    "\n",
    "    rhoij = pair_features(dataset.structures, hypers_atom, hypers_pair, order_nu = 1, all_pairs = all_pairs, both_centers = both_centers,\n",
    "                          kmesh = dataset.kmesh, device = device, lcut = LCUT, return_rho0ij = return_rho0ij)  \n",
    "    \n",
    "    if both_centers and not return_rho0ij:\n",
    "        NU = 3\n",
    "    else:\n",
    "        NU = 2\n",
    "    rhonui = single_center_features(dataset.structures, hypers_atom, order_nu = NU, lcut = LCUT, device = device,\n",
    "                                    feature_names = rhoij.property_names)\n",
    "    \n",
    "    hfeat = twocenter_features_periodic_NH(single_center = rhonui, pair = rhoij, all_pairs = all_pairs)\n",
    "\n",
    "    return hfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0131f6a-72a2-445e-9384-0ba95406c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "orbitals = {\n",
    "    'sto-3g': {5: [[1,0,0],[2,0,0],[2,1,-1], [2,1,0],[2,1,1]], \n",
    "               6: [[1,0,0],[2,0,0],[2,1,-1], [2,1,0],[2,1,1]], \n",
    "               7: [[1,0,0],[2,0,0],[2,1,-1], [2,1,0],[2,1,1]]}, \n",
    "    \n",
    "    'def2svp': {6: [[1,0,0],[2,0,0],[3,0,0],[2,1,1], [2,1,-1],[2,1,0], [3,1,1], [3,1,-1],[3,1,0], [3,2,-2], [3,2,-1],[3,2,0], [3,2,1],[3,2,2]]},\n",
    "    'benzene': {6: [[2,0,0],[2,1,-1], [2,1,0],[2,1,1]], 1:[[1,0,0]]},\n",
    "    'gthszvmolopt': {\n",
    "        6: [[2, 0, 0], [2, 1, -1], [2, 1, 0], [2, 1, 1]],\n",
    "        \n",
    "        16: [[3,0,0], \n",
    "             [3,1,-1], [3,1,0], [3,1,1]],\n",
    "\n",
    "        42: [[4,0,0], \n",
    "             [5,0,0], \n",
    "             [4,1,-1], [4,1,0], [4,1,1], \n",
    "             [4, 2, -2], [4, 2, -1], [4, 2, 0], [4, 2, 1], [4, 2, 2]]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61756a8d-5fbe-4fd2-9521-4a4604762d6d",
   "metadata": {},
   "source": [
    "# QC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cb8d851-377b-4bd5-a632-397f666731e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = './'\n",
    "START = 0 \n",
    "STOP = 5\n",
    "ORBS = 'sto-3g'\n",
    "root = f'{workdir}/examples/data/periodic/deepH_graphene/wrap/'\n",
    "data_dir = root\n",
    "frames = read(f'{data_dir}/wrapped_deepH_graphene.xyz', slice(START, STOP))\n",
    "rfock = [np.load(f\"{data_dir}/realfock_{i}.npy\", allow_pickle = True).item() for i in range(START, STOP)]\n",
    "rover = [np.load(f\"{data_dir}/realoverlap_{i}.npy\", allow_pickle = True).item() for i in range(START, STOP)]\n",
    "kmesh = [1,1,1]\n",
    "dataset = PySCFPeriodicDataset(frames = frames, \n",
    "                               kmesh = kmesh, \n",
    "                               dimension = 2,\n",
    "                               fock_realspace = rfock, \n",
    "                               overlap_realspace = rover, \n",
    "                               device = device, \n",
    "                               orbs = orbitals[ORBS], \n",
    "                               orbs_name = 'sto-3g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3873bac-ec05-4a55-aeb6-abc711ebe1b2",
   "metadata": {},
   "source": [
    "# Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4ac2b01-c2a3-47e2-9296-323a5eddd158",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "567ec238-ff88-4497-930f-fcb0551861ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_blocks, target_coupled_blocks = get_targets(dataset, cutoff = cutoff, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa78cad-0988-4be9-812a-2209fdc5a9bf",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db41bfa2-936d-4d9f-8f3c-22580d7959a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_radial  = 6\n",
    "max_angular = 4\n",
    "atomic_gaussian_width = 0.3\n",
    "\n",
    "hypers_pair = {'cutoff': cutoff,\n",
    "               'max_radial': max_radial,\n",
    "               'max_angular': max_angular,\n",
    "               'atomic_gaussian_width': atomic_gaussian_width,\n",
    "               'center_atom_weight': 1,\n",
    "               \"radial_basis\": {\"Gto\": {}},\n",
    "               \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.1}}}\n",
    "\n",
    "\n",
    "hypers_atom = {'cutoff': 4,\n",
    "               'max_radial': max_radial,\n",
    "               'max_angular': max_angular,\n",
    "               'atomic_gaussian_width': 0.3,\n",
    "               'center_atom_weight': 1,\n",
    "               \"radial_basis\": {\"Gto\": {}},\n",
    "               \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.1}}}\n",
    "\n",
    "\n",
    "return_rho0ij = False\n",
    "both_centers = False\n",
    "LCUT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e89ccaa-95c0-44d2-938c-3189761c58c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu pair features\n",
      "cpu single center features\n",
      "cpu single center features\n"
     ]
    }
   ],
   "source": [
    "features = compute_features(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2566f8d-43e1-4404-bf31-e80c1e2e7e57",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a61b2ec7-8647-4c4c-a843-e38141d5b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatensor.learn import Dataset, DataLoader\n",
    "import metatensor as mts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "82d85910-f02e-41a0-9e58-2e0f820b5bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.4 ms ± 379 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "umd1 = mts.unique_metadata(features, axis = \"samples\", names = [\"structure\", \"center\", \"neighbor\"]).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5a51cd38-2e4b-41cd-930e-d57d6b314e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 ms ± 943 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Aijs, invs = unique_Aij(features)\n",
    "umd2 = np.unique(np.concatenate(Aijs), axis = 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b8224b2b-a7c1-4eed-8b28-1691dd1b746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_Aij(tensor):\n",
    "    Aijs = []\n",
    "    invs = []\n",
    "    for b in tensor.blocks():\n",
    "        Aij, inv = np.unique(b.samples.values[:, :3].tolist(), axis = 0, return_inverse = True)\n",
    "        Aijs.append(ifrij)\n",
    "        invs.append(inv)\n",
    "    return Aijs, invs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a2efc04-3ed5-4307-84db-ede197f552ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_axis = \"samples\"\n",
    "split_by_dimension = [\"structure\", \"center\", \"neighbor\"]\n",
    "grouped_labels = [\n",
    "    mts.Labels(names=split_by_dimension, values=np.array([A]))\n",
    "    for A in mts.unique_metadata(features, axis = split_by_axis, names = split_by_dimension)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "20934b87-bfd0-4df2-b6e6-954e4a0fc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_samples = features[10].samples.values[:,:3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5c3c77f6-e603-4183-b189-2162c8028a46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels(\n",
       "    structure  center  neighbor  cell_shift_a  cell_shift_b  cell_shift_c\n",
       "        0        0        1           0             0             0\n",
       "        0        0        2           0             0             0\n",
       "        0        0        3           0             0             0\n",
       "        0        0        4           0             0             0\n",
       "        0        0        8           0             0             0\n",
       "        0        0        9           0             0             0\n",
       "        0        0        10          0             0             0\n",
       "        0        0        11          0             0             0\n",
       "        0        0        12          0             0             0\n",
       "        0        0        13          0             0             0\n",
       ")"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels(features[10].samples.names, np.array(features[10].samples.values[:10].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "56a600b1-b4e9-4eb3-9dbe-0400ed52749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.pbc_utils import unique_Aij_block\n",
    "\n",
    "def split_block_by_Aij(block):\n",
    "    \n",
    "    Aij, where_inv = unique_Aij_block(block)\n",
    "\n",
    "    values = {}\n",
    "    b_values = block.values\n",
    "    for I, (A, i, j) in enumerate(Aij):\n",
    "        idx = np.where(where_inv == I)[0]\n",
    "        values[A, i, j] = b_values[idx]\n",
    "\n",
    "    return values\n",
    "\n",
    "def split_block_by_Aij_mts(block):\n",
    "\n",
    "    from metatensor import Labels, TensorBlock\n",
    "    \n",
    "    Aij, where_inv = unique_Aij_block(block)\n",
    "\n",
    "    # samples = {}\n",
    "    # components = {}\n",
    "    # properties = {}\n",
    "    # values = {}\n",
    "    new_blocks = {}\n",
    "    b_values = block.values\n",
    "    b_samples = block.samples\n",
    "    b_components = block.components\n",
    "    b_properties = block.properties\n",
    "    for I, (A, i, j) in enumerate(Aij):\n",
    "        idx = np.where(where_inv == I)[0]\n",
    "        # samples[A, i, j] = Labels(b_samples.names, np.array(b_samples.values[idx].tolist()))\n",
    "        # components[A, i, j] = Labels(b_components.names, np.array(b_components.values[idx].tolist()))\n",
    "        # properties[A, i, j] = Labels(b_properties.names, np.array(b_properties.values[idx].tolist()))\n",
    "        # values[A, i, j] = b_values[idx]\n",
    "        new_blocks[A, i, j] = TensorBlock(samples = Labels(b_samples.names, np.array(b_samples.values[idx].tolist())),\n",
    "                                          components = b_components, #Labels(b_components.names, np.array(b_components.values[idx].tolist())), \n",
    "                                          properties = b_properties, #Labels(b_properties.names, np.array(b_properties.values[idx].tolist())),\n",
    "                                          values = b_values[idx])\n",
    "\n",
    "    return new_blocks\n",
    "\n",
    "def split_by_Aij(tensor, features = None):\n",
    "\n",
    "    if features is None:\n",
    "        values = {}\n",
    "        for k, b in tensor.items():\n",
    "            kl = tuple(k.values.tolist())\n",
    "            values[kl] = split_block_by_Aij(b)\n",
    "\n",
    "        return values\n",
    "\n",
    "    else:\n",
    "        from mlelec.utils.twocenter_utils import map_targetkeys_to_featkeys\n",
    "        \n",
    "        target_values = {}\n",
    "        feature_values = {}\n",
    "        \n",
    "        for k, target in tensor.items():\n",
    "            \n",
    "            feature = map_targetkeys_to_featkeys(features, k)\n",
    "            \n",
    "            kl = tuple(k.values.tolist())\n",
    "            \n",
    "            target_values[kl] = split_block_by_Aij(target)\n",
    "            feature_values[kl] = split_block_by_Aij(feature)\n",
    "    \n",
    "        return feature_values, target_values\n",
    "\n",
    "def split_by_Aij_mts(tensor, features = None):\n",
    "\n",
    "    from metatensor import TensorMap\n",
    "    \n",
    "    if features is None:\n",
    "\n",
    "        blocks = {}\n",
    "        keys = {}\n",
    "        for k, b in tensor.items():\n",
    "            block = split_block_by_Aij_mts(b)\n",
    "\n",
    "            for Aij in block:\n",
    "                if Aij not in blocks:\n",
    "                    blocks[Aij] = []\n",
    "                    keys[Aij] = []\n",
    "                keys[Aij].append(k.values.tolist())\n",
    "                blocks[Aij].append(block[Aij])\n",
    "\n",
    "\n",
    "        tmaps = {}\n",
    "        for Aij in blocks:\n",
    "            tmap_keys = Labels(tensor.keys.names, np.array(keys[Aij]))\n",
    "            tmap_blocks = blocks[Aij]\n",
    "            tmaps[Aij] = TensorMap(tmap_keys, tmap_blocks)\n",
    "        \n",
    "        return tmaps\n",
    "\n",
    "    else:\n",
    "        from mlelec.utils.twocenter_utils import map_targetkeys_to_featkeys\n",
    "\n",
    "        feature_blocks = {}\n",
    "        target_blocks = {}\n",
    "        keys = {}\n",
    "        for k, b in tensor.items():\n",
    "            feature = map_targetkeys_to_featkeys(features, k)\n",
    "            \n",
    "            target_block = split_block_by_Aij_mts(b)\n",
    "            feature_block = split_block_by_Aij_mts(feature)\n",
    "\n",
    "            for Aij in target_block:\n",
    "                if Aij not in target_blocks:\n",
    "                    feature_blocks[Aij] = []\n",
    "                    target_blocks[Aij] = []\n",
    "                    keys[Aij] = []\n",
    "                kval = k.values.tolist()\n",
    "                keys[Aij].append(kval)\n",
    "                feature_blocks[Aij].append(feature_block[Aij])\n",
    "                target_blocks[Aij].append(target_block[Aij])\n",
    "\n",
    "        tmaps_feature = {}\n",
    "        tmaps_target = {}\n",
    "        for Aij in feature_blocks:\n",
    "            tmap_keys = Labels(tensor.keys.names, np.array(keys[Aij]))\n",
    "            tmaps_feature[Aij] = TensorMap(tmap_keys, feature_blocks[Aij])\n",
    "            tmaps_target[Aij] = TensorMap(tmap_keys, target_blocks[Aij])\n",
    "        \n",
    "        return tmaps_feature, tmaps_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0dbdb2c6-f7ba-41d6-8ee9-cf124e282c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.twocenter_utils import map_targetkeys_to_featkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f1fc5633-ff68-4cd5-be55-3faca5aee035",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_features_, split_target_ = split_by_Aij(target_coupled_blocks, features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3291255e-e9ba-4ab9-9cfa-0c5776242ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.8 s ± 103 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "split_target_mts = split_by_Aij_mts(target_coupled_blocks, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e21bcc34-faa1-49af-874b-7c3419a9bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94 s ± 5.46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "split_features_, split_target_ = split_by_Aij(target_coupled_blocks, features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "46ef102d-b6c9-452b-a2fa-5262325ec255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2 s ± 175 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "split_target_mts = split_by_Aij_mts(target_coupled_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "029f3bb5-9dad-44b4-8757-5f10c55ca1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43 s ± 2.84 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "split_target_ = split_by_Aij(target_coupled_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e0c3273e-b48a-48e4-ad98-384b54564ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in split_features_:\n",
    "    for f, t in zip(split_features_[k].values(), split_target_[k].values()):\n",
    "        assert (f.shape[:2] == t.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6fd6d2c2-34ba-4ba7-9539-624431ea46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_target = split_by_Aij(target_coupled_blocks)\n",
    "split_features = split_by_Aij(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6622f71d-fbef-47ee-a6cb-9f30fd5d50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (A,i,j), v in split_target_mts.items():\n",
    "    for k,b in v.items():\n",
    "        assert A == np.unique(b.samples.values[:,0]), (A, np.unique(b.samples.values[:,0]))\n",
    "        assert i == np.unique(b.samples.values[:,1]), (i, np.unique(b.samples.values[:,1]))\n",
    "        assert j == np.unique(b.samples.values[:,2]), (j, np.unique(b.samples.values[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "476028b6-2d3b-4236-9424-0e285cea1d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(2, 1, 0, 6, 6, 0), (2, 1, 1, 6, 6, 0), (2, 1, 2, 6, 6, 0), (2, 1, 3, 6, 6, 0), (2, -1, 1, 6, 6, 0), (2, -1, 2, 6, 6, 0), (2, -1, 3, 6, 6, 0), (2, 1, 0, 6, 6, 1), (2, 1, 0, 6, 6, -1), (2, 1, 1, 6, 6, 1), (2, 1, 1, 6, 6, -1), (2, 1, 2, 6, 6, 1), (2, 1, 2, 6, 6, -1), (2, 1, 3, 6, 6, 1), (2, 1, 3, 6, 6, -1), (2, -1, 1, 6, 6, 1), (2, -1, 1, 6, 6, -1), (2, -1, 2, 6, 6, 1), (2, -1, 2, 6, 6, -1), (2, -1, 3, 6, 6, 1), (2, -1, 3, 6, 6, -1)])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0322aa7-c6cb-43d5-aa2e-c0c77df700e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "randidx = np.random.choice(382, 40)\n",
    "np.random.seed(1)\n",
    "randidx1 = np.random.choice(382, 40, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38900ab1-8d11-47b6-89d5-f184da2aae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = Dataset(descriptor = [features], target = [target_coupled_blocks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4978a0cf-914e-44b6-a0ed-c76715554380",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "401203e3-4809-415a-a8d4-b89347c2e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ml_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "821924d2-ee6e-43fe-b150-409c39a0e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5042ecbc-ebfa-49dd-8fef-098e45e4077f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.descriptor = TensorMap with 21 blocks\n",
      "keys: order_nu  inversion_sigma  spherical_harmonics_l  species_center  species_neighbor  block_type\n",
      "         2             1                   0                  6                6              0\n",
      "         2             1                   1                  6                6              0\n",
      "         2             1                   2                  6                6              0\n",
      "         2             1                   3                  6                6              0\n",
      "         2            -1                   1                  6                6              0\n",
      "         2            -1                   2                  6                6              0\n",
      "         2            -1                   3                  6                6              0\n",
      "         2             1                   0                  6                6              1\n",
      "         2             1                   0                  6                6              -1\n",
      "         2             1                   1                  6                6              1\n",
      "         2             1                   1                  6                6              -1\n",
      "         2             1                   2                  6                6              1\n",
      "         2             1                   2                  6                6              -1\n",
      "         2             1                   3                  6                6              1\n",
      "         2             1                   3                  6                6              -1\n",
      "         2            -1                   1                  6                6              1\n",
      "         2            -1                   1                  6                6              -1\n",
      "         2            -1                   2                  6                6              1\n",
      "         2            -1                   2                  6                6              -1\n",
      "         2            -1                   3                  6                6              1\n",
      "         2            -1                   3                  6                6              -1\n",
      "batch.target = TensorMap with 24 blocks\n",
      "keys: block_type  species_i  n_i  l_i  species_j  n_j  l_j  L\n",
      "          -1          6       1    0       6       1    0   0\n",
      "          -1          6       1    0       6       2    0   0\n",
      "          -1          6       1    0       6       2    1   1\n",
      "          -1          6       2    0       6       2    0   0\n",
      "          -1          6       2    0       6       2    1   1\n",
      "          -1          6       2    1       6       2    1   0\n",
      "          -1          6       2    1       6       2    1   1\n",
      "          -1          6       2    1       6       2    1   2\n",
      "          0           6       1    0       6       1    0   0\n",
      "          0           6       1    0       6       2    0   0\n",
      "          0           6       1    0       6       2    1   1\n",
      "          0           6       2    0       6       2    0   0\n",
      "          0           6       2    0       6       2    1   1\n",
      "          0           6       2    1       6       2    1   0\n",
      "          0           6       2    1       6       2    1   1\n",
      "          0           6       2    1       6       2    1   2\n",
      "          1           6       1    0       6       1    0   0\n",
      "          1           6       1    0       6       2    0   0\n",
      "          1           6       1    0       6       2    1   1\n",
      "          1           6       2    0       6       2    0   0\n",
      "          1           6       2    0       6       2    1   1\n",
      "          1           6       2    1       6       2    1   0\n",
      "          1           6       2    1       6       2    1   1\n",
      "          1           6       2    1       6       2    1   2\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# `scalar` data are float objects, so are just grouped and returned in a tuple\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch.target =\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch\u001b[38;5;241m.\u001b[39mtarget) \u001b[38;5;241m==\u001b[39m batch_size, \u001b[38;5;28mlen\u001b[39m(batch\u001b[38;5;241m.\u001b[39mtarget)\n",
      "\u001b[0;31mAssertionError\u001b[0m: 24"
     ]
    }
   ],
   "source": [
    "print(\"batch.descriptor =\", batch.descriptor)\n",
    "\n",
    "# `scalar` data are float objects, so are just grouped and returned in a tuple\n",
    "print(\"batch.target =\", batch.target)\n",
    "assert len(batch.target) == batch_size, len(batch.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
