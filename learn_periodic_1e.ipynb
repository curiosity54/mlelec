{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d9b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e5ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ase \n",
    "from ase.units import Bohr \n",
    "import torch\n",
    "import metatensor\n",
    "from metatensor import TensorMap, TensorBlock, Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016a5d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T15:33:18.556222Z",
     "start_time": "2023-07-13T15:33:18.549427Z"
    }
   },
   "outputs": [],
   "source": [
    "from ase.build import molecule, bulk\n",
    "bulk_C2 = bulk('C')\n",
    "bulk_C2.center()\n",
    "frames = [bulk_C2]\n",
    "# angles = np.pi*np.array([0.192, 0.243, 0.567])\n",
    "# rot_bulk_C2 = rotate_frame(bulk_C2, angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_matrices = np.load('examples/data/periodic/c2/translated_matrices_kinetic.npy')\n",
    "Ls = np.load('examples/data/periodic/c2/Ls.npy')\n",
    "kpts_lst = np.load('examples/data/periodic/c2/kpts_lst.npy')\n",
    "\n",
    "# check that the translated matrices are real \n",
    "for i in range(len(translated_matrices)):\n",
    "    assert np.allclose(translated_matrices[i], translated_matrices[i].real)\n",
    "#convert translated matrices to real \n",
    "translated_matrices = np.real(translated_matrices)\n",
    "translated_matrices = translated_matrices.squeeze(axis=(1,2))\n",
    "\n",
    "    \n",
    "expkL = np.asarray(np.exp(1j*np.dot(kpts_lst, Ls.T)), order='C')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix orbital order \n",
    "from mlelec.utils.twocenter_utils import fix_orbital_order\n",
    "orbs = {6: [[1,0,0],[2,0,0],[2,1,1], [2,1,-1],[2,1,0]]}\n",
    "frames = [bulk_C2]*len(Ls)\n",
    "translated_matrices = fix_orbital_order(translated_matrices, frames, orbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3c6aad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n"
     ]
    }
   ],
   "source": [
    "Llist = [list(l) for l in Ls]\n",
    "zeroidx = Llist.index([0,0,0]) # idx of zero translation\n",
    "print(zeroidx)\n",
    "# for i in range(zeroidx-1):\n",
    "#     print(Ls[zeroidx -i -1] + Ls[zeroidx +i +1]) # symmetry of translation about zero translation\n",
    "cell_side= 1.785 # TODO for non cubic cells, this is not the same for all directions\n",
    "# relativeL= [list(np.asarray(x*Bohr/cell_side, dtype=int)) for x in Ls] #DANGEROUS rounding to int\n",
    "#\n",
    "relativeL= [list(np.asarray(x*Bohr/cell_side, dtype=float)) for x in Ls] \n",
    "relativeL = [list(np.round(x).astype(int)) for x in relativeL] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplication \n",
    "for y in relativeL: \n",
    "    # print('searching for', y)\n",
    "    idx = [i for i, x in enumerate(relativeL) if x == y]\n",
    "    if len(idx)>1:\n",
    "        print(idx)\n",
    "        for i in idx:\n",
    "            print(i, relativeL[i])\n",
    "# PASSED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_shifts = [\n",
    "    # [0, 0, 0],\n",
    "#  [0, 0, 1],\n",
    " [0, 1, -1],\n",
    "#  [0, 1, 0],\n",
    " [0, 1, 1],\n",
    "#  [1, -1, -1],\n",
    " [1, -1, 0],\n",
    "#  [1, -1, 1],\n",
    " [1, 0, -1],\n",
    "#  [1, 0, 0],\n",
    " [1, 0, 1],\n",
    "#  [1, 1, -1],\n",
    " [1, 1, 0],\n",
    "#  [1, 1, 1], \n",
    "#  [0,2,2],\n",
    "#  [0,3,5],\n",
    "#  [2,1,2],\n",
    "#  [2,0,1],\n",
    "#  [2,0,0],\n",
    "#  [3,0,0],\n",
    "#  [0,3,0],\n",
    "#  [3,2,0],\n",
    "#  [3,0,2],\n",
    "#  [2,0,3],\n",
    "#  [3,3,1]\n",
    " ]\n",
    "\n",
    "withnegative_shifts = desired_shifts.copy()\n",
    "for s in withnegative_shifts[:]:\n",
    "    withnegative_shifts.append([-s[0], -s[1], -s[2]])\n",
    "\n",
    "selected_matrices = {}\n",
    "for s in withnegative_shifts:\n",
    "    selected_matrices[str(s)] = translated_matrices[relativeL.index(s)]\n",
    "\n",
    "# check hermiticity across translations\n",
    "for s in desired_shifts[1:]:\n",
    "    if np.linalg.norm(selected_matrices[str(s)] - selected_matrices[str([-s[0], -s[1], -s[2]])].T)/np.linalg.norm(selected_matrices[str(s)])> 1e-10:\n",
    "        print(s)\n",
    "        print(np.linalg.norm(selected_matrices[str(s)] - selected_matrices[str([-s[0], -s[1], -s[2]])].T))\n",
    "        print(np.linalg.norm(selected_matrices[str(s)] - selected_matrices[str([-s[0], -s[1], -s[2]])].T)/np.linalg.norm(selected_matrices[str(s)]))\n",
    "    # assert np.allclose(selected_matrices[str(s)], selected_matrices[str([-s[0], -s[1], -s[2]])].T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need special treatment for some translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0, 1, 0]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m mat_plus2 \u001b[39m=\u001b[39m selected_matrices[\u001b[39mstr\u001b[39;49m([\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m])]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m mat_minus2 \u001b[39m=\u001b[39m selected_matrices[\u001b[39mstr\u001b[39m([\u001b[39m0\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m])]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m mat_plus3 \u001b[39m=\u001b[39m selected_matrices[\u001b[39mstr\u001b[39m([\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m])]\n",
      "\u001b[0;31mKeyError\u001b[0m: '[0, 1, 0]'"
     ]
    }
   ],
   "source": [
    "mat_plus2 = selected_matrices[str([0,1,0])]\n",
    "mat_minus2 = selected_matrices[str([0,-1,0])]\n",
    "\n",
    "mat_plus3 = selected_matrices[str([0,0,1])]\n",
    "mat_minus3 = selected_matrices[str([0,0,-1])]\n",
    "\n",
    "mat_plus1 = selected_matrices[str([1,0,0])]\n",
    "mat_minus1 = selected_matrices[str([-1, 0,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minus_from_plus(block, shift=[0,0,1], pstarting=0 ):\n",
    "    if isinstance(shift, list):\n",
    "        shift = np.asarray(shift)\n",
    "    if sum(shift)%2 == 0:\n",
    "        return block\n",
    "    elif sum(shift)%2 == 0 and 0 in shift:\n",
    "        return block\n",
    "    \n",
    "    elif not np.where(shift==0):\n",
    "        return block\n",
    "    \n",
    "    else:\n",
    "        zeroindices = np.where(shift!=0)[0]\n",
    "        print(zeroindices)\n",
    "        minusblock = np.copy(block)\n",
    "        minusblock[:,pstarting+zeroindices] *= -1 # block[zeroindices[::-1]]\n",
    "        minusblock[pstarting+ zeroindices,:] *= -1\n",
    "        return minusblock\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[ 0.00000000e+00 -1.58818678e-22 -4.76456033e-22 -2.38228016e-22\n",
      "  -2.38228016e-22]\n",
      " [-2.11758237e-22 -3.79470760e-19 -6.50521303e-19 -3.79470760e-19\n",
      "  -3.79470760e-19]\n",
      " [ 6.88214270e-22  7.04731412e-19  1.19262239e-18  8.13151629e-19\n",
      "   8.13151629e-19]\n",
      " [ 3.70576914e-22  3.79470760e-19  8.13151629e-19  2.71050543e-19\n",
      "   4.33680869e-19]\n",
      " [ 3.70576914e-22  3.79470760e-19  8.13151629e-19  4.33680869e-19\n",
      "   2.98155597e-19]]\n",
      "[0]\n",
      "2.4991097578110683e-18\n"
     ]
    }
   ],
   "source": [
    "print(get_minus_from_plus(mat_plus1[:5, :5], shift=[1,0,0], pstarting=2) - mat_minus1[:5, :5])\n",
    "print(np.linalg.norm(get_minus_from_plus(mat_plus1[:5, :5], shift=[1,0,0], pstarting=2) - mat_minus1[:5, :5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[[ 0.00000000e+00 -4.63221143e-22  7.67623608e-22 -1.48230766e-21\n",
      "  -7.41153829e-22]\n",
      " [-3.17637355e-22 -6.50521303e-19  5.69206141e-19 -1.08420217e-18\n",
      "  -5.96311195e-19]\n",
      " [-5.29395592e-22 -6.50521303e-19  3.79470760e-19 -1.19262239e-18\n",
      "  -6.23416249e-19]\n",
      " [ 1.00585162e-21  1.24683250e-18 -1.19262239e-18  1.95156391e-18\n",
      "   1.19262239e-18]\n",
      " [ 5.29395592e-22  6.50521303e-19 -6.23416249e-19  1.19262239e-18\n",
      "   4.33680869e-19]]\n",
      "[1]\n",
      "3.909804927613368e-18\n"
     ]
    }
   ],
   "source": [
    "print(get_minus_from_plus(mat_plus2[:5, :5], shift=[0,1,0], pstarting=2) - mat_minus2[:5, :5])\n",
    "print(np.linalg.norm(get_minus_from_plus(mat_plus2[:5, :5], shift=[0,1,0], pstarting=2) - mat_minus2[:5, :5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix for cross blocks is slightly different\n",
    "print(get_minus_from_plus(mat_plus1[:5, 5:], shift=[1,0,0], pstarting=2) - mat_minus1[5:, :5])\n",
    "print(np.linalg.norm(get_minus_from_plus(mat_plus1[:5, 5:], shift=[1,0,0], pstarting=2) - mat_minus1[5:, :5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.14119327e-05, -2.30556893e-05,  4.61113787e-06],\n",
       "        [-2.30556893e-05, -3.60046680e-05,  7.68522978e-06],\n",
       "        [ 4.61113787e-06,  7.68522978e-06,  8.84434988e-07]]),\n",
       " array([[ 8.84434988e-07,  7.68522978e-06,  4.61113787e-06],\n",
       "        [ 7.68522978e-06, -3.60046680e-05, -2.30556893e-05],\n",
       "        [ 4.61113787e-06, -2.30556893e-05, -1.14119327e-05]]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_plus2[2:5, 7:] , mat_minus2[7:, 2:5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_plus1[:5, :5] ,  mat_minus1[:5, :5].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## proceed for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.utils.twocenter_utils import _to_blocks, _to_matrix, _to_coupled_basis, _to_uncoupled_basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrices_sum = {}\n",
    "matrices_diff = {}\n",
    "\n",
    "#handle separately for zero translation as 0,0,0 should be the transpose of -0,-0,-0\n",
    "# matrices_sum[str(desired_shifts[0])] = 0.5*(selected_matrices[str(desired_shifts[0])]+ selected_matrices[str(desired_shifts[0])].T)\n",
    "# matrices_diff[str(desired_shifts[0])] = 0.5*(selected_matrices[str(desired_shifts[0])]- selected_matrices[str(desired_shifts[0])].T)\n",
    "\n",
    "for s in desired_shifts[:]:\n",
    "    matrices_sum[str(s)] = 0.5*(selected_matrices[str(s)] + selected_matrices[str([-s[0], -s[1], -s[2]])])\n",
    "    matrices_diff[str(s)] = 0.5* (selected_matrices[str(s)] - selected_matrices[str([-s[0], -s[1], -s[2]])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b135fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_blocks_sum = {}\n",
    "target_blocks_minus = {}\n",
    "target_coupled_blocks_sum = {}\n",
    "target_coupled_blocks_diff= {}\n",
    "for s in desired_shifts[:]:\n",
    "    target_blocks_sum[str(s)] = _to_blocks(matrices_sum[str(s)], frames=bulk_C2, orbitals=orbs)\n",
    "    target_blocks_minus[str(s)] = _to_blocks(matrices_diff[str(s)], frames=bulk_C2, orbitals=orbs)\n",
    "    target_coupled_blocks_sum[str(s)] = _to_coupled_basis(_to_blocks(matrices_sum[str(s)], frames=bulk_C2, orbitals=orbs), orbs)\n",
    "    target_coupled_blocks_diff[str(s)] = _to_coupled_basis(_to_blocks(matrices_diff[str(s)], frames=bulk_C2, orbitals=orbs), orbs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsum = {}\n",
    "rdiff = {}\n",
    "for s in desired_shifts[:]:\n",
    "    rsum[str(s)] = _to_matrix(_to_uncoupled_basis(target_coupled_blocks_sum[str(s)]), frames = bulk_C2, orbitals=orbs)\n",
    "    rdiff[str(s)] = _to_matrix(_to_uncoupled_basis(target_coupled_blocks_diff[str(s)]), frames = bulk_C2, orbitals=orbs, hermitian=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in desired_shifts[:]:\n",
    "    assert torch.allclose(rsum[str(s)].cpu(), torch.from_numpy(matrices_sum[str(s)]).type(torch.float)),print(torch.linalg.norm(rsum[str(s)].cpu()- torch.from_numpy(matrices_sum[str(s)]).type(torch.float)))\n",
    "    assert torch.allclose(rdiff[str(s)].cpu(), torch.from_numpy(matrices_diff[str(s)]).type(torch.float)) , print(torch.linalg.norm(rdiff[str(s)].cpu()-torch.from_numpy(matrices_diff[str(s)]).type(torch.float)))\n",
    "    # print(torch.linalg.norm(rsum[str(s)].cpu()- torch.from_numpy(matrices_sum[str(s)]).type(torch.float)))\n",
    "    # print(torch.linalg.norm(rdiff[str(s)].cpu()-torch.from_numpy(matrices_diff[str(s)]).type(torch.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of summing over all translations, create a fake target with sum over a smaller number of translations\n",
    "\n",
    "shift_indices = []\n",
    "for s in withnegative_shifts:\n",
    "    shift_indices.append(relativeL.index(s))\n",
    "\n",
    "expkL_small={} \n",
    "for s in withnegative_shifts:\n",
    "    expkL_small[str(s)] = expkL[:, relativeL.index(s)][0]\n",
    "\n",
    "small_shifts_target = torch.zeros(*(translated_matrices[0].shape[:])).type(torch.complex64)\n",
    "for s in expkL_small.keys():\n",
    "    small_shifts_target += expkL_small[s]*torch.from_numpy(selected_matrices[s]).type(torch.complex64)\n",
    "# np.linalg.norm(np.einsum(\"iab, ji-> jab\", np.asarray(test).squeeze(), expkL[:]) - mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO incorporate the plus minus as samples of the same translation and different translations as keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653f11c-56bc-45cf-b2d8-6f0a91d18861",
   "metadata": {},
   "source": [
    "## feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0c692a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascaline import SphericalExpansionByPair as PairExpansion\n",
    "from rascaline import SphericalExpansion\n",
    "from mlelec.utils.metatensor_utils import labels_where\n",
    "from metatensor import Labels\n",
    "from mlelec.features.acdc import twocenter_hermitian_features, single_center_features, pair_features, twocenter_hermitian_features_periodic\n",
    "from mlelec.utils.twocenter_utils import map_targetkeys_to_featkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e299cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {'cutoff': 8.,\n",
    "          'max_radial':8, \n",
    "          'max_angular':3,\n",
    "          'atomic_gaussian_width':0.3,\n",
    "          'center_atom_weight':1,\n",
    "          \"radial_basis\": {\"Gto\": {}},\n",
    "          \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.1}},\n",
    "}\n",
    "#test_rcut_shift: \n",
    "def test_rcut(frame, hypers, shifts):\n",
    "    hypers_ij = hypers.copy()\n",
    "    r = hypers['cutoff']\n",
    "    cell = frame.cell.copy()\n",
    "    norms = np.linalg.norm(bulk_C2.cell, axis=1)\n",
    "    assert isinstance(shifts[0], tuple)\n",
    "    max_shift = tuple([np.max(shifts, axis=(0,1))]*3)\n",
    "    max_disp = np.sqrt(np.dot(max_shift, norms**2))+ frame.get_all_distances().max()**2\n",
    "    if r < max_disp:\n",
    "        hypers_ij['cutoff'] = max_disp    \n",
    "    \n",
    "    return hypers_ij\n",
    "\n",
    "hypers = test_rcut(bulk_C2, hyper, [(1,1,1)])\n",
    "\n",
    "gij = PairExpansion(**hypers)\n",
    "pair = gij.compute(bulk_C2)\n",
    "\n",
    "single = single_center_features(bulk_C2, hypers, 2, lcut=2)\n",
    "pair = pair_features(bulk_C2, hypers, order_nu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68a313d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if desired_shifts is None: \n",
    "# Assume the first block has all the shifts\n",
    "#     shifts = list(zip(pair[0].samples[\"cell_shift_a\"], pair[0].samples[\"cell_shift_b\"], pair[0].samples[\"cell_shift_c\"]))\n",
    "#     unique_shifts= list(set(shifts))\n",
    "#     unique_shifts.sort()\n",
    "#     zeroidx = unique_shifts.index((0,0,0))\n",
    "#     nonneg_shifts = unique_shifts[zeroidx:]\n",
    "#     desired_shifts = [list(x) for x in nonneg_shifts if not len(np.where(np.abs(np.asarray(x))>1)[0])]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = list(zip(pair[0].samples[\"cell_shift_a\"], pair[0].samples[\"cell_shift_b\"], pair[0].samples[\"cell_shift_c\"]))\n",
    "pair_sum = {str(x):[] for x in desired_shifts}\n",
    "pair_diff = {str(x):[] for x in desired_shifts}\n",
    "blocks_plus = []\n",
    "blocks_minus = []\n",
    "\n",
    "for i, (k,b) in enumerate(pair.items()):\n",
    "    for shift in desired_shifts:\n",
    "        minus_shift = tuple(-1*np.array(shift))\n",
    "        slab, plusidx = labels_where(b.samples, selection=Labels(names=[\"cell_shift_a\", \"cell_shift_b\", \"cell_shift_c\"], values=np.array(shift).reshape(1,-1)), return_idx=True)\n",
    "        # print(len(plusidx))\n",
    "        slabm, minusidx = labels_where(b.samples, selection=Labels(names=[\"cell_shift_a\", \"cell_shift_b\", \"cell_shift_c\"], values=np.array(minus_shift).reshape(1,-1)), return_idx=True)\n",
    "        # print(len(minusidx))\n",
    "        # if i==1: \n",
    "            # print(slab.names)\n",
    "            # print(k.values, slab.values, slabm.values)\n",
    "        pvalues = b.values[plusidx] + b.values[minusidx]\n",
    "        mvalues = b.values[plusidx] - b.values[minusidx]\n",
    "        \n",
    "        blocks_plus.append(TensorBlock(values = pvalues,\n",
    "                                   components = b.components,\n",
    "                             samples = Labels(names = pair.sample_names[:-3], values=np.asarray(b.samples.values[plusidx])[:,:-3]),\n",
    "                                   properties = b.properties)\n",
    "                            )\n",
    "        \n",
    "        blocks_minus.append(TensorBlock(values = mvalues,\n",
    "                                   components = b.components,\n",
    "                             samples = Labels(names = pair.sample_names[:-3], values=np.asarray(b.samples.values[plusidx])[:,:-3]),\n",
    "                                   properties = b.properties)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 70\n",
      "Must equal the product of the two values below\n",
      "7 10\n"
     ]
    }
   ],
   "source": [
    "print(len(blocks_plus), len(blocks_minus))\n",
    "print(\"Must equal the product of the two values below\")\n",
    "print(len(pair.keys.values), len(desired_shifts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "shift_trans = list(itertools.product(pair.keys.values.tolist(), desired_shifts))\n",
    "shift_trans = [(list(itertools.chain.from_iterable(_))) for _ in shift_trans]\n",
    "shift_trans_names = pair.keys.names  + pair.sample_names[-3:]\n",
    "shift_trans = Labels(shift_trans_names, np.array(shift_trans))\n",
    "pair_plus = TensorMap(shift_trans, blocks_plus)\n",
    "pair_minus = TensorMap(shift_trans, blocks_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_plus=twocenter_hermitian_features_periodic(single, pair_plus) \n",
    "feat_minus=twocenter_hermitian_features_periodic(single, pair_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_where(feat_plus.keys, selection=Labels(names=[\"cell_shift_a\", \"cell_shift_b\", \"cell_shift_c\"], values=np.array([1,1,1]).reshape(1,-1)), return_idx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlelec.models.linear import MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LinearModelPeriodic(nn.Module):\n",
    "    def __init__(self, feat_plus, feat_minus, target_blocks_sum, target_blocks_diff, cell_shifts, frames, orbitals, device=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.feat_plus = feat_plus\n",
    "        self.feat_minus = feat_minus\n",
    "        self.target_blocks_sum = target_blocks_sum\n",
    "        self.target_blocks_diff = target_blocks_diff\n",
    "        self.cell_shifts = cell_shifts #Doesnt belong here #TODO extract this better \n",
    "        self.frames = frames\n",
    "        self.orbitals = orbitals\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dummy_property = next(iter(self.target_blocks_sum.values()))[0].properties\n",
    "        self._submodels(**kwargs)\n",
    "\n",
    "    def _submodels(self, **kwargs):\n",
    "        self.blockmodels = {}\n",
    "        for s in self.cell_shifts: \n",
    "            shiftmodels ={}\n",
    "            for k in self.target_blocks_sum[str(s)].keys:\n",
    "                feat = map_targetkeys_to_featkeys(self.feat_plus, k, cell_shift=s)\n",
    "                shiftmodels[str(tuple(k)+(1,))] = MLP(nin=feat.values.shape[-1], nout=1, nhidden=kwargs.get(\"nhidden\",10), nlayers=kwargs.get(\"nlayers\",2))\n",
    "                feat = map_targetkeys_to_featkeys(self.feat_minus, k, cell_shift=s)\n",
    "                shiftmodels[str(tuple(k)+(-1,))] = MLP(nin=feat.values.shape[-1], nout=1, nhidden=kwargs.get(\"nhidden\",10), nlayers=kwargs.get(\"nlayers\",2))\n",
    "                \n",
    "            self.blockmodels[str(s)] = torch.nn.ModuleDict(shiftmodels)\n",
    "        self.model = torch.nn.ModuleDict(self.blockmodels)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        self.recon_sum = {}\n",
    "        self.recon_diff = {} \n",
    "        for s in self.cell_shifts: \n",
    "            pred_blocks_sum = []\n",
    "            pred_blocks_diff =[]\n",
    "            for k in self.target_blocks_sum[str(s)].keys:\n",
    "                feat = map_targetkeys_to_featkeys(self.feat_plus, k, cell_shift=s)\n",
    "                nsamples, ncomp, nprops = feat.values.shape\n",
    "                pred = self.blockmodels[str(s)][str(tuple(k)+(1,))](feat.values)\n",
    "                pred_blocks_sum.append( TensorBlock(\n",
    "                values=pred.reshape((nsamples, ncomp, 1)),\n",
    "                samples=feat.samples,\n",
    "                components=feat.components,\n",
    "                properties=self.dummy_property,\n",
    "                ))\n",
    "                \n",
    "                feat = map_targetkeys_to_featkeys(self.feat_minus, k, cell_shift=s)\n",
    "                nsamples, ncomp, nprops = feat.values.shape\n",
    "                pred = self.blockmodels[str(s)][str(tuple(k)+(-1,))](feat.values)\n",
    "                pred_blocks_diff.append( TensorBlock(\n",
    "                values=pred.reshape((nsamples, ncomp, 1)),\n",
    "                samples=feat.samples,\n",
    "                components=feat.components,\n",
    "                properties=self.dummy_property,\n",
    "            ))\n",
    "\n",
    "\n",
    "            pred_sum_tmap = TensorMap(self.target_blocks_sum[str(s)].keys, pred_blocks_sum)\n",
    "            pred_diff_tmap = TensorMap(self.target_blocks_diff[str(s)].keys, pred_blocks_diff)   \n",
    "            \n",
    "            self.recon_sum[str(s)] = _to_matrix(_to_uncoupled_basis(pred_sum_tmap), frames = self.frames, orbitals=self.orbitals)\n",
    "            self.recon_diff[str(s)] = _to_matrix(_to_uncoupled_basis(pred_diff_tmap), frames = self.frames, orbitals=self.orbitals, hermitian=False)\n",
    "        \n",
    "        return self.recon_sum, self.recon_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [bulk_C2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "def loss_fn_indiv_shift(rsum, rdiff, matrix_plust, matrix_minust, specific_shift_idx:Union[str, List]=None, device=None):\n",
    "    #TODO: loss over particular shifts\n",
    "    if device is None: \n",
    "        device = next(iter(rsum.values())).device\n",
    "    assert rsum.keys() == rdiff.keys()\n",
    "    assert rsum.keys() == matrix_plust.keys()\n",
    "    weight_minus = 1\n",
    "    weight_plus = 1\n",
    "    if not isinstance(next(iter(matrix_minust.values())), torch.Tensor):\n",
    "        matrix_minust = {k:torch.from_numpy(v).type(torch.float).to(device) for k,v in matrix_minust.items()}\n",
    "    if not isinstance(next(iter(matrix_plust.values())), torch.Tensor):\n",
    "        matrix_plust = {k:torch.from_numpy(v).type(torch.float).to(device) for k,v in matrix_plust.items()}\n",
    "    loss = 0\n",
    "    if isinstance(specific_shift_idx, list):\n",
    "        raise NotImplementedError\n",
    "    elif isinstance(specific_shift_idx, str):\n",
    "        if specific_shift_idx == \"positive\":\n",
    "            weight_minus=0\n",
    "        elif specific_shift_idx == \"negative\":\n",
    "            weight_plus=0\n",
    "           \n",
    "    for s in rsum.keys():\n",
    "        plust = rsum[str(s)] + rdiff[str(s)]\n",
    "        minust = rsum[str(s)] - rdiff[str(s)]\n",
    "        loss += weight_plus*torch.sum((plust-matrix_plust[str(s)])**2) + weight_minus*torch.sum((minust-matrix_minust[str(s)])**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss_fn_combined(rsum, rdiff, expkL:dict, complex_target, device = None):\n",
    "    #TODO : support multiple k points \n",
    "    if device is None: \n",
    "        device = next(iter(rsum.values())).device\n",
    "        complex_target = complex_target.to(device)\n",
    "    assert rsum.keys() == rdiff.keys()\n",
    "    matrix = {}\n",
    "    for s in rsum.keys():\n",
    "        sint = [int(x) for x in s[1:-1].split(\", \")]\n",
    "        matrix[s] = rsum[s] + rdiff[s]\n",
    "        matrix[str([-sint[0], -sint[1], -sint[2]])] = rsum[s] - rdiff[s]\n",
    "\n",
    "    recon_target = torch.zeros_like(complex_target, requires_grad=True, dtype = torch.complex64, device = device)\n",
    "    for s in matrix.keys():\n",
    "         recon_target = recon_target+ matrix[s]*expkL[s]\n",
    "    \n",
    "    loss = torch.tensordot((recon_target-complex_target),torch.conj(recon_target-complex_target)) \n",
    "    # equivalent to torch.linalg.norm((recon_target-complex_target))**2\n",
    "    assert torch.isclose(abs(loss), abs(loss.real))\n",
    "    return loss.real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModelPeriodic(feat_plus, feat_minus, target_coupled_blocks_sum, target_coupled_blocks_diff, desired_shifts, frames, orbs, nhidden=16, nlayers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15764929354190826\n",
      "0.016342302784323692\n",
      "0.004817893262952566\n",
      "0.001984007190912962\n",
      "0.0006870462675578892\n",
      "0.00017402175581082702\n",
      "7.530872971983626e-05\n",
      "3.31263909174595e-05\n",
      "1.039859216689365e-05\n",
      "3.357890363986371e-06\n",
      "1.310852439928567e-06\n",
      "6.168491495373019e-07\n",
      "3.730638127308339e-07\n",
      "2.5614144760766067e-07\n",
      "1.960261784006434e-07\n",
      "1.7161434584522794e-07\n",
      "1.6059340168794733e-07\n",
      "1.5261019825629774e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb Cell 45\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     rsum, rdiff \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn_indiv_shift(rsum, rdiff, matrices_sum, matrices_diff, specific_shift_idx \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpositive\u001b[39m\u001b[39m'\u001b[39m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;32m/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb Cell 45\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     pred_diff_tmap \u001b[39m=\u001b[39m TensorMap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_blocks_diff[\u001b[39mstr\u001b[39m(s)]\u001b[39m.\u001b[39mkeys, pred_blocks_diff)   \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon_sum[\u001b[39mstr\u001b[39m(s)] \u001b[39m=\u001b[39m _to_matrix(_to_uncoupled_basis(pred_sum_tmap), frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes, orbitals\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morbitals)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon_diff[\u001b[39mstr\u001b[39m(s)] \u001b[39m=\u001b[39m _to_matrix(_to_uncoupled_basis(pred_diff_tmap), frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes, orbitals\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morbitals, hermitian\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y263sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon_sum, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon_diff\n",
      "File \u001b[0;32m/media/nigam/b5749eb7-d3f1-4495-adeb-2c318fb7d0de/MAC/my_mlelec/src/mlelec/utils/twocenter_utils.py:499\u001b[0m, in \u001b[0;36m_to_uncoupled_basis\u001b[0;34m(blocks, cg, device)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mif\u001b[39;00m cg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m     lmax \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(blocks\u001b[39m.\u001b[39mkeys[\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 499\u001b[0m     cg \u001b[39m=\u001b[39m ClebschGordanReal(lmax)\n\u001b[1;32m    501\u001b[0m block_builder \u001b[39m=\u001b[39m TensorBuilder(\n\u001b[1;32m    502\u001b[0m     \u001b[39m# last key name is L, we remove it here\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     blocks\u001b[39m.\u001b[39mkeys\u001b[39m.\u001b[39mnames[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m     [\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    511\u001b[0m )\n\u001b[1;32m    512\u001b[0m \u001b[39mfor\u001b[39;00m idx, block \u001b[39min\u001b[39;00m blocks\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/media/nigam/b5749eb7-d3f1-4495-adeb-2c318fb7d0de/MAC/my_mlelec/src/mlelec/utils/symmetry.py:315\u001b[0m, in \u001b[0;36mClebschGordanReal.__init__\u001b[0;34m(self, lmax, device)\u001b[0m\n\u001b[1;32m    309\u001b[0m cg_M \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\n\u001b[1;32m    310\u001b[0m     (\u001b[39mlen\u001b[39m(cg_nonzero[\u001b[39m0\u001b[39m]), \u001b[39m3\u001b[39m),\n\u001b[1;32m    311\u001b[0m     \u001b[39m# dtype=[(torch.int32, torch.int32, torch.int32)],\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice,\n\u001b[1;32m    313\u001b[0m )\n\u001b[1;32m    314\u001b[0m cg_M[:, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m cg_nonzero[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mint)\n\u001b[0;32m--> 315\u001b[0m cg_M[:, \u001b[39m1\u001b[39;49m] \u001b[39m=\u001b[39m cg_nonzero[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mint)\n\u001b[1;32m    316\u001b[0m cg_M[:, \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m rcg[cg_nonzero[\u001b[39m0\u001b[39m], cg_nonzero[\u001b[39m1\u001b[39m], M]\n\u001b[1;32m    317\u001b[0m new_cg\u001b[39m.\u001b[39mappend(cg_M)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=100, verbose=True)\n",
    "losses = []\n",
    "for i in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    rsum, rdiff = model.forward()\n",
    "    loss = loss_fn_indiv_shift(rsum, rdiff, matrices_sum, matrices_diff, specific_shift_idx = 'positive' )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step(loss)\n",
    "    losses.append(loss.item())\n",
    "    if i%10 ==0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModelPeriodic(feat_plus, feat_minus, target_coupled_blocks_sum, target_coupled_blocks_diff, desired_shifts, frames, orbs, nhidden=16, nlayers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1038382425904274\n",
      "0.00786609761416912\n",
      "0.002919369377195835\n",
      "0.0010007970267906785\n",
      "0.00043279261444695294\n",
      "0.0001539203367428854\n",
      "8.933284698287025e-05\n",
      "5.395801781560294e-05\n",
      "4.2344014218542725e-05\n",
      "3.9078113331925124e-05\n",
      "3.752602788154036e-05\n",
      "3.690515586640686e-05\n",
      "3.668478530016728e-05\n",
      "3.662038579932414e-05\n",
      "3.659453068394214e-05\n",
      "3.658318746602163e-05\n",
      "3.657736306195147e-05\n",
      "3.6574332625605166e-05\n",
      "3.657187698991038e-05\n",
      "3.6569719668477774e-05\n",
      "3.65677842637524e-05\n",
      "3.65659361705184e-05\n",
      "3.6564175388775766e-05\n",
      "3.6562487366609275e-05\n",
      "3.6560861190082505e-05\n",
      "3.655929322121665e-05\n",
      "3.6557783460011706e-05\n",
      "3.655632463051006e-05\n",
      "3.6554920370690525e-05\n",
      "3.655356340459548e-05\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=100, verbose=True)\n",
    "losses = []\n",
    "for i in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    rsum, rdiff = model.forward()\n",
    "    loss = loss_fn_indiv_shift(rsum, rdiff, matrices_sum, matrices_diff, specific_shift_idx = 'negative' )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step(loss)\n",
    "    losses.append(loss.item())\n",
    "    if i%10 ==0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModelPeriodic(feat_plus, feat_minus, target_coupled_blocks_sum, target_coupled_blocks_diff, desired_shifts, frames, orbs, nhidden=16, nlayers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16023802757263184\n",
      "0.031491734087467194\n",
      "0.009251020848751068\n",
      "0.003096561646088958\n",
      "0.0009399798000231385\n",
      "0.0004689812776632607\n",
      "0.00024364719865843654\n",
      "0.00017960922559723258\n",
      "0.00014655283303000033\n",
      "0.00012858735863119364\n",
      "0.0001240893907379359\n",
      "0.00012232616427354515\n",
      "0.00012163409701315686\n",
      "0.00012134024291299284\n",
      "0.00012129032984375954\n",
      "0.00012125116336392239\n",
      "0.00012124008208047599\n",
      "0.00012123619671911001\n",
      "0.00012123472697567195\n",
      "0.0001212342904182151\n",
      "0.00012123407941544428\n",
      "0.00012123402848374099\n",
      "0.00012123401393182576\n",
      "0.00012123399937991053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb Cell 47\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     rsum, rdiff \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn_combined(rsum, rdiff, expkL_small, small_shifts_target)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;32m/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb Cell 47\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     pred_diff_tmap \u001b[39m=\u001b[39m TensorMap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_blocks_diff[\u001b[39mstr\u001b[39m(s)]\u001b[39m.\u001b[39mkeys, pred_blocks_diff)   \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon_sum[\u001b[39mstr\u001b[39m(s)] \u001b[39m=\u001b[39m _to_matrix(_to_uncoupled_basis(pred_sum_tmap), frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes, orbitals\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morbitals)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon_diff[\u001b[39mstr\u001b[39m(s)] \u001b[39m=\u001b[39m _to_matrix(_to_uncoupled_basis(pred_diff_tmap), frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes, orbitals\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morbitals, hermitian\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcosmopc/home/nigam/scratch/MAC/k-hamiltonian/learn_kin.ipynb#Y236sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon_sum, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon_diff\n",
      "File \u001b[0;32m/media/nigam/b5749eb7-d3f1-4495-adeb-2c318fb7d0de/MAC/my_mlelec/src/mlelec/utils/twocenter_utils.py:544\u001b[0m, in \u001b[0;36m_to_uncoupled_basis\u001b[0;34m(blocks, cg, device)\u001b[0m\n\u001b[1;32m    533\u001b[0m     new_block \u001b[39m=\u001b[39m block_builder\u001b[39m.\u001b[39madd_block(\n\u001b[1;32m    534\u001b[0m         keys\u001b[39m=\u001b[39mblock_idx,\n\u001b[1;32m    535\u001b[0m         properties\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39masarray([[\u001b[39m0\u001b[39m]], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32),\n\u001b[1;32m    536\u001b[0m         components\u001b[39m=\u001b[39m[_components_idx(li), _components_idx(lj)],\n\u001b[1;32m    537\u001b[0m     )\n\u001b[1;32m    538\u001b[0m     new_block\u001b[39m.\u001b[39madd_samples(\n\u001b[1;32m    539\u001b[0m         labels\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39masarray(block\u001b[39m.\u001b[39msamples\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m    540\u001b[0m             block\u001b[39m.\u001b[39msamples\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    541\u001b[0m         ),\n\u001b[1;32m    542\u001b[0m         data\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mmoveaxis(decoupled, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    543\u001b[0m     )\n\u001b[0;32m--> 544\u001b[0m \u001b[39mreturn\u001b[39;00m block_builder\u001b[39m.\u001b[39;49mbuild()\n",
      "File \u001b[0;32m/media/nigam/b5749eb7-d3f1-4495-adeb-2c318fb7d0de/MAC/my_mlelec/src/mlelec/utils/metatensor_utils.py:86\u001b[0m, in \u001b[0;36mTensorBuilder.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m     blocks\u001b[39m.\u001b[39mappend(block\u001b[39m.\u001b[39mbuild())\n\u001b[1;32m     85\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(block, TensorBuilderPerSamples):\n\u001b[0;32m---> 86\u001b[0m     blocks\u001b[39m.\u001b[39mappend(block\u001b[39m.\u001b[39;49mbuild())\n\u001b[1;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid block type\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/nigam/b5749eb7-d3f1-4495-adeb-2c318fb7d0de/MAC/my_mlelec/src/mlelec/utils/metatensor_utils.py:129\u001b[0m, in \u001b[0;36mTensorBuilderPerSamples.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    128\u001b[0m     samples \u001b[39m=\u001b[39m Labels(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_names, np\u001b[39m.\u001b[39mvstack(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_samples))\n\u001b[0;32m--> 129\u001b[0m     block \u001b[39m=\u001b[39m TensorBlock(\n\u001b[1;32m    130\u001b[0m         values\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mcat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m),\n\u001b[1;32m    131\u001b[0m         samples\u001b[39m=\u001b[39;49msamples,\n\u001b[1;32m    132\u001b[0m         components\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_components,\n\u001b[1;32m    133\u001b[0m         properties\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_properties,\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_samples \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         \u001b[39mraise\u001b[39;00m (\u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGradient data not implemented for BlockBuilderSamples\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/metatensor/block.py:72\u001b[0m, in \u001b[0;36mTensorBlock.__init__\u001b[0;34m(self, values, samples, components, properties)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m i, component \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(components):\n\u001b[1;32m     70\u001b[0m     components_array[i] \u001b[39m=\u001b[39m component\u001b[39m.\u001b[39m_as_mts_labels_t()\n\u001b[0;32m---> 72\u001b[0m values \u001b[39m=\u001b[39m ArrayWrapper(values)\n\u001b[1;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actual_ptr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lib\u001b[39m.\u001b[39mmts_block(\n\u001b[1;32m     75\u001b[0m     values\u001b[39m.\u001b[39minto_mts_array(),\n\u001b[1;32m     76\u001b[0m     samples\u001b[39m.\u001b[39m_as_mts_labels_t(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     properties\u001b[39m.\u001b[39m_as_mts_labels_t(),\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     81\u001b[0m _check_pointer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actual_ptr)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/metatensor/data/array.py:78\u001b[0m, in \u001b[0;36mArrayWrapper.__init__\u001b[0;34m(self, array)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m# `mts_array_t::ptr` is a pointer to the PyObject `self`\u001b[39;00m\n\u001b[1;32m     73\u001b[0m mts_array\u001b[39m.\u001b[39mptr \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mcast(\n\u001b[1;32m     74\u001b[0m     ctypes\u001b[39m.\u001b[39mpointer(ctypes\u001b[39m.\u001b[39mpy_object(\u001b[39mself\u001b[39m)), ctypes\u001b[39m.\u001b[39mc_void_p\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[39m@catch_exceptions\u001b[39;49m\n\u001b[0;32m---> 78\u001b[0m \u001b[39mdef\u001b[39;49;00m \u001b[39mmts_array_origin\u001b[39;49m(this, origin):\n\u001b[1;32m     79\u001b[0m     origin[\u001b[39m0\u001b[39;49m] \u001b[39m=\u001b[39;49m array_origin\n\u001b[1;32m     81\u001b[0m \u001b[39m# use storage.XXX.__class__ to get the right type for all functions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/metatensor/utils.py:31\u001b[0m, in \u001b[0;36mcatch_exceptions\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcatch_exceptions\u001b[39m(function):\n\u001b[1;32m     30\u001b[0m     \u001b[39m@functools\u001b[39;49m\u001b[39m.\u001b[39;49mwraps(function)\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mdef\u001b[39;49;00m \u001b[39minner\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs):\n\u001b[1;32m     32\u001b[0m         \u001b[39mtry\u001b[39;49;00m:\n\u001b[1;32m     33\u001b[0m             function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/functools.py:50\u001b[0m, in \u001b[0;36mupdate_wrapper\u001b[0;34m(wrapper, wrapped, assigned, updated)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_wrapper\u001b[39m(wrapper,\n\u001b[1;32m     36\u001b[0m                    wrapped,\n\u001b[1;32m     37\u001b[0m                    assigned \u001b[39m=\u001b[39m WRAPPER_ASSIGNMENTS,\n\u001b[1;32m     38\u001b[0m                    updated \u001b[39m=\u001b[39m WRAPPER_UPDATES):\n\u001b[1;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Update a wrapper function to look like the wrapped function\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m       wrapper is the function to be updated\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m       function (defaults to functools.WRAPPER_UPDATES)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m assigned:\n\u001b[1;32m     51\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m             value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(wrapped, attr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=100, verbose=True)\n",
    "losses = []\n",
    "for i in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    rsum, rdiff = model.forward()\n",
    "    loss = loss_fn_combined(rsum, rdiff, expkL_small, small_shifts_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step(loss)\n",
    "    losses.append(loss.item())\n",
    "    if i%10 ==0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
